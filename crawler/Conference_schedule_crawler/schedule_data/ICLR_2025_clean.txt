ICLR 2025 Schedule
Skip to yearly menu bar
Skip to main content
Main Navigation
Help/FAQ
Contact ICLR
Downloads
ICLR Blog
Code of Conduct
Privacy Policy
Create Profile
Reset Password
Journal To Conference Track
Diversity & Inclusion
Proceedings at OpenReview
Future Meetings
Exhibitor Information
ICLR Twitter
About ICLR
My Stuff
Select Year: (2025)
Getting Started
Schedule
Main Conference
Invited Talks
Awards
Papers
In-person Orals
Spotlight Posters
Blog Track Posters
Workshops
Community
Town Hall
Socials
Sponsors
Organizers
Helpdesk
RocketChat Client
Website FAQ
Show Detail
Schedule
Timezone: Singapore
Filter Events
Exhibit Hall
Expo Talk Panel
Invited Talk
Mentorship
Oral Session
Poster Session
Reception
Remarks
Social
Test Of Time
Town Hall
Workshop
Filter Rooms:
Conference GHJ
Garnet 212&219
Garnet 212-213
Garnet 212-219 & Peridot 202-205
Garnet 213-215
Garnet 214-215
Garnet 216-217
Garnet 216-218
Garnet 218-219
Hall 1 Apex
Hall 2
Hall 3 + Hall 2B
Hall 4
Hall 4 #1
Hall 4 #2
Hall 4 #3
Hall 4 #4
Hall 4 #5
Hall 4 #6
Hall 4 #7
Opal 101-102
Opal 103-104
Peridot 201
Peridot 201&206
Peridot 202-203
Peridot 204-205
Peridot 206
Topaz 220-225
Topaz Concourse
THU 24 APR
8:45 a.m.
Remarks:
Opening Remarks - Welcome
(ends 9:00 AM)
9 a.m.
Invited Talk:
Building Safe and Robust AI Systems
Zico Kolter
(ends 10:00 AM)
Invited Talk:
Overflow: Building Safe and Robust AI Systems
Zico Kolter
(ends 10:00 AM)
10 a.m.
Poster Session 1
[10:00-12:30]
Poster
10:00-12:30
PharmacoMatch: Efficient 3D Pharmacophore Screening via Neural Subgraph Matching
Hotspot-Driven Peptide Design via Multi-Fragment Autoregressive Extension
DriveTransformer: Unified Transformer for Scalable End-to-End Autonomous Driving
Meta-Continual Learning of Neural Fields
Understanding Long Videos with Multimodal Language Models
GTR: Improving Large 3D Reconstruction Models through Geometry and Texture Refinement
GenVP: Generating Visual Puzzles with Contrastive Hierarchical VAEs
Scalable Benchmarking and Robust Learning for Noise-Free Ego-Motion and 3D Reconstruction from Noisy Video
Kronecker Mask and Interpretive Prompts are Language-Action Video Learners
Fast Training of Sinusoidal Neural Fields via Scaling Initialization
DECO: Unleashing the Potential of ConvNets for Query-based Detection and Segmentation
GaussianBlock: Building Part-Aware Compositional and Editable 3D Scene by Primitives and Gaussians
ReNovo: Retrieval-Based \emph{De Novo} Mass Spectrometry Peptide Sequencing
Controllable Blur Data Augmentation Using 3D-Aware Motion Estimation
Efficient Neuron Segmentation in Electron Microscopy by Affinity-Guided Queries
Eagle: Exploring The Design Space for Multimodal LLMs with Mixture of Encoders
One-for-All Few-Shot Anomaly Detection via Instance-Induced Prompt Learning
MotionAura: Generating High-Quality and Motion Consistent Videos using Discrete Diffusion
ImDy: Human Inverse Dynamics from Imitated Observations
MotionDreamer: One-to-Many Motion Synthesis with Localized Generative Masked Transformer
DELTA: DENSE EFFICIENT LONG-RANGE 3D TRACKING FOR ANY VIDEO
Gaussian Splatting Lucas-Kanade
Spatial-Mamba: Effective Visual State Space Models via Structure-Aware State Fusion
DenoiseVAE: Learning Molecule-Adaptive Noise Distributions for Denoising-based 3D Molecular Pre-training
Reti-Diff: Illumination Degradation Image Restoration with Retinex-based Latent Diffusion Model
MMR: A Large-scale Benchmark Dataset for Multi-target and Multi-granularity Reasoning Segmentation
TimeSuite: Improving MLLMs for Long Video Understanding via Grounded Tuning
Distilling Dataset into Neural Field
Vision-RWKV: Efficient and Scalable Visual Perception with RWKV-Like Architectures
MMWorld: Towards Multi-discipline Multi-faceted World Model Evaluation in Videos
Scaling In-the-Wild Training for Diffusion-based Illumination Harmonization and Editing by Imposing Consistent Light Transport
Self-Supervised Diffusion MRI Denoising via Iterative and Stable Refinement
Sort-free Gaussian Splatting via Weighted Sum Rendering
Contextual Self-paced Learning for Weakly Supervised Spatio-Temporal Video Grounding
Meta Flow Matching: Integrating Vector Fields on the Wasserstein Manifold
Once-for-All: Controllable Generative Image Compression with Dynamic Granularity Adaptation
A Large-scale Dataset and Benchmark for Commuting Origin-Destination Flow Generation
Near, far: Patch-ordering enhances vision foundation models' scene understanding
VLMaterial: Procedural Material Generation with Large Vision-Language Models
AIMS.au: A Dataset for the Analysis of Modern Slavery Countermeasures in Corporate Statements
Linear Recurrences Accessible to Everyone
Beyond Squared Error: Exploring Loss Design for Enhanced Training of Generative Flow Networks
Accelerating neural network training: An analysis of the AlgoPerf competition
Adapt-$\infty$: Scalable Continual Multimodal Instruction Tuning via Dynamic Data Selection
Boltzmann Semantic Score: A Semantic Metric for Evaluating Large Vision Models Using Large Language Models
MambaQuant: Quantizing the Mamba Family with Variance Aligned Rotation Methods
FlashRNN: I/O-Aware Optimization of Traditional RNNs on modern hardware
Understanding Matrix Function Normalizations in Covariance Pooling through the Lens of Riemannian Geometry
OSTQuant: Refining Large Language Model Quantization with Orthogonal and Scaling Transformations for Better Distribution Fitting
Mechanistic Interpretability Meets Vision Language Models: Insights and Limitations
PADRe: A Unifying Polynomial Attention Drop-in Replacement for Efficient Vision Transformer
Selective induction Heads: How Transformers Select Causal Structures in Context
Spiking Vision Transformer with Saccadic Attention
Generative Adversarial Ranking Nets
Be More Diverse than the Most Diverse: Optimal Mixtures of Generative Models via Mixture-UCB Bandit Algorithms
Learning to engineer protein flexibility
Improving Long-Text Alignment for Text-to-Image Diffusion Models
Learning Spatiotemporal Dynamical Systems from Point Process Observations
Automated Filtering of Human Feedback Data for Aligning Text-to-Image Diffusion Models
RouteLLM: Learning to Route LLMs from Preference Data
Denoising Task Difficulty-based Curriculum for Training Diffusion Models
T2V-Turbo-v2: Enhancing Video Model Post-Training through Data, Reward, and Conditional Guidance Design
Robust Barycenter Estimation using Semi-Unbalanced Neural Optimal Transport
TFG-Flow: Training-free Guidance in Multimodal Generative Flow
GeSubNet: Gene Interaction Inference for Disease Subtype Network Generation
Manifolds, Random Matrices and Spectral Gaps: The geometric phases of generative diffusion
Accelerating Auto-regressive Text-to-Image Generation with Training-free Speculative Jacobi Decoding
Efficient Perplexity Bound and Ratio Matching in Discrete Diffusion Language Models
One Step Diffusion via Shortcut Models
Steering Masked Discrete Diffusion Models via Discrete Denoising Posterior Prediction
ImageFolder: Autoregressive Image Generation with Folded Tokens
A3D: Does Diffusion Dream about 3D Alignment?
Fréchet Wavelet Distance: A Domain-Agnostic Metric for Image Generation
Denoising Levy Probabilistic Models
FreCaS: Efficient Higher-Resolution Image Generation via Frequency-aware Cascaded Sampling
Multimodal Lego: Model Merging and Fine-Tuning Across Topologies and Modalities in Biomedicine
Approaching Rate-Distortion Limits in Neural Compression with Lattice Transform Coding
Concept Pinpoint Eraser for Text-to-image Diffusion Models via Residual Attention Gate
Diffusion Transformers for Tabular Data Time Series Generation
Precise Parameter Localization for Textual Generation in Diffusion Models
Simple Guidance Mechanisms for Discrete Diffusion Models
Overcoming False Illusions in Real-World Face Restoration with Multi-Modal Guided Diffusion Model
Layout-your-3D: Controllable and Precise 3D Generation with 2D Blueprint
DreamDistribution: Learning Prompt Distribution for Diverse In-distribution Generation
Lightning-Fast Image Inversion and Editing for Text-to-Image Diffusion Models
Discrete Diffusion Schrödinger Bridge Matching for Graph Transformation
PathGen-1.6M: 1.6 Million Pathology Image-text Pairs Generation through Multi-agent Collaboration
Heavy-Tailed Diffusion Models
Block Diffusion: Interpolating Between Autoregressive and Diffusion Language Models
SaRA: High-Efficient Diffusion Model Fine-tuning with Progressive Sparse Low-Rank Adaptation
NRGBoost: Energy-Based Generative Boosted Trees
A Spark of Vision-Language Intelligence: 2-Dimensional Autoregressive Transformer for Efficient Finegrained Image Generation
HERO: Human-Feedback Efficient Reinforcement Learning for Online Diffusion Model Finetuning
Do You Keep an Eye on What I Ask? Mitigating Multimodal Hallucination via Attention-Guided Ensemble Decoding
Spectro-Riemannian Graph Neural Networks
Training-Free Message Passing for Learning on Hypergraphs
On the Completeness of Invariant Geometric Deep Learning Models
NutriBench: A Dataset for Evaluating Large Language Models in Nutrition Estimation from Meal Descriptions
E(n) Equivariant Topological Neural Networks
The Effectiveness of Curvature-Based Rewiring and the Role of Hyperparameters in GNNs Revisited
Generalizing Weisfeiler-Lehman Kernels to Subgraphs
Exponential Topology-enabled Scalable Communication in Multi-agent Reinforcement Learning
Towards Continuous Reuse of Graph Models via Holistic Memory Diversification
Higher-Order Graphon Neural Networks: Approximation and Cut Distance
Relation-Aware Diffusion for Heterogeneous Graphs with Partially Observed Features
Improving Graph Neural Networks by Learning Continuous Edge Directions
ContextGNN: Beyond Two-Tower Recommendation Systems
Chemistry-Inspired Diffusion with Non-Differentiable Guidance
Reliable and Diverse Evaluation of LLM Medical Knowledge Mastery
Systematic Relational Reasoning With Epistemic Graph Neural Networks
Homomorphism Expressivity of Spectral Invariant Graph Neural Networks
Node Identifiers: Compact, Discrete Representations for Efficient Graph Learning
Precedence-Constrained Winter Value for Effective Graph Data Valuation
GOLD: Graph Out-of-Distribution Detection via Implicit Adversarial Latent Generation
TAU-106K: A New Dataset for Comprehensive Understanding of Traffic Accident
CycleResearcher: Improving Automated Research via Automated Review
Training LLMs over Neurally Compressed Text
Intricacies of Feature Geometry in Large Language Models
On LLM Knowledge Distillation - A Comparison between Forward KL and Reverse KL
Learning-Augmented Search Data Structures
VILA-U: a Unified Foundation Model Integrating Visual Understanding and Generation
Multi-modal Agent Tuning: Building a VLM-Driven Agent for Efficient Tool Usage
Do Large Language Models Truly Understand Geometric Structures?
Chain-of-Action: Faithful and Multimodal Question Answering through Large Language Models
Monet: Mixture of Monosemantic Experts for Transformers
HELMET: How to Evaluate Long-context Models Effectively and Thoroughly
From Commands to Prompts: LLM-based Semantic File System for AIOS
LongGenBench: Benchmarking Long-Form Generation in Long Context LLMs
Visual Description Grounding Reduces Hallucinations and Boosts Reasoning in LVLMs
On the self-verification limitations of large language models on reasoning and planning tasks
Adaptive Shrinkage Estimation for Personalized Deep Kernel Regression in Modeling Brain Trajectories
Nova: Generative Language Models for Assembly Code with Hierarchical Attention and Contrastive Learning
Inference Optimal VLMs Need Fewer Visual Tokens and More Parameters
DON’T STOP ME NOW: EMBEDDING BASED SCHEDULING FOR LLMS
Logically Consistent Language Models via Neuro-Symbolic Integration
xFinder: Large Language Models as Automated Evaluators for Reliable Evaluation
RRM:  Robust Reward Model Training Mitigates Reward Hacking
ToolACE: Winning the Points of LLM Function Calling
RaSA: Rank-Sharing Low-Rank Adaptation
Sample then Identify: A General Framework for Risk Control and Assessment in Multimodal Large Language Models
Diffusion Models are Evolutionary Algorithms
PhysBench: Benchmarking and Enhancing Vision-Language Models for Physical World Understanding
ROUTE: Robust Multitask Tuning and Collaboration for Text-to-SQL
Understanding and Mitigating Hallucination in Large Vision-Language Models via Modular Attribution and Intervention
RuAG: Learned-rule-augmented Generation for Large Language Models
Interactive Speculative Planning: Enhance Agent Efficiency through Co-design of System and User Interface
Polynomial Composition Activations: Unleashing the Dynamics of Large Language Models
Digi-Q: Learning VLM Q-Value Functions for Training Device-Control Agents
Beyond Single Concept Vector: Modeling Concept Subspace in LLMs with Gaussian Distribution
MovieDreamer: Hierarchical Generation for Coherent Long Visual Sequences
Privacy-Preserving Personalized Federated Prompt Learning for Multimodal Large Language Models
Shh, don't say that! Domain Certification in LLMs
QuaDiM: A Conditional Diffusion Model For Quantum State Property Estimation
STAFF: Speculative Coreset Selection for Task-Specific Fine-tuning
Determine-Then-Ensemble: Necessity of Top-k Union for Large Language Model Ensembling
World Model on Million-Length Video And Language With Blockwise RingAttention
Certifying Counterfactual Bias in LLMs
Streamlining Redundant Layers to Compress Large Language Models
Harnessing Webpage UIs for Text-Rich Visual Understanding
An Empirical Analysis of Uncertainty in Large Language Model Evaluations
Jamba: Hybrid Transformer-Mamba Language Models
Language Imbalance Driven Rewarding for Multilingual Self-improving
Learning Chaos In A Linear Way
Learning to Plan Before Answering: Self-Teaching LLMs to Learn Abstract Plans for Problem Solving
Frame-Voyager: Learning to Query Frames for Video Large Language Models
Eliciting Human Preferences with Language Models
Can LLMs Generate Novel Research Ideas? A Large-Scale Human Study with 100+ NLP Researchers
SFS: Smarter Code Space Search improves LLM Inference Scaling
Commit0: Library Generation from Scratch
Chain-of-Thought Provably Enables Learning the (Otherwise) Unlearnable
Efficiently Learning at Test-Time: Active Fine-Tuning of LLMs
Measuring And Improving Persuasiveness Of Large Language Models
KaSA: Knowledge-Aware Singular-Value Adaptation of Large Language Models
Regularized Proportional Fairness Mechanism for Resource Allocation Without Money
Progressive Mixed-Precision Decoding for Efficient LLM Inference
Earlier Tokens Contribute More: Learning Direct Preference Optimization From Temporal Decay Perspective
u-$\mu$P: The Unit-Scaled Maximal Update Parametrization
Reframing Structure-Based Drug Design Model Evaluation via Metrics Correlated to Practical Needs
Should VLMs be Pre-trained with Image Data?
Magpie: Alignment Data Synthesis from Scratch by Prompting Aligned LLMs with Nothing
RAG-DDR: Optimizing Retrieval-Augmented Generation Using Differentiable Data Rewards
SuperCorrect: Advancing Small LLM Reasoning with Thought Template Distillation and Self-Correction
ClawMachine: Learning to Fetch Visual Tokens for Referential Comprehension
The Belief State Transformer
MGCFNN: A Neural MultiGrid Solver with Novel Fourier Neural Network for High Wave Number Helmholtz Equations
Gnothi Seauton: Empowering Faithful Self-Interpretability in Black-Box Transformers
TypedThinker: Diversify Large Language Model Reasoning with Typed Thinking
MrT5: Dynamic Token Merging for Efficient Byte-level Language Models
Dynamic Multimodal Evaluation with Flexible Complexity by Vision-Language Bootstrapping
GraphArena: Evaluating and Exploring Large Language Models on Graph Computation
Step-by-Step Reasoning for Math Problems  via Twisted Sequential Monte Carlo
SELF-EVOLVED REWARD LEARNING FOR LLMS
Enhancing Language Model Agents using Diversity of Thoughts
Injecting Universal Jailbreak Backdoors into LLMs in Minutes
Generating Physical Dynamics under Priors
BigDocs: An Open Dataset for Training Multimodal Models on Document and Code Tasks
Can Generative AI Solve Your In-Context Learning Problem?  A Martingale Perspective
DuoAttention: Efficient Long-Context LLM Inference with Retrieval and Streaming Heads
Efficient Learning with Sine-Activated Low-Rank Matrices
Data Selection via Optimal Control for Language Models
Filtered not Mixed: Filtering-Based Online Gating for Mixture of Large Language Models
PerturboLLaVA: Reducing Multimodal Hallucinations with Perturbative Visual Training
What is Wrong with Perplexity for Long-context Language Modeling?
When LLMs Play the Telephone Game: Cultural Attractors as Conceptual Tools to Evaluate LLMs in Multi-turn Settings
CS-Bench: A Comprehensive Benchmark for Large Language Models towards Computer Science Mastery
Continuous Ensemble Weather Forecasting with Diffusion models
As Simple as Fine-tuning: LLM Alignment via Bidirectional Negative Feedback Loss
SCBench: A KV Cache-Centric Analysis of Long-Context Methods
Improving Complex Reasoning with Dynamic Prompt Corruption: A Soft Prompt Optimization Approach
OBI-Bench: Can LMMs Aid in Study of Ancient Script on Oracle Bones?
Investigating the Pre-Training Dynamics of In-Context Learning: Task Recognition vs. Task Learning
ComLoRA: A Competitive Learning Approach for Enhancing LoRA
HeadMap: Locating and Enhancing Knowledge Circuits in LLMs
U-shaped and Inverted-U Scaling behind Emergent Abilities of Large Language Models
Adaptive Deployment of Untrusted LLMs Reduces Distributed Threats
OSDA Agent: Leveraging Large Language Models for De Novo Design of Organic Structure Directing Agents
SimXRD-4M: Big Simulated X-ray Diffraction Data and Crystal Symmetry Classification Benchmark
Enhancing Graph Of Thought: Enhancing Prompts with LLM Rationales and Dynamic Temperature Control
Show-o: One Single Transformer to Unify Multimodal Understanding and Generation
AgentOccam: A Simple Yet Strong Baseline for LLM-Based Web Agents
LongMemEval: Benchmarking Chat Assistants on Long-Term Interactive Memory
mPLUG-Owl3: Towards Long Image-Sequence Understanding in Multi-Modal Large Language Models
On the Optimization Landscape of Low Rank Adaptation Methods for Large Language Models
VOILA: Evaluation of MLLMs For Perceptual Understanding and Analogical Reasoning
Uncovering Overfitting in Large Language Model Editing
Knowledge Localization: Mission Not Accomplished? Enter Query Localization!
VAE-Var: Variational Autoencoder-Enhanced Variational Methods for Data Assimilation in Meteorology
RainbowPO: A Unified Framework for Combining Improvements in Preference Optimization
Composable Interventions for Language Models
OmniKV: Dynamic Context Selection for Efficient Long-Context LLMs
VideoWebArena:  Evaluating Long Context Multimodal Agents with Video Understanding Web Tasks
TODO: Enhancing LLM Alignment with Ternary Preferences
Beware of Calibration Data for Pruning Large Language Models
Speculative RAG: Enhancing Retrieval Augmented Generation through Drafting
PALMBENCH: A COMPREHENSIVE BENCHMARK OF COMPRESSED LARGE LANGUAGE MODELS ON MOBILE PLATFORMS
HarmAug: Effective Data Augmentation for Knowledge Distillation of Safety Guard Models
Active Learning for Neural PDE Solvers
Generative Monoculture in Large Language Models
VisRAG: Vision-based Retrieval-augmented Generation on Multi-modality Documents
Exact Byte-Level Probabilities from Tokenized Language Models for FIM-Tasks and Model Ensembles
Lines of Thought in Large Language Models
RefactorBench: Evaluating Stateful Reasoning in Language Agents Through Code
On Quantizing Neural Representation for Variable-Rate Video Coding
Model merging with SVD to tie the Knots
High-Dynamic Radar Sequence Prediction for Weather Nowcasting Using Spatiotemporal Coherent Gaussian Representation
Exploring the Effectiveness of Object-Centric Representations in Visual Question Answering: Comparative Insights with Foundation Models
Neural Eulerian Scene Flow Fields
Learning Continually by Spectral Regularization
Towards Unified Human Motion-Language Understanding via Sparse Interpretable Characterization
A Simple Framework for Open-Vocabulary Zero-Shot Segmentation
Release the Powers of Prompt Tuning: Cross-Modality Prompt Transfer
Cross the Gap:  Exposing the Intra-modal Misalignment in CLIP via Modality Inversion
Improving Deep Regression with Tightness
DICE: Data Influence Cascade in Decentralized Learning
NoVo: Norm Voting off Hallucinations with Attention Heads in Large Language Models
SEBRA : Debiasing through Self-Guided Bias Ranking
NextBestPath: Efficient 3D Mapping of Unseen Environments
Concept-ROT: Poisoning Concepts in Large Language Models with Model Editing
Multi-level Certified Defense Against Poisoning Attacks in Offline Reinforcement Learning
Understanding and Enhancing the Transferability of Jailbreaking Attacks
Aligned Datasets Improve Detection of Latent Diffusion-Generated Images
Inverse Scaling: When Bigger Isn't Better
Optimizing importance weighting in the presence of sub-population shifts
Support is All You Need for Certified VAE Training
Adversarially Robust Anomaly Detection through Spurious Negative Pair Mitigation
Aligning Visual Contrastive learning models via Preference Optimization
Refining CLIP's Spatial Awareness: A Visual-Centric Perspective
LASeR: Towards Diversified and Generalizable Robot Design with Large Language Models
COME: Test-time Adaption by Conservatively Minimizing Entropy
COPER: Correlation-based Permutations for Multi-View Clustering
FlexCAD: Unified and Versatile Controllable CAD Generation with Fine-tuned Large Language Models
Projection Head is Secretly an Information Bottleneck
Learning Mask Invariant Mutual Information for Masked Image Modeling
Efficient Distribution Matching of Representations via Noise-Injected Deep InfoMax
On Discriminative Probabilistic Modeling for Self-Supervised Representation Learning
What Does It Mean to Be a Transformer? Insights from a Theoretical Hessian Analysis
UniGEM: A Unified Approach to Generation and Property Prediction for Molecules
Deep Networks Learn Features From Local Discontinuities in the Label Function
Bootstrapping Language-Guided Navigation Learning with Self-Refining Data Flywheel
Ask, and it shall be given: On the Turing completeness of prompting
Sharpness-Aware Minimization Efficiently Selects Flatter Minima Late In Training
Training Neural Networks as Recognizers of Formal Languages
The Unreasonable Ineffectiveness of the Deeper Layers
Effective and Efficient Time-Varying Counterfactual Prediction with State-Space Models
A-Bench: Are LMMs Masters at Evaluating AI-generated Images?
MLE-bench: Evaluating Machine Learning Agents on Machine Learning Engineering
Transformers Struggle to Learn to Search
Adversarial Mixup Unlearning
Learning Geometric Reasoning Networks For Robot Task And Motion Planning
MMIE: Massive Multimodal Interleaved Comprehension Benchmark for Large Vision-Language Models
NExUME: Adaptive Training and Inference for DNNs under Intermittent Power Environments
Find A Winning Sign: Sign Is All We Need to Win the Lottery
Weak-to-Strong Generalization Through the Data-Centric Lens
Deep Weight Factorization: Sparse Learning Through the Lens of Artificial Symmetries
Unlocking Global Optimality in Bilevel Optimization: A Pilot Study
Rethinking Light Decoder-based Solvers for Vehicle Routing Problems
Solving hidden monotone variational inequalities with surrogate losses
Nesterov acceleration in benignly non-convex landscapes
Overcoming Lower-Level Constraints in Bilevel Optimization: A Novel Approach with Regularized Gap Functions
Towards Realistic UAV Vision-Language Navigation: Platform, Benchmark, and Methodology
Loss Landscape of Shallow ReLU-like Neural Networks: Stationary Points, Saddle Escape, and Network Embedding
Does SGD really happen in tiny subspaces?
A Deep Generative Learning Approach for Two-stage Adaptive Robust Optimization
On Stochastic Contextual Bandits with Knapsacks in Small Budget Regime
Optimization by Parallel Quasi-Quantum Annealing with Gradient-Based Sampling
OCCAM: Towards Cost-Efficient and Accuracy-Aware Classification Inference
Provable Convergence Bounds for Hybrid Dynamical Sampling and Optimization
SINGER: Stochastic Network Graph Evolving Operator for High Dimensional PDEs
Utilitarian Algorithm Configuration for Infinite Parameter Spaces
Cross-Embodiment Dexterous Grasping with Reinforcement Learning
Vertical Federated Learning with Missing Features During Training and Inference
Convergence of Distributed Adaptive Optimization with Local Updates
Local Steps Speed Up Local GD for Heterogeneous Distributed Logistic Regression
On Scaling Up 3D Gaussian Splatting Training
MAST: model-agnostic sparsified training
SMI-Editor: Edit-based SMILES Language Model with Fragment-level Supervision
Decision Information Meets Large Language Models: The Future of Explainable Operations Research
Flat Reward in Policy Parameter Space Implies Robust Reinforcement Learning
AtomSurf: Surface Representation for Learning on Protein Structures
Stem-OB: Generalizable Visual Imitation Learning with Stem-Like Convergent Observation through Diffusion Inversion
Hierarchical World Models as Visual Whole-Body Humanoid Controllers
DeepLTL: Learning to Efficiently Satisfy Complex LTL Specifications for Multi-Task RL
Transformers Can Learn Temporal Difference Methods for In-Context Reinforcement Learning
Towards General-Purpose Model-Free Reinforcement Learning
Bootstrapped Model Predictive Control
Learning Splitting Heuristics in Divide-and-Conquer SAT Solvers with Reinforcement Learning
Towards Empowerment Gain through Causal Structure Learning in Model-Based Reinforcement Learning
Toward Exploratory Inverse Constraint Inference with Generative Diffusion Verifiers
Physiome-ODE: A Benchmark for Irregularly Sampled Multivariate Time-Series Forecasting Based on Biological ODEs
ComaDICE: Offline Cooperative Multi-Agent Reinforcement Learning with Stationary Distribution Shift Regularization
Federated $Q$-Learning with Reference-Advantage Decomposition: Almost Optimal Regret and Logarithmic Communication Cost
Inverse Attention Agents for Multi-Agent Systems
eQMARL: Entangled Quantum Multi-Agent Reinforcement Learning for Distributed Cooperation over Quantum Channels
Diff3DS: Generating View-Consistent 3D Sketch via Differentiable Curve Rendering
Discrete Codebook World Models for Continuous Control
Open-World Reinforcement Learning over Long Short-Term Imagination
What Makes a Good Diffusion Planner for Decision Making?
Learning to Search from Demonstration Sequences
Policy Gradient with Kernel Quadrature
Diffusion-based Decoupled Deterministic and Uncertain Framework for Probabilistic Multivariate Time Series Forecasting
Efficient Residual Learning with Mixture-of-Experts for Universal Dexterous Grasping
MrSteve: Instruction-Following Agents in Minecraft with What-Where-When Memory
Leveraging Sub-Optimal Data for Human-in-the-Loop Reinforcement Learning
Interpreting Emergent Planning in Model-Free Reinforcement Learning
Mitigating Information Loss in Tree-Based Reinforcement Learning via Direct Optimization
CBMA: Improving Conformal Prediction through Bayesian Model Averaging
Residual Deep Gaussian Processes on Manifolds
Sequential Controlled Langevin Diffusions
Variance-Reducing Couplings for Random Features
Zero-shot Imputation with Foundation Inference Models for Dynamical Systems
Score-based free-form architectures for high-dimensional Fokker-Planck equations
Conformalized Survival Analysis for General Right-Censored Data
Wasserstein-Regularized Conformal Prediction under General Distribution Shift
Identifying latent state transitions in non-linear dynamical systems
Multi-Dimensional Conformal Prediction
Training One-Dimensional Graph Neural Networks is NP-Hard
Robust Feature Learning for Multi-Index Models in High Dimensions
DynaPrompt: Dynamic Test-Time Prompt Tuning
Revisiting Source-Free Domain Adaptation: a New Perspective via Uncertainty Control
On the Convergence of No-Regret Dynamics in Information Retrieval Games with Proportional Ranking Functions
Context-Alignment: Activating and Enhancing LLMs Capabilities in Time Series
Re-evaluating Open-ended Evaluation of Large Language Models
Sketching for Convex and Nonconvex Regularized Least Squares with Sharp Guarantees
Transformers Handle Endogeneity in In-Context Linear Regression
The Breakdown of Gaussian Universality in Classification of High-dimensional Linear Factor Mixtures
Towards Generalization Bounds of GCNs for Adversarially Robust Node Classification
How Much is Unseen Depends Chiefly on Information About the Seen
Demystifying Online Clustering of Bandits: Enhanced Exploration Under Stochastic and Smoothed Adversarial Contexts
Conservative Contextual Bandits: Beyond Linear Representations
Lasso Bandit with Compatibility Condition on Optimal Arm
Almost Optimal Batch-Regret Tradeoff for Batch Linear Contextual Bandits
Flow Matching with Gaussian Process Priors for Probabilistic Time Series Forecasting
ADAM Optimization with Adaptive Batch Selection
Faster Algorithms for Structured Linear and Kernel Support Vector Machines
Streaming Algorithms For $\ell_p$ Flows and $\ell_p$ Regression
DPaI: Differentiable Pruning at Initialization with Node-Path Balance Principle
Quantum (Inspired)  $D^2$-sampling with Applications
Reexamining the Aleatoric and Epistemic Uncertainty Dichotomy
Singular Subspace Perturbation Bounds via Rectangular Random Matrix Diffusions
Matrix Product Sketching via Coordinated Sampling
Learning a Fast Mixing Exogenous Block MDP using a Single Trajectory
Learning Diagrams: A Graphical Language for Compositional Training Regimes
Neuron Platonic Intrinsic Representation From Dynamics Using Contrastive Learning
Optimal Protocols for Continual Learning via Statistical Physics and Control Theory
Constructing Confidence Intervals for Average Treatment Effects from Multiple Datasets
ADAM: An Embodied Causal Agent in Open-World Environments
Recovery of Causal Graph Involving Latent Variables via Homologous Surrogates
Causal Graph Transformer for Treatment Effect Estimation Under Unknown Interference
Robust Root Cause Diagnosis using In-Distribution Interventions
When Selection Meets Intervention: Additional Complexities in Causal Discovery
Euler Characteristic Tools for Topological Data Analysis
Instance-dependent Early Stopping
Out-of-distribution Generalization for Total Variation based Invariant Risk Minimization
Dynamic-SUPERB Phase-2: A Collaboratively Expanding Benchmark for Measuring the Capabilities of Spoken Language Models with 180 Tasks
Controlling Language and Diffusion Models by Transporting Activations
Exploiting Distribution Constraints for Scalable and Efficient Image Retrieval
Predicate Hierarchies Improve Few-Shot State Classification
Diffusion Feedback Helps CLIP See Better
PhysPDE: Rethinking PDE Discovery and a Physical HYpothesis Selection Benchmark
Scalable Universal T-Cell Receptor Embeddings from Adaptive Immune Repertoires
Realistic Evaluation of Deep Partial-Label Learning Algorithms
DLEFT-MKC: Dynamic Late Fusion Multiple Kernel Clustering with Robust Tensor Learning via Min-Max Optimization
Lost in Prediction: Why Social Media Narratives Don't Help Macroeconomic Forecasting?
Simple yet Effective Incomplete Multi-view Clustering: Similarity-level Imputation and Intra-view Hybrid-group Prototype Construction
Two Effects, One Trigger: On the Modality Gap, Object Bias, and Information Imbalance in Contrastive Vision-Language Models
Exact Community Recovery under Side Information: Optimality of Spectral Algorithms
TSC-Net: Prediction of Pedestrian Trajectories by Trajectory-Scene-Cell Classification
Uni-Sign: Toward Unified Sign Language Understanding at Scale
LoCA: Location-Aware Cosine Adaptation for Parameter-Efficient Fine-Tuning
LiFT: Learning to Fine-Tune via Bayesian Parameter Efficient Meta Fine-Tuning
CL-DiffPhyCon: Closed-loop Diffusion Control of Complex Physical Systems
Self-Normalized Resets for Plasticity in Continual Learning
Automated Proof Generation for Rust Code via Self-Evolution
Query-based Knowledge Transfer for Heterogeneous Learning Environments
Modeling Unseen Environments with Language-guided Composable Causal Components in Reinforcement Learning
Deep Linear Probe Generators for Weight Space Learning
Selective Aggregation for Low-Rank Adaptation in Federated Learning
Pitfalls of Evidence-Based AI Policy
Uncovering Gaps in How Humans and LLMs Interpret Subjective Language
Enhancing Learning with Label Differential Privacy by Vector Approximation
A Statistical Approach for Controlled Training Data Detection
Differentially Private Steering for Large Language Model Alignment
Examining Alignment of Large Language Models through Representative Heuristics: the case of political stereotypes
ShEPhERD: Diffusing shape, electrostatics, and pharmacophores for bioisosteric drug design
Revisiting Convolution Architecture in the Realm of DNA Foundation Models
Forte : Finding Outliers with Representation Typicality Estimation
PFGuard: A Generative Framework with Privacy and Fairness Safeguards
Poison-splat: Computation Cost Attack on 3D Gaussian Splatting
SaLoRA: Safety-Alignment Preserved Low-Rank Adaptation
How to Verify Any (Reasonable) Distribution Property: Computationally Sound Argument Systems for Distributions
Do LLMs estimate uncertainty well in instruction-following?
Selective Unlearning via Representation Erasure Using Domain Adversarial Training
Mechanistic Permutability: Match Features Across Layers
A transfer learning framework for weak to strong generalization
Agent Security Bench (ASB): Formalizing and Benchmarking Attacks and Defenses in LLM-based Agents
MELODI: Exploring Memory Compression for Long Contexts
Adversarial Search Engine Optimization for Large Language Models
Interpreting Language Reward Models via Contrastive Explanations
Large Language Models can Become Strong Self-Detoxifiers
Ward: Provable RAG Dataset Inference via LLM Watermarks
Self-Introspective Decoding: Alleviating Hallucinations for Large Vision-Language Models
Regretful Decisions under Label Noise
Exact Computation of Any-Order Shapley Interactions for Graph Neural Networks
Enhancing Pre-trained Representation Classifiability can Boost its Interpretability
Mitigating Memorization in Language Models
Vevo: Controllable Zero-Shot Voice Imitation with Self-Supervised Disentanglement
From Search to Sampling: Generative Models for Robust Algorithmic Recourse
Navigating Neural Space: Revisiting Concept Activation Vectors to Overcome Directional Divergence
Breaking Free from MMI: A New Frontier in Rationalization by Probing Input Utilization
Not All Language Model Features Are One-Dimensionally Linear
Bilinear MLPs enable weight-based mechanistic interpretability
HiBug2: Efficient and Interpretable Error Slice Discovery for Comprehensive Model Debugging
Understanding Fairness Surrogate Functions in Algorithmic Fairness
Robust Watermarking Using Generative Priors Against Image Editing: From Benchmarking to Advances
Bad-PFL: Exploiting Backdoor Attacks against Personalized Federated Learning
A Watermark for Order-Agnostic Language Models
ImpScore: A Learnable Metric For Quantifying The Implicitness Level of Sentences
ETA: Evaluating Then Aligning Safety of Vision Language Models at Inference Time
Surgical, Cheap, and Flexible: Mitigating False Refusal in Language Models via Single Vector Ablation
Glimpse: Enabling White-Box Methods to Use Proprietary Models for Zero-Shot LLM-Generated Text Detection
Dysca: A Dynamic and Scalable Benchmark for Evaluating Perception Ability of LVLMs
Policy Design in Long-run Welfare Dynamics
PAD: Personalized Alignment of LLMs at Decoding-time
Conformal Prediction Sets Can Cause Disparate Impact
Iterative Label Refinement Matters More than Preference Optimization under Weak Supervision
Can Watermarked LLMs be Identified by Users via Crafted Prompts?
Scaling Speech-Text Pre-training with Synthetic Interleaved Data
YouTube-SL-25: A Large-Scale, Open-Domain Multilingual Sign Language Parallel Corpus
SpikeGPT: Generative Pre-trained Language Model with Spiking Neural Networks
A Curious Case of the Missing Measure: Better Scores and Worse Generation
The Lottery LLM Hypothesis, Rethinking What Abilities Should LLM Compression Preserve?
Positional Embeddings in Transformer Models: Evolution from Text to Vision Domains
Improved Diffusion-based Generative Model with Better Adversarial Robustness
Discovering Temporally Compositional Neural Manifolds with Switching Infinite GPFA
Prioritized Generative Replay
KooNPro: A Variance-Aware Koopman Probabilistic Model Enhanced by Neural Process for Time Series Forecasting
STBLLM: Breaking the 1-Bit Barrier with Structured Binary LLMs
Self-Boosting Large Language Models with  Synthetic Preference Data
Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence
Language Models are Advanced Anonymizers
Temporal Flexibility in Spiking Neural Networks: Towards Generalization Across Time Steps and Deployment Friendliness
Towards Optimal Multi-draft Speculative Decoding
Vision and Language Synergy for Rehearsal Free Continual Learning
Zero-Shot Whole-Body Humanoid Control via Behavioral Foundation Models
Open-CK: A Large Multi-Physics Fields Coupling benchmarks in Combustion Kinetics
Do Egocentric Video-Language Models Truly Understand Hand-Object Interactions?
Grounding Continuous Representations in Geometry: Equivariant Neural Fields
HG-Adapter: Improving Pre-Trained Heterogeneous Graph Neural Networks with Dual Adapters
Improving Unsupervised Constituency Parsing via Maximizing Semantic Information
Geometry of Neural Reinforcement Learning in Continuous State and Action Spaces
The Foundations of Tokenization: Statistical and Computational Concerns
S4M: S4 for multivariate time series forecasting with Missing values
OPTAMI: Global Superlinear Convergence of High-order Methods
Clique Number Estimation via Differentiable Functions of Adjacency Matrix Permutations
Representation Alignment for Generation: Training Diffusion Transformers Is Easier Than You Think
Large Convolutional Model Tuning via Filter Subspace
Differentiable Integer Linear Programming
Proactive Agent: Shifting LLM Agents from Reactive Responses to Active Assistance
In Search of Forgotten Domain Generalization
MMQA: Evaluating LLMs with Multi-Table Multi-Hop Complex Questions
Interpreting the Second-Order Effects of Neurons in CLIP
Learn Your Reference Model for Real Good Alignment
VL-Cache: Sparsity and Modality-Aware KV Cache Compression for Vision-Language Model Inference Acceleration
Refine Knowledge of Large Language Models via Adaptive Contrastive Learning
Cyclic Contrastive Knowledge Transfer for Open-Vocabulary Object Detection
DAMO: Decoding by Accumulating Activations Momentum for Mitigating Hallucinations in Vision-Language Models
MetaMetrics: Calibrating Metrics for Generation Tasks Using Human Preferences
Robustness of Quantum Algorithms for Nonconvex Optimization
ReAttention: Training-Free Infinite Context with Finite Attention Scope
Towards Domain Adaptive Neural Contextual Bandits
Computational Limits of Low-Rank Adaptation (LoRA) Fine-Tuning for Transformer Models
Simplifying, Stabilizing and Scaling Continuous-time Consistency Models
STORM: Spatio-TempOral Reconstruction Model For Large-Scale Outdoor Scenes
WildBench: Benchmarking LLMs with Challenging Tasks from Real Users in the Wild
How new data permeates LLM knowledge and how to dilute it
No Pose, No Problem: Surprisingly Simple 3D Gaussian Splats from Sparse Unposed Images
FlowDec: A flow-based full-band general audio codec with high perceptual quality
ECD: A Machine Learning Benchmark for Predicting Enhanced-Precision Electronic Charge Density in Crystalline Inorganic Materials
Towards Understanding Text Hallucination of Diffusion Models via Local Generation Bias
Value-Incentivized Preference Optimization: A Unified Approach to Online and Offline RLHF
ZooProbe: A Data Engine for Evaluating, Exploring, and Evolving Large-scale Training Data for Multimodal LLMs
Physics of Language Models: Part 2.1, Grade-School Math and the Hidden Reasoning Process
On Disentangled Training for Nonlinear Transform in Learned Image Compression
Correlation and Navigation in the Vocabulary Key Representation Space of Language Models
A Theoretical Perspective: How to Prevent Model Collapse in Self-consuming Training Loops
Oracle efficient truncated statistics
HELM: Hierarchical Encoding for mRNA Language Modeling
Progressive Compositionality in Text-to-Image Generative Models
PvNeXt: Rethinking Network Design and Temporal Motion for Point Cloud Video Recognition
Second-Order Fine-Tuning without Pain for LLMs: A Hessian Informed Zeroth-Order Optimizer
Dynamic Sparse Training versus Dense Training: The Unexpected Winner in Image Corruption Robustness
DeepTAGE: Deep Temporal-Aligned Gradient Enhancement for Optimizing Spiking Neural Networks
OpenPRM: Building Open-domain Process-based Reward Models with Preference Trees
PseDet: Revisiting the Power of Pseudo Label in Incremental Object Detection
Directional Gradient Projection for Robust Fine-Tuning of Foundation Models
A Conditional Independence Test in the Presence of Discretization
PortLLM: Personalizing Evolving Large Language Models with Training-Free and Portable Model Patches
Deep Distributed Optimization for Large-Scale Quadratic Programming
SiReRAG: Indexing Similar and Related Information for Multihop Reasoning
Adaptive Batch Size for Privately Finding Second-Order Stationary Points
Building Interactable Replicas of Complex Articulated Objects via Gaussian Splatting
Noisy Test-Time Adaptation in Vision-Language Models
Rethinking the generalization of drug target affinity prediction algorithms via similarity aware evaluation
MME-RealWorld: Could Your Multimodal LLM Challenge High-Resolution Real-World Scenarios that are Difficult for Humans?
LongWriter: Unleashing 10,000+ Word Generation from Long Context LLMs
ConceptPrune: Concept Editing in Diffusion Models via Skilled Neuron Pruning
Efficient Top-m Data Values Identification for Data Selection
ANaGRAM: A Natural Gradient Relative to Adapted Model for efficient PINNs learning
Multi-modal brain encoding models for multi-modal stimuli
Learning Causal Alignment for Reliable Disease Diagnosis
Tackling Data Corruption in Offline Reinforcement Learning via Sequence Modeling
Towards a Complete Logical Framework for GNN Expressiveness
CofCA: A STEP-WISE Counterfactual Multi-hop QA benchmark
Protecting against simultaneous data poisoning attacks
ConvCodeWorld: Benchmarking Conversational Code Generation in Reproducible Feedback Environments
UniCBE: An Uniformity-driven Comparing Based Evaluation Framework with Unified Multi-Objective Optimization
Offline Model-Based Optimization by Learning to Rank
nGPT: Normalized Transformer with Representation Learning on the Hypersphere
Conditional Diffusion with Ordinal Regression: Longitudinal Data Generation for Neurodegenerative Disease Studies
Semantix: An Energy-guided Sampler for Semantic Style Transfer
Neural Spacetimes for DAG Representation Learning
SVG: 3D Stereoscopic Video Generation via Denoising Frame Matrix
Robustness Inspired Graph Backdoor Defense
Towards Neural Scaling Laws for Time Series Foundation Models
On the Modeling Capabilities of Large Language Models for Sequential Decision Making
Making Text Embedders Few-Shot Learners
Learning General-purpose Biomedical Volume Representations using Randomized Synthesis
Animate Your Thoughts: Reconstruction of Dynamic Natural Vision from Human Brain Activity
Feature Averaging: An Implicit Bias of Gradient Descent Leading to Non-Robustness in Neural Networks
CBraMod: A Criss-Cross Brain Foundation Model for EEG Decoding
Brain Bandit: A Biologically Grounded Neural Network for Efficient Control of Exploration
Meta-Dynamical State Space Models for Integrative Neural Data Analysis
Probabilistic Geometric Principal Component Analysis with application to neural data
SAM-CP: Marrying SAM with Composable Prompts for Versatile Segmentation
Redefining the task of Bioactivity Prediction
Differentiable Optimization of Similarity Scores Between Models and Brains
Brain Mapping with Dense Features: Grounding Cortical Semantic Selectivity in Natural Images With Vision Transformers
ReCogLab: a framework testing relational reasoning & cognitive hypotheses on LLMs
TOMATO: Assessing Visual Temporal Reasoning Capabilities in Multimodal Foundation Models
As large as it gets – Studying Infinitely Large Convolutions via Neural Implicit Frequency Filters
Weakly-Supervised Affordance Grounding Guided by Part-Level Semantic Priors
MIM-Refiner: A Contrastive Learning Boost from Intermediate Pre-Trained Masked Image Modeling Representations
CREMA: Generalizable and Efficient Video-Language Reasoning via Multimodal Modular Fusion
NeuralPlane: Structured 3D Reconstruction in Planar Primitives with Neural Fields
Compositional 4D Dynamic Scenes Understanding with Physics Priors for Video Question Answering
Efficient Evolutionary Search Over Chemical Space with Large Language Models
Visually Consistent Hierarchical Image Classification
Manifold Induced Biases for Zero-shot and Few-shot Detection of Generated Images
SC-OmniGS: Self-Calibrating Omnidirectional Gaussian Splatting
CityAnchor: City-scale 3D Visual Grounding with Multi-modality LLMs
ViSAGe: Video-to-Spatial Audio Generation
TetSphere Splatting: Representing High-Quality Geometry with Lagrangian Volumetric Meshes
Visual Haystacks: A Vision-Centric Needle-In-A-Haystack Benchmark
SplatFormer: Point Transformer for Robust 3D Gaussian Splatting
What Matters When Repurposing Diffusion Models for General Dense Perception Tasks?
Flow Distillation Sampling: Regularizing 3D Gaussians with Pre-trained Matching Priors
Multi-domain Distribution Learning for De Novo Drug Design
Refine-by-Align: Reference-Guided Artifacts Refinement through Semantic Alignment
Segment Any 3D Object with Language
R2Det: Exploring Relaxed Rotation Equivariance in 2D Object Detection
CogCoM: A Visual Language Model with Chain-of-Manipulations Reasoning
Graph-based Document Structure Analysis
Weakly Supervised Video Scene Graph Generation via Natural Language Supervision
Bridging Compressed Image Latents and Multimodal Large Language Models
SVBench: A Benchmark with Temporal Multi-Turn Dialogues for Streaming Video Understanding
What Makes a Maze Look Like a Maze?
Framer: Interactive Frame Interpolation
(ends 12:30 PM)
Exhibit Hall
(ends 5:30 PM)
Break:
(ends 10:30 AM)
10:30 a.m.
Oral Session 1A
[10:30-12:00]
10:30-11:42
[10:30]
Scaling LLM Test-Time Compute Optimally Can be More Effective than Scaling Parameters for Reasoning
[10:42]
MIND over Body: Adaptive Thinking using Dynamic Computation
[10:54]
Inference Scaling for Long-Context Retrieval Augmented Generation
[11:06]
miniCTX: Neural Theorem Proving with (Long-)Contexts
[11:18]
FlexPrefill: A Context-Aware Sparse Attention Mechanism for Efficient Long-Sequence Inference
[11:30]
Scaling Laws for Precision
(ends 12:00 PM)
Oral Session 1B
[10:30-12:00]
10:30-11:42
[10:30]
A Probabilistic Perspective on Unlearning and Alignment for Large Language Models
[10:42]
Turning Up the Heat: Min-p Sampling for Creative and Coherent LLM Outputs
[10:54]
BIRD: A Trustworthy Bayesian Inference Framework for Large Language Models
[11:06]
Unlocking the Power of Function Vectors for Characterizing and Mitigating Catastrophic Forgetting in Continual Instruction Tuning
[11:18]
Training on the Test Task Confounds Evaluation and Emergence
[11:30]
WizardMath: Empowering Mathematical Reasoning for Large Language Models via Reinforced Evol-Instruct
(ends 12:00 PM)
Oral Session 1C
[10:30-12:00]
10:30-11:42
[10:30]
Variational Diffusion Posterior Sampling with Midpoint Guidance
[10:42]
Progressive Compression with Universally Quantized Diffusion Models
[10:54]
Influence Functions for Scalable Data Attribution in Diffusion Models
[11:06]
Improving Probabilistic Diffusion Models With Optimal Diagonal Covariance Matching
[11:18]
Feedback Schrödinger Bridge Matching
[11:30]
Learning to Discretize Denoising Diffusion ODEs
(ends 12:00 PM)
Oral Session 1D
[10:30-12:00]
10:30-11:42
[10:30]
Towards Understanding Why FixMatch Generalizes Better Than Supervised Learning
[10:42]
Safety Alignment Should be Made More Than Just a Few Tokens Deep
[10:54]
Backtracking Improves Generation Safety
[11:06]
On the Role of Attention Heads in Large Language Model Safety
[11:18]
Booster: Tackling Harmful Fine-tuning for Large Language Models via Attenuating Harmful Perturbation
[11:30]
TANGO: Co-Speech Gesture Video Reenactment with Hierarchical Audio Motion Embedding and Diffusion Interpolation
(ends 12:00 PM)
Oral Session 1E
[10:30-12:00]
10:30-11:42
[10:30]
Wide Neural Networks Trained with Weight Decay Provably Exhibit Neural Collapse
[10:42]
Exploring The Loss Landscape Of Regularized Neural Networks Via Convex Duality
[10:54]
Global Convergence in Neural ODEs: Impact of Activation Functions
[11:06]
KAN: Kolmogorov–Arnold Networks
[11:18]
Feedback Favors the Generalization of Neural ODEs
[11:30]
On the Benefits of Memory for Modeling Time-Dependent PDEs
(ends 12:00 PM)
Oral Session 1F
[10:30-12:00]
10:30-11:42
[10:30]
Amortized Control of Continuous State Space Feynman-Kac Model for Irregular Time Series
[10:42]
Oscillatory State-Space Models
[10:54]
Unlocking State-Tracking in Linear RNNs Through Negative Eigenvalues
[11:06]
Learning stochastic dynamics from snapshots through regularized unbalanced optimal transport
[11:18]
Artificial Kuramoto Oscillatory Neurons
[11:30]
Navigating the Digital World as Humans Do: Universal Visual Grounding for GUI Agents
(ends 12:00 PM)
12:30 p.m.
Break:
Lunch Break (on your own)
(ends 2:00 PM)
Mentorship:
Mentorship Hour
(ends 1:15 PM)
Social:
TU-SOFIA
(ends 2:00 PM)
Social:
Birds of a Feather Session: "Towards tokenizer-free, end-to-end architectures"
(ends 2:00 PM)
Social:
AI for Mathematics and Theorem Proving
(ends 2:00 PM)
Social:
LLMs in the Public Sector
(ends 2:00 PM)
1 p.m.
Expo Talk Panel:
Beyond Chain-of-Thought: Towards Autonomous Knowledge Management in Alibaba Cloud Tongyi Agentic Systems
(ends 2:00 PM)
Expo Talk Panel:
Agent research in the real world
(ends 2:00 PM)
Expo Talk Panel:
Ant-InclusionAI: A Fully Open-Sourced Project for LLMs from RL Reasoning to Agents
(ends 2:00 PM)
1:15 p.m.
Mentorship:
Mentorship Hour
(ends 2:00 PM)
2 p.m.
Invited Talk:
Framework, Prototype, Definition and Benchmark
Song-Chun Zhu
(ends 3:00 PM)
Invited Talk:
Overflow: Framework, Prototype, Definition and Benchmark
Song-Chun Zhu
(ends 3:00 PM)
3 p.m.
Poster Session 2
[3:00-5:30]
Poster
3:00-5:30
Stiefel Flow Matching for Moment-Constrained Structure Elucidation
Contextualizing biological perturbation experiments through language
Action Sequence Augmentation for Action Anticipation
Enhancing End-to-End Autonomous Driving with Latent World Model
Robust-PIFu: Robust Pixel-aligned Implicit Function for 3D Human Digitalization from a Single Image
LIFe-GoM: Generalizable Human Rendering with Learned Iterative Feedback Over Multi-Resolution Gaussians-on-Mesh
GI-GS: Global Illumination Decomposition on Gaussian Splatting for Inverse Rendering
DenseGrounding: Improving Dense Language-Vision Semantics for Ego-centric 3D Visual Grounding
AVHBench: A Cross-Modal Hallucination Benchmark for Audio-Visual Large Language Models
TempMe: Video Temporal Token Merging for Efficient Text-Video Retrieval
NeRAF: 3D Scene Infused Neural Radiance and Acoustic Fields
TEOChat: A Large Vision-Language Assistant for Temporal Earth Observation Data
MuirBench: A Comprehensive Benchmark for Robust Multi-image Understanding
Neuralized Markov Random Field for Interaction-Aware Stochastic Human Trajectory Prediction
Implicit Neural Surface Deformation with Explicit Velocity Fields
SV4D: Dynamic 3D Content Generation with Multi-Frame and Multi-View Consistency
AuroraCap: Efficient, Performant Video Detailed Captioning and a New Benchmark
Memory Efficient Transformer Adapter for Dense Predictions
DisEnvisioner: Disentangled and Enriched Visual Prompt for Customized Image Generation
AdaIR: Adaptive All-in-One Image Restoration via Frequency Mining and Modulation
UniRestore3D: A Scalable Framework For General Shape Restoration
SimulPL: Aligning Human Preferences in Simultaneous Machine Translation
AutoBencher: Towards Declarative Benchmark Construction
MAESTRO: Masked Encoding Set Transformer with Self-Distillation
A Non-Contrastive Learning Framework for Sequential Recommendation with Preference-Preserving Profile Generation
AnalogGenie: A Generative Engine for Automatic Discovery of Analog Circuit Topologies
Noise Stability Optimization for Finding Flat Minima: A Hessian-based Regularization Approach
MotherNet: Fast Training and Inference via Hyper-Network Transformers
Implicit Search via Discrete Diffusion: A Study on Chess
Reveal Object in Lensless Photography via Region Gaze and Amplification
IDInit: A Universal and Stable Initialization Method for Neural Network Training
Asymmetric Factorized Bilinear Operation for Vision Transformer
Smoothing the Shift: Towards Stable Test-Time Adaptation under Complex Multimodal Noises
Learning stochastic dynamics from snapshots through regularized unbalanced optimal transport
ELFS: Label-Free Coreset Selection with Proxy Training Dynamics
kNN Attention Demystified: A Theoretical Exploration for Scalable Transformers
Class Distribution-induced Attention Map for Open-vocabulary Semantic Segmentations
Fundamental Limitations on Subquadratic Alternatives to Transformers
VD3D: Taming Large Video Diffusion Transformers for 3D Camera Control
RTop-K: Ultra-Fast Row-Wise Top-K Selection for Neural Network Acceleration on GPUs
GenXD: Generating Any 3D and 4D Scenes
BiGR: Harnessing Binary Latent Codes for Image Generation and Improved Visual Representation Capabilities
Flow matching achieves almost minimax optimal convergence
Trajectory attention for fine-grained video motion control
Learning system dynamics without forgetting
Free Hunch: Denoiser Covariance Estimation for Diffusion Models Without Extra Costs
Manifold Constraint Reduces Exposure Bias in Accelerated Diffusion Sampling
Training Free Guided Flow-Matching with Optimal Control
Variational Diffusion Posterior Sampling with Midpoint Guidance
How Discrete and Continuous Diffusion Meet: Comprehensive Analysis of Discrete Diffusion Models  via a Stochastic Integral Framework
GameGen-X: Interactive Open-world Game Video Generation
Generating  Graphs  via Spectral Diffusion
PRISM: Privacy-Preserving Improved Stochastic Masking for Federated Generative Models
Bias Mitigation in Graph Diffusion Models
MIND over Body: Adaptive Thinking using Dynamic Computation
Interpretable Vision-Language Survival Analysis with Ordinal Inductive Bias for Computational Pathology
Meissonic: Revitalizing Masked Generative Transformers for Efficient High-Resolution Text-to-Image Synthesis
Presto! Distilling Steps and Layers for Accelerating Music Generation
Guided Score identity Distillation for Data-Free One-Step Text-to-Image Generation
HGM³: Hierarchical Generative Masked Motion Modeling with Hard Token Mining
GALA: Geometry-Aware Local Adaptive Grids for Detailed 3D Generation
DynamicCity: Large-Scale 4D Occupancy Generation from Dynamic Scenes
SWE-Search: Enhancing Software Agents with Monte Carlo Tree Search and Iterative Refinement
Text-to-Image Rectified Flow as Plug-and-Play Priors
AvatarGO: Zero-shot 4D Human-Object Interaction Generation and Animation
InstantSwap: Fast Customized Concept Swapping across Sharp Shape Differences
Synthesizing Realistic fMRI: A Physiological Dynamics-Driven Hierarchical Diffusion Model for Efficient fMRI Acquisition
PivotMesh: Generic 3D Mesh Generation via Pivot Vertices Guidance
Improved Sampling Algorithms for Lévy-Itô Diffusion Models
TopoDiffusionNet: A Topology-aware Diffusion Model
Add-it: Training-Free Object Insertion in Images With Pretrained Diffusion Models
MotionClone: Training-Free Motion Cloning for Controllable Video Generation
A Geometric Framework for Understanding Memorization in Generative Models
A Large-scale Training Paradigm for Graph Generative Models
Flash Inference: Near Linear Time Inference for Long Convolution Sequence Models and Beyond
Controlling Space and Time with Diffusion Models
BoneMet: An Open Large-Scale Multi-Modal Murine Dataset for Breast Cancer Bone Metastasis Diagnosis and Prognosis
TD-Paint: Faster Diffusion Inpainting Through Time-Aware Pixel Conditioning
Controllable Satellite-to-Street-View Synthesis with Precise Pose Alignment and Zero-Shot Environmental Control
Improving Probabilistic Diffusion Models With Optimal Diagonal Covariance Matching
FIG: Flow with Interpolant Guidance for Linear Inverse Problems
Build-A-Scene: Interactive 3D Layout Control for Diffusion-Based Image Generation
Score Forgetting Distillation: A Swift, Data-Free Method for Machine Unlearning in Diffusion Models
MixEval-X: Any-to-any Evaluations from Real-world Data Mixture
An Undetectable Watermark for Generative Image Models
Circuit Transformer: A Transformer That Preserves Logical Equivalence
PT-T2I/V: An Efficient Proxy-Tokenized Diffusion Transformer for Text-to-Image/Video-Task
ParFam -- (Neural Guided) Symbolic Regression via Continuous Global Optimization
TIGeR: Unifying Text-to-Image Generation and Retrieval with Large Multimodal Models
Rectified Diffusion: Straightness Is Not Your Need in Rectified Flow
Counterfactual Generative Modeling with Variational Causal Inference
Global Well-posedness and Convergence Analysis of Score-based Generative Models via Sharp Lipschitz Estimates
Enhanced Diffusion Sampling via Extrapolation with Multiple ODE Solutions
Efficient Masked AutoEncoder for Video Object Counting and A Large-Scale Benchmark
TabDiff: a Mixed-type Diffusion Model for Tabular Data Generation
ElasticTok: Adaptive Tokenization for Image and Video
PeriodWave: Multi-Period Flow Matching for High-Fidelity Waveform Generation
SG-I2V: Self-Guided Trajectory Control in Image-to-Video Generation
GridMix: Exploring Spatial Modulation for Neural Fields in PDE Modeling
Test-time Alignment of Diffusion Models without Reward Over-optimization
Advancing Graph Generation through Beta Diffusion
Learning to Discretize Denoising Diffusion ODEs
Discrete Distribution Networks
MaRS: A Fast Sampler for Mean Reverting Diffusion based on ODE and SDE Solvers
Normed Spaces for Graph Embedding
Fully-inductive Node Classification on Arbitrary Graphs
GotenNet: Rethinking Efficient 3D Equivariant Graph Neural Networks
Towards Explaining the Power of Constant-depth Graph Neural Networks for Structured Linear Programming
MANTRA: The Manifold Triangulations Assemblage
Learning Molecular Representation in a Cell
Continuity-Preserving  Convolutional Autoencoders for Learning Continuous Latent Dynamical Models from Images
Biologically Plausible Brain Graph Transformer
Learning to Explore and Exploit with GNNs for Unsupervised Combinatorial Optimization
K-HALU: Multiple Answer Korean Hallucination Benchmark for Large Language Models
Navigating the Digital World as Humans Do: Universal Visual Grounding for GUI Agents
AgentSquare: Automatic LLM Agent Search in Modular Design Space
Factual Context Validation and Simplification: A Scalable Method to Enhance GPT Trustworthiness and Efficiency
In Search of the Engram in LLMs: A Neuroscience Perspective on the Memory Functions in AI Models
Weak-to-Strong Preference Optimization: Stealing Reward from Weak Aligned Model
Aligning Language Models with Demonstrated Feedback
Learning to Contextualize Web Pages for Enhanced Decision Making by LLM Agents
Predicting the Energy Landscape of Stochastic Dynamical System via  Physics-informed Self-supervised Learning
UniCoTT: A Unified Framework for Structural Chain-of-Thought Distillation
Instruct-SkillMix: A Powerful Pipeline for LLM Instruction Tuning
Scaling LLM Test-Time Compute Optimally Can be More Effective than Scaling Parameters for Reasoning
A Probabilistic Perspective on Unlearning and Alignment for Large Language Models
RegMix: Data Mixture as Regression for Language Model Pre-training
GraphEval: A Lightweight Graph-Based LLM Framework for Idea Evaluation
You Only Prune Once: Designing Calibration-Free Model Compression With Policy Learning
Painting with Words: Elevating Detailed Image Captioning with Benchmark and Alignment Learning
GeoX: Geometric Problem Solving Through Unified Formalized Vision-Language Pre-training
Learning How Hard to Think: Input-Adaptive Allocation of LM Computation
Real-time design of architectural structures with differentiable mechanics and neural networks
CoTFormer: A Chain of Thought Driven Architecture with Budget-Adaptive Computation Cost at Inference
Do WGANs succeed because they minimize the Wasserstein Distance? Lessons from Discrete Generators
Guaranteed Generation from Large Language Models
SqueezeAttention: 2D Management of KV-Cache in LLM Inference via Layer-wise Optimal Budget
Mixture of Parrots: Experts improve memorization more than reasoning
Conformal Language Model Reasoning with Coherent Factuality
LLaMaFlex: Many-in-one LLMs via Generalized Pruning and Weight Sharing
Mix-LN: Unleashing the Power of Deeper Layers by Combining Pre-LN and Post-LN
MatryoshkaKV: Adaptive KV Compression via Trainable Orthogonal Projection
PhyMPGN: Physics-encoded Message Passing Graph Network for spatiotemporal PDE systems
Can LLMs Solve Longer Math Word Problems Better?
Innovative Thinking, Infinite Humor: Humor Research of Large Language Models through Structured Thought Leaps
ELICIT: LLM Augmentation Via External In-context Capability
Estimating the Probabilities of Rare Outputs in Language Models
OATS: Outlier-Aware Pruning Through Sparse and Low Rank Decomposition
Jailbreaking as a Reward Misspecification Problem
Evaluating Large Language Models through Role-Guide and Self-Reflection: A Comparative Study
Turning Up the Heat: Min-p Sampling for Creative and Coherent LLM Outputs
AgentRefine: Enhancing Agent Generalization through Refinement Tuning
Inference Scaling for Long-Context Retrieval Augmented Generation
Learning a Neural Solver for Parametric PDEs to Enhance Physics-Informed Methods
EmbedLLM: Learning Compact Representations of Large Language Models
SMT: Fine-Tuning Large Language Models with Sparse Matrices
StructRAG: Boosting Knowledge Intensive Reasoning of LLMs via Inference-time Hybrid Information Structurization
Rethinking Evaluation of Sparse Autoencoders through the Representation of Polysemous Words
Super(ficial)-alignment: Strong Models May Deceive Weak Models in Weak-to-Strong Generalization
Intelligence at the Edge of Chaos
Active Task Disambiguation with LLMs
From Models to Microtheories: Distilling a Model's Topical Knowledge for Grounded Question-Answering
miniCTX: Neural Theorem Proving with (Long-)Contexts
Agent Skill Acquisition for Large Language Models via CycleQD
Learning the Complexity of Weakly Noisy Quantum States
Adapters for Altering LLM Vocabularies: What Languages Benefit the Most?
Palu: KV-Cache Compression with Low-Rank Projection
Cut the Crap: An Economical Communication Pipeline for LLM-based Multi-Agent Systems
AdaRankGrad: Adaptive Gradient Rank and Moments for Memory-Efficient LLMs Training and Fine-Tuning
Style Outweighs Substance: Failure Modes of LLM Judges in Alignment Benchmarking
Maintaining Structural Integrity in Parameter Spaces for Parameter Efficient Fine-tuning
Oryx MLLM: On-Demand Spatial-Temporal Understanding at Arbitrary Resolution
B-STaR: Monitoring and Balancing Exploration and Exploitation in Self-Taught Reasoners
Magnetic Preference Optimization: Achieving Last-iterate Convergence for Language Model Alignment
Unlocking Efficient, Scalable, and Continual Knowledge Editing with Basis-Level Representation Fine-Tuning
Dream to Manipulate: Compositional World Models Empowering Robot Imitation Learning with Imagination
Progress or Regress? Self-Improvement Reversal in Post-training
Can We Trust Embodied Agents? Exploring Backdoor Attacks against Embodied LLM-Based Decision-Making Systems
Is In-Context Learning Sufficient for Instruction Following in LLMs?
KOR-Bench: Benchmarking Language Models on Knowledge-Orthogonal Reasoning Tasks
Learning Harmonized Representations for Speculative Sampling
VLM2Vec: Training Vision-Language Models for Massive Multimodal Embedding Tasks
HShare: Fast LLM Decoding by Hierarchical Key-Value Sharing
MMAU: A Massive Multi-Task Audio Understanding and Reasoning Benchmark
L3Ms — Lagrange Large Language Models
Exploring the Design Space of Visual Context Representation in Video MLLMs
Intent3D: 3D Object Detection in RGB-D Scans Based on Human Intention
Trajectory-LLM: A Language-based Data Generator for Trajectory Prediction in Autonomous Driving
McEval: Massively Multilingual Code Evaluation
Unlocking State-Tracking in Linear RNNs Through Negative Eigenvalues
Fictitious Synthetic Data Can Improve LLM Factuality via Prerequisite Learning
Don't Take Things Out of Context: Attention Intervention for Enhancing Chain-of-Thought Reasoning in Large Language Models
Variational Best-of-N Alignment
Scaling up Masked Diffusion Models on Text
Scaling Optimal LR Across Token Horizons
ARB-LLM: Alternating Refined Binarizations for Large Language Models
Global Convergence of Policy Gradient in Average Reward MDPs
ManiSkill-HAB: A Benchmark for Low-Level Manipulation in Home Rearrangement Tasks
TLDR: Token-Level Detective Reward Model for Large Vision Language Models
Self-Updatable Large Language Models by Integrating Context into Model Parameters
Intelligent Go-Explore: Standing on the Shoulders of Giant Foundation Models
MR-GSM8K: A Meta-Reasoning Benchmark for Large Language Model Evaluation
Are Large Vision Language Models Good Game Players?
ChatQA 2: Bridging the Gap to Proprietary LLMs in Long Context and RAG Capabilities
TC-MoE: Augmenting Mixture of Experts with Ternary Expert Choice
CBQ: Cross-Block Quantization for Large Language Models
The Rise and Down of Babel Tower: Investigating the Evolution Process of Multilingual Code Large Language Model
Unlearning or Obfuscating? Jogging the Memory of Unlearned LLMs via Benign Relearning
Direct Post-Training Preference Alignment for Multi-Agent Motion Generation Model Using Implicit Feedback from Pre-training Demonstrations
OptiBench Meets ReSocratic: Measure and Improve LLMs for Optimization Modeling
ADePT: Adaptive Decomposed Prompt Tuning for Parameter-Efficient Fine-tuning
Unlocking the Power of Function Vectors for Characterizing and Mitigating Catastrophic Forgetting in Continual Instruction Tuning
Basis Sharing: Cross-Layer Parameter Sharing for Large Language Model Compression
On the Role of Attention Heads in Large Language Model Safety
Training on the Test Task Confounds Evaluation and Emergence
Neural Phylogeny: Fine-Tuning Relationship Detection among Neural Networks
INCLUDE: Evaluating Multilingual Language Understanding with Regional Knowledge
Semantic Loss Guided Data Efficient Supervised Fine Tuning for Safe Responses in LLMs
Ensembles of Low-Rank Expert Adapters
Bayesian Optimization of Antibodies Informed by a Generative Model of Evolving Sequences
EMOS: Embodiment-aware Heterogeneous Multi-robot Operating System with LLM Agents
HMoRA: Making LLMs More Effective with Hierarchical Mixture of LoRA Experts
From Isolated Conversations to Hierarchical Schemas: Dynamic Tree Memory Representation for LLMs
Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG
Large (Vision) Language Models are Unsupervised In-Context Learners
No Need to Talk: Asynchronous Mixture of Language Models
Diverse Preference Learning for Capabilities and Alignment
VCR: A Task for Pixel-Level Complex Reasoning in Vision Language Models via Restoring Occluded Text
Your Weak LLM is Secretly a Strong Teacher for Alignment
Perturbation-Restrained Sequential Model Editing
MiniPLM: Knowledge Distillation for Pre-training Language Models
BaB-ND: Long-Horizon Motion Planning with Branch-and-Bound and Neural Dynamics
SeedLM: Compressing LLM Weights into Seeds of Pseudo-Random Generators
MMKE-Bench: A Multimodal Editing Benchmark for Diverse Visual Knowledge
KiVA: Kid-inspired Visual Analogies for Testing Large Multimodal Models
Benchmarking Agentic Workflow Generation
Needle Threading: Can LLMs Follow Threads Through Near-Million-Scale Haystacks?
Inspection and Control of Self-Generated-Text Recognition Ability in Llama3-8b-Instruct
Scaling Laws for Precision
Better autoregressive regression with LLMs via regression-aware fine-tuning
EIA: ENVIRONMENTAL INJECTION ATTACK ON GENERALIST WEB AGENTS FOR PRIVACY LEAKAGE
To Code or Not To Code? Exploring Impact of Code in Pre-training
Think Then React: Towards Unconstrained Action-to-Reaction Motion Generation
On the Fourier analysis in the SO(3) space : the EquiLoPO Network
Identification of Intermittent Temporal Latent Process
Probabilistic Language-Image Pre-Training
INFER: A Neural-symbolic Model For Extrapolation Reasoning on Temporal Knowledge Graph
Multiplicative Logit Adjustment Approximates Neural-Collapse-Aware Decision Boundary Adjustment
CtD: Composition through Decomposition in Emergent Communication
NUDGE: Lightweight Non-Parametric Fine-Tuning of Embeddings for Retrieval
Advancing Prompt-Based Methods for Replay-Independent General Continual Learning
Can We Talk Models Into Seeing the World Differently?
ESE: Espresso Sentence Embeddings
Navigation-Guided Sparse Scene Representation for End-to-End Autonomous Driving
Language Models Need Inductive Biases to Count Inductively
BRIGHT: A Realistic and Challenging Benchmark for Reasoning-Intensive Retrieval
Democratic Training Against Universal Adversarial Perturbations
Verifying Properties of Binary Neural Networks Using Sparse Polynomial Optimization
Severing Spurious Correlations with Data Pruning
Backtracking Improves Generation Safety
Beyond correlation: The impact of human uncertainty in measuring the effectiveness of automatic evaluation and LLM-as-a-judge
Adversaries With Incentives:  A Strategic Alternative to Adversarial Robustness
Robust Representation Consistency Model via Contrastive Denoising
Certified Robustness Under Bounded Levenshtein Distance
COMBO: Compositional World Models for Embodied Multi-Agent Cooperation
Provably Safeguarding a Classifier from OOD and Adversarial Samples
Shifting the Paradigm: A Diffeomorphism Between Time Series Data Manifolds for Achieving Shift-Invariancy in Deep Learning
The Journey Matters: Average Parameter Count over Pre-training Unifies Sparse and Dense Scaling Laws
Provable Robust Overfitting Mitigation in Wasserstein Distributionally Robust Optimization
Zero-cost Proxy for Adversarial Robustness Evaluation
Towards Understanding Why FixMatch Generalizes Better Than Supervised Learning
Risk-Sensitive Diffusion: Robustly Optimizing Diffusion Models with Noisy Samples
Learning Video-Conditioned Policy on Unlabelled Data with Joint Embedding Predictive Transformer
Wide Neural Networks Trained with Weight Decay Provably Exhibit Neural Collapse
Make Haste Slowly: A Theory of Emergent Structured Mixed Selectivity in Feature Learning ReLU Networks
TraceVLA: Visual Trace Prompting Enhances Spatial-Temporal Awareness for Generalist Robotic Policies
Exploring The Loss Landscape Of Regularized Neural Networks Via Convex Duality
Bayesian Treatment of the Spectrum of the Empirical Kernel in (Sub)Linear-Width Neural Networks
How DNNs break the Curse of Dimensionality: Compositionality and Symmetry Learning
Generalization, Expressivity, and Universality of Graph Neural Networks on Attributed Graphs
Oscillatory State-Space Models
Towards a General Time Series Anomaly Detector with Adaptive Bottlenecks and Dual Adversarial Decoders
Making Transformer Decoders Better Differentiable Indexers
In-context Time Series Predictor
Towards Learning High-Precision Least Squares Algorithms with Sequence Models
Preference Diffusion for Recommendation
MetaUrban: An Embodied AI Simulation Platform for Urban Micromobility
Two Sparse Matrices are Better than One: Sparsifying Neural Networks with Double Sparse Factorization
P-SPIKESSM: HARNESSING PROBABILISTIC SPIKING STATE SPACE MODELS FOR LONG-RANGE DEPENDENCY TASKS
Deep Learning Alternatives Of The Kolmogorov Superposition Theorem
Youku Dense Caption: A Large-scale Chinese Video Dense Caption Dataset and Benchmarks
Designing Concise ConvNets with Columnar Stages
Learning to Solve Differential Equation Constrained Optimization Problems
Sharpness-Aware Minimization: General Analysis and Improved Rates
qNBO: quasi-Newton Meets Bilevel Optimization
Non-Equilibrium Dynamics of Hybrid Continuous-Discrete Ground-State Sampling
Linear Mode Connectivity in Differentiable Tree Ensembles
GravMAD: Grounded Spatial Value Maps Guided Action Diffusion for Generalized 3D Manipulation
Complexity Lower Bounds of Adaptive Gradient Algorithms for Non-convex Stochastic Optimization under Relaxed Smoothness
AdaFisher: Adaptive Second Order Optimization via Fisher Information
LancBiO: Dynamic Lanczos-aided Bilevel Optimization via Krylov Subspace
Group Distributionally Robust Dataset Distillation with Risk Minimization
Improved Approximation Algorithms for $k$-Submodular Maximization via Multilinear Extension
Efficient and Robust Neural Combinatorial Optimization via Wasserstein-Based Coresets
SFESS: Score Function Estimators for $k$-Subset Sampling
ZIP: An Efficient Zeroth-order Prompt Tuning for Black-box Vision-Language Models
Revisiting Zeroth-Order Optimization:  Minimum-Variance Two-Point Estimators and  Directionally Aligned Perturbations
Learning to Help in Multi-Class Settings
ThinkBot: Embodied Instruction Following with Thought Chain Reasoning
From Promise to Practice: Realizing High-performance Decentralized Training
EDiT: A Local-SGD-Based Efficient Distributed Training Method for Large Language Models
A Tight Convergence Analysis of Inexact Stochastic Proximal Point Algorithm for Stochastic Composite Optimization Problems
Joint Gradient Balancing for Data Ordering in Finite-Sum Multi-Objective Optimization
Scrutinize What We Ignore: Reining In Task Representation Shift Of Context-Based Offline Meta Reinforcement Learning
Value-aligned Behavior Cloning for Offline Reinforcement Learning via Bi-level Optimization
Model Risk-sensitive Offline Reinforcement Learning
ACTIVE: Offline Reinforcement Learning via Adaptive Imitation and In-sample $V$-Ensemble
Learning on One Mode: Addressing Multi-modality in Offline Reinforcement Learning
PEAR: Primitive Enabled Adaptive Relabeling for Boosting Hierarchical Reinforcement Learning
Learning under Temporal Label Noise
BlendRL: A Framework for Merging Symbolic and Neural Policy Learning
Drama: Mamba-Enabled Model-Based Reinforcement Learning Is Sample and Parameter Efficient
Prevalence of Negative Transfer in Continual Reinforcement Learning: Analyses and a Simple Baseline
Policy Optimization under Imperfect Human Interactions with Agent-Gated Shared Autonomy
SmartRAG: Jointly Learn RAG-Related Tasks From the Environment Feedback
VICtoR: Learning Hierarchical Vision-Instruction Correlation Rewards for Long-horizon Manipulation
SimBa: Simplicity Bias for Scaling Up Parameters in Deep Reinforcement Learning
Adaptive $Q$-Network: On-the-fly Target Selection for Deep Reinforcement Learning
Reward Dimension Reduction for Scalable Multi-Objective Reinforcement Learning
Understanding Constraint Inference in Safety-Critical Inverse Reinforcement Learning
A Periodic Bayesian Flow for Material Generation
Specialized Foundation Models Struggle to Beat Supervised Baselines
Efficient Imitation under Misspecification
Learning to Steer Markovian Agents under Model Uncertainty
MA$^2$E: Addressing Partial Observability in Multi-Agent Reinforcement Learning with Masked Auto-Encoder
DOPL: Direct Online Preference Learning for Restless Bandits with Preference Feedback
Efficient Action-Constrained Reinforcement Learning via Acceptance-Rejection Method and Augmented MDPs
Empowering LLM Agents with Zero-Shot Optimal Decision-Making through Q-learning
From an LLM Swarm to a PDDL-empowered Hive: Planning Self-executed Instructions in a Multi-modal Jungle
HASARD: A Benchmark for Vision-Based Safe Reinforcement Learning in Embodied Agents
Asynchronous Federated Reinforcement Learning with Policy Gradient Updates: Algorithm Design and Convergence Analysis
VVC-Gym: A Fixed-Wing UAV Reinforcement Learning Environment for Multi-Goal Long-Horizon Problems
Learning the Optimal Stopping for Early Classification within Finite Horizons via Sequential Probability Ratio Test
Reward Learning from Multiple Feedback Types
Execution-guided within-prompt search for programming-by-example
A Distributional Approach to Uncertainty-Aware Preference Alignment Using Offline Demonstrations
Process Reward Model with Q-value Rankings
KLay: Accelerating Arithmetic Circuits for Neurosymbolic AI
Dimension Agnostic Neural Processes
Optimistic Games for Combinatorial Bayesian Optimization with Application to Protein Design
Models trained with unnormalized density functions: A need for a course correction
Fast training and sampling of Restricted Boltzmann Machines
Amortized Control of Continuous State Space Feynman-Kac Model for Irregular Time Series
Zero-shot forecasting of chaotic systems
Provable Benefit of Annealed Langevin Monte Carlo for Non-log-concave Sampling
Learned Reference-based Diffusion Sampler for multi-modal distributions
BioDiscoveryAgent: An AI Agent for Designing Genetic Perturbation Experiments
MedTrinity-25M: A Large-scale Multimodal Dataset with Multigranular Annotations for Medicine
Rare event modeling with self-regularized normalizing flows: what can we learn from a single failure?
Probabilistic Neural Pruning via Sparsity Evolutionary Fokker-Planck-Kolmogorov Equation
Stochastic variance-reduced Gaussian variational inference on the Bures-Wasserstein manifold
Risk-Controlling Model Selection via Guided Bayesian Optimization
Towards Understanding Why Label Smoothing Degrades Selective Classification and How to Fix It
Action abstractions for amortized sampling
MuPT: A Generative Symbolic Music Pretrained Transformer
Benchmarking Predictive Coding Networks -- Made Simple
Unified Convergence Analysis for Score-Based Diffusion Models with Deterministic Samplers
The Hyperfitting Phenomenon: Sharpening and Stabilizing LLMs for Open-Ended Text Generation
On the Optimal Memorization Capacity of Transformers
The impact of allocation strategies in subset learning on the expressive power of neural networks
Quantitative Approximation for Neural Operators in Nonlinear Parabolic Equations
What Has Been Overlooked in Contrastive Source-Free Domain Adaptation: Leveraging Source-Informed Latent Augmentation within Neighborhood Context
Efficient and Context-Aware Label Propagation for Zero-/Few-Shot Training-Free Adaptation of Vision-Language Model
Single-agent Poisoning Attacks Suffice to Ruin Multi-Agent Learning
Rethinking Shapley Value for Negative Interactions in Non-convex Games
DiTTo-TTS: Diffusion Transformers for Scalable Text-to-Speech without Domain-Specific Factors
Data Mixing Laws: Optimizing Data Mixtures by Predicting Language Modeling Performance
When does compositional structure yield compositional generalization? A kernel theory.
Geometry of Long-Tailed Representation Learning: Rebalancing Features for Skewed Distributions
The Computational Complexity of Positive Non-Clashing Teaching in Graphs
Distribution-Specific Agnostic Conditional Classification With Halfspaces
ONLINE EPSILON NET & PIERCING SET FOR GEOMETRIC CONCEPTS
Analyzing Neural Scaling Laws in Two-Layer Networks with Power-Law Data Spectra
On the Price of Differential Privacy for Hierarchical Clustering
Non-Stationary Dueling Bandits Under a Weighted Borda Criterion
uniINF: Best-of-Both-Worlds Algorithm for Parameter-Free Heavy-Tailed MABs
Divide and Translate: Compositional First-Order Logic Translation and Verification for Complex Logical Reasoning
Online Clustering with Nearly Optimal Consistency
Stochastic Bandits Robust to Adversarial Attacks
DUET: Decentralized Bilevel Optimization without Lower-Level Strong Convexity
Do Stochastic, Feel Noiseless: Stable Stochastic Optimization via a Double Momentum Mechanism
Progressive Compression with Universally Quantized Diffusion Models
Convergence of Score-Based Discrete Diffusion Models: A Discrete-Time Analysis
Behavioral Entropy-Guided Dataset Generation for Offline Reinforcement Learning
Temporal Difference Learning: Why It Can Be Fast and How It Will Be Faster
Robustness Auditing for Linear Regression: To Singularity and Beyond
Causal Order: The Key to Leveraging Imperfect Experts in Causal Inference
Not All Heads Matter: A Head-Level KV Cache Compression Method with Integrated Retrieval and Reasoning
From Probability to Counterfactuals: the Increasing Complexity of Satisfiability in Pearl's Causal Hierarchy
Deriving Causal Order from Single-Variable Interventions: Guarantees & Algorithm
KAN: Kolmogorov–Arnold Networks
Dist Loss: Enhancing Regression in Few-Shot Region through Distribution Distance Constraint
Symbolic regression via MDLformer-guided search: from minimizing prediction error to minimizing description length
Multiview Equivariance Improves 3D Correspondence Understanding with Minimal Feature Finetuning
Supervised and Semi-Supervised Diffusion Maps with Label-Driven Diffusion
VisualPredicator: Learning Abstract World Models with Neuro-Symbolic Predicates for Robot Planning
SyllableLM: Learning Coarse Semantic Units for Speech Language Models
Artificial Kuramoto Oscillatory Neurons
Agents' Room:  Narrative Generation through Multi-step Collaboration
Group Downsampling with Equivariant Anti-aliasing
An Illustrated Guide to Automatic Sparse Differentiation
On the Feature Learning in Diffusion Models
Test-time Adaptation for Cross-modal Retrieval with Query Shift
Pursuing Feature Separation based on Neural Collapse for Out-of-Distribution Detection
Tree-Wasserstein Distance for High Dimensional Data with a Latent Feature Hierarchy
Content-Style Learning from Unaligned Domains: Identifiability under Unknown Latent Dimensions
An Online Learning Theory of Trading-Volume Maximization
Feedback Favors the Generalization of Neural ODEs
Selective Label Enhancement Learning for Test-Time Adaptation
SoftMatcha: A Soft and Fast Pattern Matcher for Billion-Scale Corpus Searches
Unsupervised Meta-Learning via In-Context Learning
A Second-Order Perspective on Model Compositionality and Incremental Learning
Efficient Model Editing with Task-Localized Sparse Fine-tuning
Swiss Army Knife: Synergizing Biases in Knowledge from Vision Foundation Models for Multi-Task Learning
Black Sheep in the Herd: Playing with Spuriously Correlated Attributes for Vision-Language Recognition
Towards Robust Multimodal Open-set Test-time Adaptation via Adaptive Entropy-aware Optimization
LeanVec: Searching vectors faster by making them fit
Towards Robust and Parameter-Efficient Knowledge Unlearning for LLMs
An Efficient Framework for Crediting Data Contributors of Diffusion Models
Comparing Targeting Strategies for Maximizing Social Welfare with Limited Resources
Multi-Task Corrupted Prediction for Learning Robust Audio-Visual Speech Representation
CollabEdit: Towards Non-destructive Collaborative Knowledge Editing
Measuring Non-Adversarial Reproduction of Training Data in Large Language Models
Optimality of Matrix Mechanism on $\ell_p^p$-metric
TDDBench: A Benchmark for Training data detection
Encryption-Friendly LLM Architecture
Dataset Ownership Verification in Contrastive Pre-trained Models
Open Problems and Fundamental Limitations of Reinforcement Learning from Human Feedback
REFINE: Inversion-Free Backdoor Defense via Model Reprogramming
Towards Understanding the Universality of Transformers for Next-Token Prediction
Start Smart: Leveraging Gradients For Enhancing Mask-based XAI Methods
CryoFM: A Flow-based Foundation Model for Cryo-EM Densities
Continuous Autoregressive Modeling with Stochastic Monotonic Alignment for Speech Synthesis
On the Adversarial Vulnerability of Label-Free Test-Time Adaptation
Provable Uncertainty Decomposition via Higher-Order Calibration
On Evaluating the Durability of Safeguards for Open-Weight LLMs
Provably Robust Explainable Graph Neural Networks against Graph Perturbation Attacks
Latent Space Chain-of-Embedding Enables Output-free LLM Self-Evaluation
Predictive Uncertainty Quantification for Bird's Eye View Segmentation: A Benchmark and Novel Loss Function
Convergent Privacy Loss of Noisy-SGD without Convexity and Smoothness
Adversarial Machine Unlearning
Booster: Tackling Harmful Fine-tuning for Large Language Models via Attenuating Harmful Perturbation
Enhancing Uncertainty Estimation and Interpretability with Bayesian Non-negative Decision Layer
RFWave: Multi-band Rectified Flow for Audio Waveform Reconstruction
Efficient Automated Circuit Discovery in Transformers using Contextual Decomposition
Explain Yourself, Briefly! Self-Explaining Neural Networks with Concise Sufficient Reasons
Restyling Unsupervised Concept Based Interpretable Networks with Generative Models
Controllable Context Sensitivity and the Knob Behind It
GMValuator: Similarity-based Data Valuation for Generative Models
Influence Functions for Scalable Data Attribution in Diffusion Models
Beyond Surface Structure: A Causal Assessment of LLMs' Comprehension ability
Explanations of GNN on Evolving Graphs via Axiomatic  Layer edges
Explaining Modern Gated-Linear RNNs via a Unified Implicit Attention Formulation
OmnixR: Evaluating Omni-modality Language Models on Reasoning across Modalities
AgentHarm: A Benchmark for Measuring Harmfulness of LLM Agents
Can a Large Language Model be a Gaslighter?
Durable Quantization Conditioned Misalignment Attack on Large Language Models
MMFakeBench: A Mixed-Source Multimodal Misinformation Detection Benchmark for LVLMs
Towards counterfactual fairness through auxiliary variables
Humanizing the Machine: Proxy Attacks to Mislead LLM Detectors
Strong Preferences Affect the Robustness of Preference Models and Value Alignment
FairDen: Fair Density-Based Clustering
Model Editing as a Robust and Denoised variant of DPO: A Case Study on Toxicity
FakeShield: Explainable Image Forgery Detection and Localization via Multi-modal Large Language Models
Improving Large Language Model Planning with Action Sequence Similarity
Rethinking Fair Representation Learning for Performance-Sensitive Tasks
Bayesian WeakS-to-Strong from Text Classification to Generation
A Causal Lens for Learning Long-term Fair Policies
Revisiting Energy Based Models as Policies: Ranking Noise Contrastive Estimation and Interpolating Energy Models
Restating the Proof of Linear Convergence for Linear GNNs
Rethinking Artistic Copyright Infringements In the Era Of Text-to-Image Generative Models
Unsupervised Zero-Shot Reinforcement Learning via Dual-Value Forward-Backward Representation
SAVA: Scalable Learning-Agnostic Data Valuation
ThunderKittens: Simple, Fast, and $\textit{Adorable}$ Kernels
PETRA: Parallel End-to-end Training with Reversible Architectures
Context-aware Dynamic Pruning for Speech Foundation Models
Towards Universality: Studying Mechanistic Similarity Across Language Model Architectures
WorkflowLLM: Enhancing Workflow Orchestration Capability of Large Language Models
O(d/T) Convergence Theory for Diffusion Probabilistic Models under Minimal Assumptions
Captured by Captions: On Memorization and its Mitigation in CLIP Models
Semantics-Adaptive Activation Intervention for LLMs via Dynamic Steering Vectors
Ada-K Routing: Boosting the Efficiency of MoE-based LLMs
Hyper-Connections
When do GFlowNets learn the right distribution?
Rewarding Progress: Scaling Automated Process Verifiers for LLM Reasoning
Global Convergence in Neural ODEs: Impact of Activation Functions
Quantized Spike-driven Transformer
Real2Code: Reconstruct Articulated Objects via Code Generation
How Do Large Language Models Understand Graph Patterns? A Benchmark for Graph Pattern Comprehension
$R^2$-Guard: Robust Reasoning Enabled LLM Guardrail via Knowledge-Enhanced Logical Reasoning
Imputation for prediction: beware of diminishing returns.
OmniSep: Unified Omni-Modality Sound Separation with Query-Mixup
Speculative Knowledge Distillation: Bridging the Teacher-Student Gap Through Interleaved Sampling
InstaRevive: One-Step Image Enhancement via Dynamic Score Matching
Synergy Between Sufficient Changes and Sparse Mixing Procedure for Disentangled Representation Learning
SecureGS: Boosting the Security and Fidelity of 3D Gaussian Splatting Steganography
Rodimus*: Breaking the Accuracy-Efficiency Trade-Off with Efficient Attentions
Sparse components distinguish visual pathways & their alignment to neural networks
On Designing General and Expressive Quantum Graph Neural Networks with Applications to MILP Instance Representation
Boosting Perturbed Gradient Ascent for Last-Iterate Convergence in Games
EVA: Geometric Inverse Design for Fast Protein Motif-Scaffolding with Coupled Flow
Can Watermarks be Used to Detect LLM IP Infringement For Free?
What Matters in Learning from Large-Scale Datasets for Robot Manipulation
Following the Human Thread in Social Navigation
Zigzag Diffusion Sampling: Diffusion Models Can Self-Improve via Self-Reflection
MetaDesigner: Advancing Artistic Typography through AI-Driven, User-Centric, and Multilingual WordArt Synthesis
Decoupled Graph Energy-based Model for Node Out-of-Distribution Detection on Heterophilic Graphs
FlexPrefill: A Context-Aware Sparse Attention Mechanism for Efficient Long-Sequence Inference
Energy-Based Diffusion Language Models for Text Generation
Deep MMD Gradient Flow without adversarial training
Transformers Learn Low Sensitivity Functions: Investigations and Implications
GROOT-2: Weakly Supervised Multimodal Instruction Following Agents
Bridging the Gap between Database Search and \emph{De Novo} Peptide Sequencing with SearchNovo
You Only Sample Once: Taming One-Step Text-to-Image Synthesis by Self-Cooperative Diffusion GANs
MUSE: Machine Unlearning Six-Way Evaluation for Language Models
CLIPure: Purification in Latent Space via CLIP for Adversarially Robust Zero-Shot Classification
Language Models Trained to do Arithmetic Predict Human Risky and Intertemporal Choice
Regularization by Texts for Latent Diffusion Inverse Solvers
LLaVA-Mini: Efficient Image and Video Large Multimodal Models with One Vision Token
TopoNets: High performing vision and language models with brain-like topography
Accurate and Scalable Graph Neural Networks via Message Invariance
Protein Language Model Fitness is a Matter of Preference
Latent Action Pretraining from Videos
On the Hölder Stability of Multiset and Graph Neural Networks
Efficient stagewise pretraining via progressive subnetworks
Needle In A Video Haystack: A Scalable  Synthetic Evaluator for Video MLLMs
Group-robust Sample Reweighting for Subpopulation Shifts via Influence Functions
Gradient descent with generalized Newton’s method
Proving Olympiad Inequalities by Synergizing LLMs and Symbolic Reasoning
SOO-Bench: Benchmarks for Evaluating the Stability of Offline Black-Box Optimization
Biologically Constrained Barrel Cortex Model Integrates Whisker Inputs and Replicates Key Brain Network Dynamics
Online Preference Alignment for Language Models via Count-based Exploration
Gyrogroup Batch Normalization
Mask-DPO: Generalizable Fine-grained Factuality Alignment of LLMs
Large Language Models Assume People are More Rational than We Really are
Reassessing EMNLP 2024’s Best Paper: Does Divergence-Based Calibration for MIAs Hold Up?
ImProver: Agent-Based Automated Proof Optimization
UniWav: Towards Unified Pre-training for Speech Representation Learning and Generation
Preserving Deep Representations in One-Shot Pruning: A Hessian-Free Second-Order Optimization Framework
Layerwise Recurrent Router for  Mixture-of-Experts
BIRD: A Trustworthy Bayesian Inference Framework for Large Language Models
Accelerating 3D Molecule Generation via Jointly Geometric Optimal Transport
NetFormer: An interpretable model for recovering dynamical connectivity in neuronal population dynamics
GReaTer: Gradients Over Reasoning Makes Smaller Language Models Strong Prompt Optimizers
Correcting the Mythos of KL-Regularization: Direct Alignment without Overoptimization via Chi-Squared Preference Optimization
Understanding Factual Recall in Transformers via Associative Memories
Adversarial Training Can Provably Improve Robustness: Theoretical Analysis of Feature Learning Process Under Structured Data
Leveraging Submodule Linearity Enhances Task Arithmetic Performance in LLMs
WeatherGFM: Learning a Weather Generalist Foundation Model via In-context Learning
The OMG dataset: An Open MetaGenomic corpus for mixed-modality genomic language modeling
Feedback Schrödinger Bridge Matching
Diffusion Attribution Score: Evaluating Training Data Influence in Diffusion Models
Catastrophic Failure of LLM Unlearning via Quantization
ZAPBench: A Benchmark for Whole-Brain Activity Prediction in Zebrafish
Task Descriptors Help Transformers Learn Linear Models In-Context
Understanding Warmup-Stable-Decay Learning Rates: A River Valley Loss Landscape View
WizardMath: Empowering Mathematical Reasoning for Large Language Models via Reinforced Evol-Instruct
CBGBench: Fill in the Blank of Protein-Molecule Complex Binding Graph
Web Agents with World Models: Learning and Leveraging Environment Dynamics in Web Navigation
PQMass: Probabilistic Assessment of the Quality of Generative Models using Probability Mass Estimation
MeToken: Uniform Micro-environment Token Boosts Post-Translational Modification Prediction
On the Benefits of Memory for Modeling Time-Dependent PDEs
TokenFormer: Rethinking Transformer Scaling with Tokenized Model Parameters
SpinQuant: LLM Quantization with Learned Rotations
Emergent Orientation Maps —— Mechanisms, Coding Efficiency and Robustness
Bidirectional Decoding: Improving Action Chunking via Guided Test-Time Sampling
GETS: Ensemble Temperature Scaling for Calibration in Graph Neural Networks
Aligning Generative Denoising with Discriminative Objectives Unleashes Diffusion for Visual Perception
SWE-bench Multimodal: Do AI Systems Generalize to Visual Software Domains?
Understanding Optimization in Deep Learning with Central Flows
C-CLIP: Multimodal Continual Learning for Vision-Language Model
pMoE: Prompting Diverse Experts Together Wins More in Visual Adaptation
U-Nets as Belief Propagation: Efficient Classification, Denoising, and Diffusion in Generative Hierarchical Models
RazorAttention: Efficient KV Cache Compression Through Retrieval Heads
ProAdvPrompter: A Two-Stage Journey to Effective Adversarial Prompting for LLMs
Discriminating image representations with principal distortions
PEARL: Towards Permutation-Resilient LLMs
UniCon: Unidirectional Information Flow for Effective Control of Large-Scale Diffusion Models
Tracing Representation Progression: Analyzing and Enhancing Layer-Wise Similarity
VoxDialogue: Can Spoken Dialogue Systems Understand Information Beyond Words?
A Solvable Attention for Neural Scaling Laws
Consistency Models Made Easy
APE: Faster and Longer Context-Augmented Generation via Adaptive Parallel Encoding
Accelerating Diffusion Transformers with Token-wise Feature Caching
Omni-MATH: A Universal Olympiad Level Mathematic Benchmark for Large Language Models
Physics of Language Models: Part 2.2, How to Learn From Mistakes on Grade-School Math Problems
Modeling dynamic social vision highlights gaps between deep learning and humans
Less is More: Masking Elements in Image Condition Features Avoids Content Leakages in Style Transfer Diffusion Models
ConcreTizer: Model Inversion Attack via Occupancy Classification and Dispersion Control for 3D Point Cloud Restoration
TANGO: Co-Speech Gesture Video Reenactment with Hierarchical Audio Motion Embedding and Diffusion Interpolation
$F^3Set$: Towards Analyzing Fast, Frequent, and Fine-grained Events from Videos
A Large-Scale 3D Face Mesh Video Dataset via Neural Re-parameterized Optimization
SymmCD: Symmetry-Preserving Crystal Generation with Diffusion Models
Few-Class Arena: A Benchmark for Efficient Selection of Vision Models and Dataset Difficulty Measurement
Revisit the Open Nature of Open Vocabulary Semantic Segmentation
An Intelligent Agentic System for Complex Image Restoration Problems
MTSAM: Multi-Task Fine-Tuning for Segment Anything Model
PuzzleFusion++: Auto-agglomerative 3D Fracture Assembly by Denoise and Verify
Modality-Specialized Synergizers for Interleaved Vision-Language Generalists
Order-aware Interactive Segmentation
RGB-Event ISP: The Dataset and Benchmark
Unposed Sparse Views Room Layout Reconstruction in the Age of Pretrain Model
Learning Spatial-Semantic Features for Robust Video Object Segmentation
Group Ligands Docking to Protein Pockets
Adaptive Camera Sensor for Vision Models
OmniEdit: Building Image Editing Generalist Models Through Specialist Supervision
Optimizing 4D Gaussians for Dynamic Scene Video from Single Landscape Images
DynAlign: Unsupervised Dynamic Taxonomy Alignment for Cross-Domain Segmentation
MMAD: A Comprehensive Benchmark for Multimodal Large Language Models in Industrial Anomaly Detection
Inverse Rendering using Multi-Bounce Path Tracing and Reservoir Sampling
Training-free Camera Control for Video Generation
LoRA3D: Low-Rank Self-Calibration of 3D Geometric Foundation models
Rethinking Classifier Re-Training in Long-Tailed Recognition: Label Over-Smooth Can Balance
SegLLM: Multi-round Reasoning Segmentation with Large Language Models
Interpretable Causal Representation Learning for Biological Data in the Pathway Space
ComPC: Completing a 3D Point Cloud with 2D Diffusion Priors
Phidias: A Generative Model for Creating 3D  Content from Text, Image, and 3D Conditions with Reference-Augmented  Diffusion
GoodDrag: Towards Good Practices for Drag Editing with Diffusion Models
GenDataAgent: On-the-fly Dataset Augmentation with Synthetic Data
DartControl: A Diffusion-Based Autoregressive Motion Model for Real-Time Text-Driven Motion Control
Pedestrian Motion Reconstruction: A Large-scale Benchmark via Mixed Reality Rendering with Multiple Perspectives and Modalities
InterMask: 3D Human Interaction Generation via Collaborative Masked Modeling
Swift4D: Adaptive divide-and-conquer Gaussian Splatting for compact and efficient reconstruction of dynamic scene
Foundation Models Secretly Understand Neural Network Weights: Enhancing Hypernetwork Architectures with Foundation Models
GSE: Group-wise Sparse and Explainable Adversarial Attacks
(ends 5:30 PM)
Break:
(ends 3:30 PM)
3:30 p.m.
Oral Session 2A
[3:30-5:00]
3:30-4:42
[3:30]
Flat Reward in Policy Parameter Space Implies Robust Reinforcement Learning
[3:42]
DeepLTL: Learning to Efficiently Satisfy Complex LTL Specifications for Multi-Task RL
[3:54]
Geometry of Neural Reinforcement Learning in Continuous State and Action Spaces
[4:06]
Interpreting Emergent Planning in Model-Free Reinforcement Learning
[4:18]
Learning to Search from Demonstration Sequences
[4:30]
Open-World Reinforcement Learning over Long Short-Term Imagination
(ends 5:00 PM)
Oral Session 2B
[3:30-5:00]
3:30-4:42
[3:30]
MLE-bench: Evaluating Machine Learning Agents on Machine Learning Engineering
[3:42]
MMQA: Evaluating LLMs with Multi-Table Multi-Hop Complex Questions
[3:54]
MMIE: Massive Multimodal Interleaved Comprehension Benchmark for Large Vision-Language Models
[4:06]
Dynamic Multimodal Evaluation with Flexible Complexity by Vision-Language Bootstrapping
[4:18]
PathGen-1.6M: 1.6 Million Pathology Image-text Pairs Generation through Multi-agent Collaboration
[4:30]
Two Effects, One Trigger: On the Modality Gap, Object Bias, and Information Imbalance in Contrastive Vision-Language Models
(ends 5:00 PM)
Oral Session 2C
[3:30-5:00]
3:30-4:30
[3:30]
ProtComposer: Compositional Protein Structure Generation with 3D Ellipsoids
[3:42]
ShEPhERD: Diffusing shape, electrostatics, and pharmacophores for bioisosteric drug design
[3:54]
ECD: A Machine Learning Benchmark for Predicting Enhanced-Precision Electronic Charge Density in Crystalline Inorganic Materials
[4:06]
Rethinking the generalization of drug target affinity prediction algorithms via similarity aware evaluation
[4:18]
PhysBench: Benchmarking and Enhancing Vision-Language Models for Physical World Understanding
(ends 5:00 PM)
Oral Session 2D
[3:30-5:00]
3:30-4:42
[3:30]
Prioritized Generative Replay
[3:42]
Representation Alignment for Generation: Training Diffusion Transformers Is Easier Than You Think
[3:54]
Simplifying, Stabilizing and Scaling Continuous-time Consistency Models
[4:06]
One Step Diffusion via Shortcut Models
[4:18]
Block Diffusion: Interpolating Between Autoregressive and Diffusion Language Models
[4:30]
Scaling In-the-Wild Training for Diffusion-based Illumination Harmonization and Editing by Imposing Consistent Light Transport
(ends 5:00 PM)
Oral Session 2E
[3:30-5:00]
3:30-4:42
[3:30]
A Theoretically-Principled Sparse, Connected, and Rigid Graph Representation of Molecules
[3:42]
GeSubNet: Gene Interaction Inference for Disease Subtype Network Generation
[3:54]
Towards a Complete Logical Framework for GNN Expressiveness
[4:06]
Homomorphism Expressivity of Spectral Invariant Graph Neural Networks
[4:18]
Robustness Inspired Graph Backdoor Defense
[4:30]
Joint Graph Rewiring and Feature Denoising via Spectral Resonance
(ends 5:00 PM)
Oral Session 2F
[3:30-5:00]
3:30-4:42
[3:30]
NeuralPlane: Structured 3D Reconstruction in Planar Primitives with Neural Fields
[3:42]
TetSphere Splatting: Representing High-Quality Geometry with Lagrangian Volumetric Meshes
[3:54]
High-Dynamic Radar Sequence Prediction for Weather Nowcasting Using Spatiotemporal Coherent Gaussian Representation
[4:06]
Residual Deep Gaussian Processes on Manifolds
[4:18]
No Pose, No Problem: Surprisingly Simple 3D Gaussian Splats from Sparse Unposed Images
[4:30]
On Scaling Up 3D Gaussian Splatting Training
(ends 5:00 PM)
5 p.m.
Social:
AI and Human Agency
(ends 6:30 PM)
Social:
Muslim in ML Social
(ends 6:30 PM)
Social:
Oracle AI Science Social
(ends 6:30 PM)
Social:
Global AI Systems: Inclusive and Culturally Aware AI
(ends 6:30 PM)
5:30 p.m.
Remarks:
Opening Reception Remarks
(ends 5:50 PM)
6 p.m.
Reception:
Opening Reception
(ends 7:30 PM)
FRI 25 APR
9 a.m.
Invited Talk:
Pursuing the Nature of Intelligence
(ends 10:00 AM)
Invited Talk:
Overflow: Pursuing the Nature of Intelligence
(ends 10:00 AM)
10 a.m.
Exhibit Hall
(ends 5:30 PM)
Poster Session 3
[10:00-12:30]
Poster
10:00-12:30
ProtComposer: Compositional Protein Structure Generation with 3D Ellipsoids
SAGEPhos: Sage Bio-Coupled and Augmented Fusion for Phosphorylation Site Detection
Ctrl-Adapter: An Efficient and Versatile Framework for Adapting Diverse Controls to Any Diffusion Model
ChartMoE: Mixture of Diversely Aligned Expert Connector for Chart Understanding
CLoSD: Closing the Loop between Simulation and Diffusion for multi-task character control
Semi-Supervised Vision-Centric 3D Occupancy World Model for Autonomous Driving
SplineGS: Learning Smooth Trajectories in Gaussian Splatting for Dynamic Scene Reconstruction
EG4D: Explicit Generation of 4D Object without Score Distillation
AniSDF: Fused-Granularity Neural Surfaces with Anisotropic Encoding for High-Fidelity 3D Reconstruction
IMDPrompter: Adapting SAM to Image Manipulation Detection by Cross-View Automated Prompt Learning
Revolutionizing EMCCD Denoising through a Novel Physics-Based Learning Framework for Noise Modeling
Reflective Gaussian Splatting
Immunogenicity Prediction with Dual Attention Enables Vaccine Target Selection
Point-SAM: Promptable 3D Segmentation Model for Point Clouds
Generative Inbetweening: Adapting Image-to-Video Models for Keyframe Interpolation
Open-Vocabulary Customization from CLIP via Data-Free Knowledge Distillation
DeLLMa: Decision Making Under Uncertainty with Large Language Models
SoundCTM: Unifying Score-based and Consistency Models for Full-band Text-to-Sound Generation
CARTS: Advancing Neural Theorem Proving with Diversified Tactic Calibration and Bias-Resistant Tree Search
API Pack: A Massive Multi-Programming Language Dataset for API Call Generation
CrossMPT: Cross-attention Message-passing Transformer for Error Correcting Codes
ForecastBench: A Dynamic Benchmark of AI Forecasting Capabilities
AutoCLIP: Auto-tuning Zero-Shot Classifiers for Vision-Language Models
GlycanML: A Multi-Task and Multi-Structure Benchmark for Glycan Machine Learning
Sensitivity-Constrained Fourier Neural Operators for Forward and Inverse Problems in Parametric Differential Equations
Revisiting Nearest Neighbor for Tabular Data: A Deep Tabular Baseline Two Decades Later
BP-Modified Local Loss for Efficient Training of Deep Neural Networks
Autoregressive Pretraining with Mamba in Vision
RFMamba: Frequency-Aware State Space Model for RF-Based Human-Centric Perception
On the Byzantine-Resilience of Distillation-Based Federated Learning
Random-Set Neural Networks
Efficiently Parameterized Neural Metriplectic Systems
Why RoPE Struggles to Maintain Long-Term Decay in Long Sequences?
CLOVER: Cross-Layer Orthogonal Vectors Pruning and Fine-Tuning
Boltzmann priors for Implicit Transfer Operators
A Training-Free Sub-quadratic Cost Transformer Model Serving Framework with Hierarchically Pruned Attention
Scaling Stick-Breaking Attention: An Efficient Implementation and In-depth Study
Selective Attention Improves Transformer
Quality over Quantity in Attention Layers: When Adding More Heads Hurts
Looking Backward: Streaming Video-to-Video Translation with Feature Banks
OASIS Uncovers: High-Quality T2I Models, Same Old Stereotypes
HQ-Edit: A High-Quality Dataset for Instruction-based Image Editing
Manifold Learning by Mixture Models of VAEs for Inverse Problems
RevisEval: Improving LLM-as-a-Judge via Response-Adapted References
ParaSolver: A Hierarchical Parallel Integral Solver for Diffusion Models
Lift Your Molecules: Molecular Graph Generation in Latent Euclidean Space
Unlocking Point Processes through Point Set Diffusion
Enhancing Compositional Text-to-Image Generation with Reliable Random Seeds
Towards Hierarchical Rectified Flow
Generalization through variance: how noise shapes inductive biases in diffusion models
LANTERN: Accelerating Visual Autoregressive Models with Relaxed Speculative Decoding
OmniPhysGS: 3D Constitutive Gaussians for General Physics-Based Dynamics Generation
Multi-Reward as Condition for Instruction-based Image Editing
Masked Diffusion Models are Secretly Time-Agnostic Masked Models and Exploit Inaccurate Categorical Sampling
ViDiT-Q: Efficient and Accurate Quantization of Diffusion Transformers for Image and Video Generation
MeshAnything: Artist-Created Mesh Generation with Autoregressive Transformers
SynFlowNet: Design of Diverse and Novel Molecules with Synthesis Constraints
Linear Combination of Saved Checkpoints Makes Consistency and Diffusion Models Better
Shallow diffusion networks provably learn hidden low-dimensional structure
CPSample: Classifier Protected Sampling for Guarding Training Data During Diffusion
EC-DIT: Scaling Diffusion Transformers with Adaptive Expert-Choice Routing
Vec2Face: Scaling Face Dataset Generation with Loosely Constrained Vectors
NetMoE: Accelerating MoE Training through Dynamic Sample Placement
High-Dimensional Bayesian Optimisation with Gaussian Process Prior Variational Autoencoders
Unlocking Guidance for Discrete State-Space Diffusion and Flow Models
Infinite-Resolution Integral Noise Warping for Diffusion Models
High-Quality Joint Image and Video Tokenization with Causal VAE
MolSpectra: Pre-training 3D Molecular Representation with Multi-modal Energy Spectra
MMDisCo: Multi-Modal Discriminator-Guided Cooperative Diffusion for Joint Audio and Video Generation
RB-Modulation: Training-Free Stylization using Reference-Based Modulation
Repulsive Latent Score Distillation for Solving Inverse Problems
SafeDiffuser: Safe Planning with Diffusion Probabilistic Models
Towards Semantic Equivalence of Tokenization in Multimodal LLM
Lossy Compression with Pretrained Diffusion Models
A Simple Approach to Unifying Diffusion-based Conditional Generation
RAPID: Retrieval Augmented Training of Differentially Private Diffusion Models
Beyond Autoregression: Fast LLMs via Self-Distillation Through Time
SVDQuant: Absorbing Outliers by Low-Rank Component for 4-Bit Diffusion Models
Multi-Modal and Multi-Attribute Generation of Single Cells with CFGen
Video In-context Learning: Autoregressive Transformers are Zero-Shot Video Imitators
Boosting Latent Diffusion with Perceptual Objectives
Rethinking Graph Prompts: Unraveling the Power of Data Manipulation in Graph Neural Networks
Port-Hamiltonian Architectural Bias for Long-Range Propagation in Deep Graph Networks
Energy-based Backdoor Defense Against Federated Graph Learning
Towards Bridging Generalization and Expressivity of Graph Neural Networks
Tuning-Free Bilevel Optimization: New Algorithms and Convergence Analysis
Topological Blindspots: Understanding and Extending Topological Deep Learning Through the Lens of Expressivity
MuseGNN: Forming Scalable, Convergent GNN Layers that Minimize a Sampling-Based Energy
Understanding Virtual Nodes: Oversquashing and Node Heterogeneity
A Multiscale Frequency Domain Causal Framework for Enhanced Pathological Analysis
Graph Neural Preconditioners for Iterative Solutions of Sparse Linear Systems
KAA: Kolmogorov-Arnold Attention for Enhancing Attentive Graph Neural Networks
Subgraph Federated Learning for Local Generalization
Revealing and Mitigating Over-Attention in Knowledge Editing
Minimal Impact ControlNet: Advancing Multi-ControlNet Integration
Valid Conformal Prediction for Dynamic GNNs
Rethinking Graph Neural Networks From A Geometric Perspective Of Node Features
Is uniform expressivity too restrictive? Towards efficient expressivity of GNNs
Spreading Out-of-Distribution Detection on Graphs
Holographic Node Representations: Pre-training Task-Agnostic Node Embeddings
Diffusion Generative Modeling for Spatially Resolved Gene Expression Inference from Histology Images
IGL-Bench: Establishing the Comprehensive Benchmark for Imbalanced Graph Learning
Ferret-UI 2: Mastering Universal User Interface Understanding Across Platforms
Unleashing the Power of Task-Specific Directions in Parameter Efficient Fine-tuning
SWEb: A Large Web Dataset for the Scandinavian Languages
Synthetic continued pretraining
Personality Alignment of Large Language Models
PAL: Sample-Efficient Personalized Reward Modeling for Pluralistic Alignment
DeFT: Decoding with Flash Tree-attention for Efficient Tree-structured LLM Inference
MEGA-Bench: Scaling Multimodal Evaluation to over 500 Real-World Tasks
Sparse Autoencoders Reveal Temporal Difference Learning in Large Language Models
Periodic Materials Generation using Text-Guided Joint Diffusion Model
GS-CPR: Efficient Camera Pose Refinement via 3D Gaussian Splatting
From Pixels to Tokens: Byte-Pair Encoding on Quantized Visual Modalities
Self-Evolving Multi-Agent Collaboration Networks for Software Development
Varying Shades of Wrong: Aligning LLMs with Wrong Answers Only
Holistic Reasoning with Long-Context LMs: A Benchmark for Database Operations on Massive Textual Data
Precise Localization of Memories: A Fine-grained Neuron-level Knowledge Editing Technique for LLMs
MMEgo: Towards Building Egocentric Multimodal LLMs for Video QA
Token-Supervised Value Models for Enhancing Mathematical Problem-Solving Capabilities of Large Language Models
Answer, Assemble, Ace: Understanding How LMs Answer Multiple Choice Questions
Mutual Reasoning Makes Smaller LLMs Stronger Problem-Solver
Episodic Memories Generation and Evaluation Benchmark for Large Language Models
Interpretable Bilingual Multimodal Large Language Model for Diverse Biomedical Tasks
When Attention Sink Emerges in Language Models: An Empirical View
Lawma: The Power of Specialization for Legal Annotation
Do Vision-Language Models Represent Space and How? Evaluating Spatial Frame of Reference under Ambiguities
Human Simulacra: Benchmarking the Personification of Large Language Models
CodeMMLU: A Multi-Task Benchmark for Assessing Code Understanding & Reasoning Capabilities of CodeLLMs
CHASE-SQL: Multi-Path Reasoning and Preference Optimized Candidate Selection in Text-to-SQL
DSBench: How Far Are Data Science Agents from Becoming Data Science Experts?
Cut Your Losses in Large-Vocabulary Language Models
CAKE: Cascading and Adaptive KV Cache Eviction with Layer Preferences
Agent-Oriented Planning in Multi-Agent Systems
L-WISE: Boosting Human Visual Category Learning Through Model-Based Image Selection and Enhancement
EMMA: Empowering Multi-modal Mamba with Structural and Hierarchical Alignment
The Crucial Role of Samplers in Online Direct Preference Optimization
Searching for Optimal Solutions with LLMs via Bayesian Optimization
MM1.5: Methods, Analysis & Insights from Multimodal LLM Fine-tuning
Learning LLM-as-a-Judge for Preference Alignment
$\text{D}_{2}\text{O}$: Dynamic Discriminative Operations for Efficient Long-Context Inference of Large Language Models
DeepSeek-Prover-V1.5: Harnessing Proof Assistant Feedback for Reinforcement Learning and Monte-Carlo Tree Search
From Attention to Activation: Unraveling the Enigmas of Large Language Models
Measuring and Enhancing Trustworthiness of LLMs in RAG through Grounded Attributions and Learning to Refuse
Streaming Video Understanding and Multi-round Interaction with Memory-enhanced Knowledge
Physics-Informed Deep Inverse Operator Networks for Solving PDE Inverse Problems
Sufficient Context: A New Lens on Retrieval Augmented Generation Systems
To Trust or Not to Trust? Enhancing Large Language Models' Situated Faithfulness to External Contexts
Tracking the Copyright of Large Vision-Language Models through Parameter Learning Adversarial Images
LLMs Know More Than They Show: On the Intrinsic Representation of LLM Hallucinations
Uncovering Latent Memories in Large Language Models
SysBench: Can LLMs Follow System Message?
SVD-LLM: Truncation-aware Singular Value Decomposition for Large Language Model Compression
Neuron based Personality Trait Induction in Large Language Models
Fiddler: CPU-GPU Orchestration for Fast Inference of Mixture-of-Experts Models
The Same but Different: Structural Similarities and Differences in Multilingual Language Modeling
Model-Agnostic Knowledge Guided Correction for Improved Neural Surrogate Rollout
It Helps to Take a Second Opinion: Teaching Smaller LLMs To Deliberate Mutually via Selective Rationale Optimisation
Beyond Autoregression: Discrete Diffusion for Complex Reasoning and Planning
TPO: Aligning Large Language Models with Multi-branch & Multi-step Preference Trees
Arithmetic Without Algorithms: Language Models Solve Math with a Bag of Heuristics
InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales
RM-Bench: Benchmarking Reward Models of Language Models with Subtlety and Style
From Exploration to Mastery: Enabling LLMs to Master Tools via Self-Driven Interactions
Reflexive Guidance: Improving OoDD in Vision-Language Models via Self-Guided Image-Adaptive Concept Generation
Large Language Models Often Say One Thing and Do Another
Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model
Physics-aligned field reconstruction with diffusion bridge
Language Models Are Implicitly Continuous
Herald: A Natural Language Annotated Lean 4 Dataset
GameArena: Evaluating LLM Reasoning through Live Computer Games
Logical Consistency of Large Language Models in Fact-Checking
REEF: Representation Encoding Fingerprints for Large Language Models
Provence: efficient and robust context pruning for retrieval-augmented generation
Revisit Large-Scale Image-Caption Data in Pre-training Multimodal Foundation Models
Law of the Weakest Link: Cross Capabilities of Large Language Models
MIND: Math Informed syNthetic Dialogues for Pretraining LLMs
CREAM: Consistency Regularized Self-Rewarding Language Models
Going Beyond Feature Similarity: Effective Dataset distillation based on Class-aware Conditional Mutual Information
Rotated Runtime Smooth: Training-Free Activation Smoother for accurate INT4 inference
BigCodeBench: Benchmarking Code Generation with Diverse Function Calls and Complex Instructions
InsightBench: Evaluating Business Analytics Agents Through Multi-Step Insight Generation
What Makes Large Language Models Reason in (Multi-Turn) Code Generation?
IterGen: Iterative Semantic-aware Structured LLM Generation with Backtracking
Mini-batch Coresets for Memory-efficient Language Model Training on Data Mixtures
Regressing the Relative Future: Efficient Policy Optimization for Multi-turn RLHF
TAID: Temporally Adaptive Interpolated Distillation for Efficient Knowledge Transfer in Language Models
MallowsPO: Fine-Tune Your LLM with Preference Dispersions
Tool-Planner: Task Planning with Clusters across Multiple Tools
MAPS: Advancing Multi-Modal Reasoning in Expert-Level Physical Science
Bootstrapping Language Models with DPO Implicit Rewards
Your Mixture-of-Experts LLM Is Secretly an Embedding Model for Free
DataMan: Data Manager for Pre-training Large Language Models
GraphRouter: A Graph-based Router for LLM Selections
UGMathBench: A Diverse and Dynamic Benchmark for Undergraduate-Level Mathematical Reasoning with Large Language Models
Dynamic Loss-Based Sample Reweighting for Improved Large Language Model Pretraining
Uncertainty-Aware Decoding with Minimum Bayes Risk
Rethinking and Improving Autoformalization: Towards a Faithful Metric and a Dependency Retrieval-based Approach
Mixture Compressor for Mixture-of-Experts LLMs Gains More
Rethinking LLM Unlearning Objectives: A Gradient Perspective and Go Beyond
Text2PDE: Latent Diffusion Models for Accessible Physics Simulation
Adam-mini: Use Fewer Learning Rates To Gain More
SePer: Measure Retrieval Utility Through The Lens Of Semantic Perplexity Reduction
SimPER: A Minimalist Approach to Preference  Alignment without Hyperparameters
ShortcutsBench: A Large-Scale Real-world Benchmark for API-based Agents
Semi-Parametric Retrieval via Binary Bag-of-Tokens Index
Do as I do (Safely): Mitigating Task-Specific Fine-tuning Risks in Large Language Models
From Tokens to Lattices: Emergent Lattice Structures in Language Models
ACC-Collab: An Actor-Critic Approach to Multi-Agent LLM Collaboration
Hypothetical Minds: Scaffolding Theory of Mind for Multi-Agent Tasks with Large Language Models
G-LLaVA: Solving Geometric Problem with Multi-Modal Large Language Model
TRENDy: Temporal Regression of Effective Nonlinear Dynamics
$\gamma-$MoD: Exploring Mixture-of-Depth Adaptation for Multimodal Large Language Models
LongPO: Long Context Self-Evolution of Large Language Models through Short-to-Long Preference Optimization
{$\tau$}-bench: A Benchmark for \underline{T}ool-\underline{A}gent-\underline{U}ser Interaction in Real-World Domains
An Evolved Universal Transformer Memory
Temporal Reasoning Transfer from Text to Video
PiCO: Peer Review in LLMs based on Consistency Optimization
Breaking Mental Set to Improve Reasoning through Diverse Multi-Agent Debate
MoE++: Accelerating Mixture-of-Experts Methods with Zero-Computation Experts
Backdooring Vision-Language Models with Out-Of-Distribution Data
Cybench: A Framework for Evaluating Cybersecurity Capabilities and Risks of Language Models
Procedural Synthesis of Synthesizable Molecules
Provable weak-to-strong generalization via benign overfitting
DOTS: Learning to Reason Dynamically in LLMs via Optimal Reasoning Trajectories Search
Benchmarking LLMs' Judgments with No Gold Standard
SeRA: Self-Reviewing and Alignment of LLMs using Implicit Reward Margins
Seeing Eye to AI: Human Alignment via Gaze-Based Response Rewards for Large Language Models
LongVILA: Scaling Long-Context Visual Language Models for Long Videos
ChroKnowledge: Unveiling Chronological Knowledge of Language Models in Multiple Domains
OLMoE: Open Mixture-of-Experts Language Models
MindSearch: Mimicking Human Minds Elicits Deep AI Searcher
Advantage-Guided Distillation for Preference Alignment in Small Language Models
LICO: Large Language Models for In-Context Molecular Optimization
Poisson-Dirac Neural Networks for Modeling Coupled Dynamical Systems across Domains
Attention in Large Language Models Yields Efficient Zero-Shot Re-Rankers
AFlow: Automating Agentic Workflow Generation
Unified Parameter-Efficient Unlearning for LLMs
h4rm3l: A Language for Composable Jailbreak Attack Synthesis
MMTEB: Massive Multilingual Text Embedding Benchmark
Compositional Entailment Learning for Hyperbolic Vision-Language Models
Input Space Mode Connectivity in Deep Neural Networks
Affine Steerable Equivariant Layer for Canonicalization of Neural Networks
TIPS: Text-Image Pretraining with Spatial awareness
Discovering Clone Negatives via Adaptive Contrastive Learning for Image-Text Matching
Fengbo: a Clifford Neural Operator pipeline for 3D PDEs in Computational Fluid Dynamics
Plastic Learning with Deep Fourier Features
GS-LiDAR: Generating Realistic LiDAR Point Clouds with Panoramic Gaussian Splatting
Locality-aware Gaussian Compression for Fast and High-quality Rendering
MM-EMBED: UNIVERSAL MULTIMODAL RETRIEVAL WITH MULTIMODAL LLMS
I Can Hear You: Selective Robust Training for Deepfake Audio Detection
Generating Less Certain Adversarial Examples Improves Robust Generalization
LR0.FM: LOW-RESOLUTION ZERO-SHOT CLASSIFICATION BENCHMARK FOR FOUNDATION MODELS
Adversarially Robust Out-of-Distribution Detection Using Lyapunov-Stabilized Embeddings
To Tackle Adversarial Transferability: A Novel Ensemble Training Method with Fourier Transformation
Detecting Backdoor Samples in Contrastive Language Image Pretraining
DiffPC: Diffusion-based High Perceptual Fidelity Image Compression with Semantic Refinement
Towards Certification of Uncertainty Calibration under Adversarial Attacks
MOCA: Self-supervised Representation Learning by Predicting Masked Online Codebook Assignments
Object-Centric Pretraining via Target Encoder Bootstrapping
Mutual Effort for Efficiency: A Similarity-based Token Pruning for Vision Transformers in Self-Supervised Learning
Self-supervised contrastive learning performs non-linear system identification
Morphing Tokens Draw Strong Masked Image Models
PooDLe🐩: Pooled and dense self-supervised learning from naturalistic videos
T-JEPA: Augmentation-Free Self-Supervised Learning for Tabular Data
Lambda-Skip Connections: the architectural component that prevents Rank Collapse
Reasoning of Large Language Models over Knowledge Graphs with Super-Relations
Rapidly Adapting Policies to the Real-World via Simulation-Guided Fine-Tuning
Limits of Deep Learning: Sequence Modeling through the Lens of Complexity Theory
Distance-Based Tree-Sliced Wasserstein Distance
A Theory of Initialisation's Impact on Specialisation
Inner Information Analysis Algorithm for Deep Neural Network based on Community
Capability Localization: Capabilities Can be Localized rather than Individual Knowledge
Swing-by Dynamics in Concept Learning and Compositional Generalization
SysCaps: Language Interfaces for Simulation Surrogates of Complex Systems
Learning Interpretable Hierarchical Dynamical Systems Models from Time Series Data
HADAMRNN: BINARY AND SPARSE TERNARY ORTHOGONAL RNNS
Balanced Neural ODEs: nonlinear model order reduction and Koopman operator approximations
Policy Decorator: Model-Agnostic Online Refinement for Large Policy Model
Autocorrelation Matters: Understanding the Role of Initialization Schemes for State Space Models
OmniCorpus: A Unified Multimodal Corpus of 10 Billion-Level Images Interleaved with Text
Revisiting Mode Connectivity in Neural Networks with Bezier Surface
STAR: Stability-Inducing Weight Perturbation for Continual Learning
FedLWS: Federated Learning with Adaptive Layer-wise Weight Shrinking
DRL: Decomposed Representation Learning for Tabular Anomaly Detection
LiveXiv - A Multi-Modal live benchmark based on Arxiv papers content
Watch Less, Do More: Implicit Skill Discovery for Video-Conditioned Policy
SLoPe: Double-Pruned Sparse Plus Lazy Low-Rank Adapter Pretraining of LLMs
SOREL: A Stochastic Algorithm for Spectral Risks Minimization
HAMSTER: Hierarchical Action Models for Open-World Robot Manipulation
PolyNet: Learning Diverse Solution Strategies for Neural Combinatorial Optimization
BTBS-LNS: Binarized-Tightening, Branch and Search on Learning LNS Policies for MIP
Adversarial Generative Flow Network for Solving Vehicle Routing Problems
Efficient Sparse PCA via Block-Diagonalization
Learning Dynamics of Deep Matrix Factorization Beyond the Edge of Stability
A Theoretically-Principled Sparse, Connected, and Rigid Graph Representation of Molecules
Local convergence of simultaneous min-max algorithms to differential equilibrium on Riemannian manifold
Adaptive Methods through the Lens of SDEs: Theoretical Insights on the Role of Noise
Bayesian Optimization via Continual Variational Last Layer Training
Elliptic Loss Regularization
GEVRM: Goal-Expressive Video Generation Model For Robust Visual Manipulation
Scalable Discrete Diffusion Samplers: Combinatorial Optimization and Statistical Physics
CONGO: Compressive Online Gradient Optimization
Enhancing Zeroth-order Fine-tuning for Language Models with Low-rank Structures
Sharpness-Aware Black-Box Optimization
Fine-tuning with Reserved Majority for Noise Reduction
Decentralized Optimization with Coupled Constraints
How Does Critical Batch Size Scale in Pre-training?
An Auditing Test to Detect Behavioral Shift in Language Models
A Truncated Newton Method for Optimal Transport
The AdEMAMix Optimizer: Better, Faster, Older
LLaRA: Supercharging Robot Learning Data for Vision-Language Policy
ConFIG: Towards Conflict-free Training of Physics Informed Neural Networks
Constraint-Conditioned Actor-Critic for Offline Safe Reinforcement Learning
Adversarial Policy Optimization for Offline Preference-based Reinforcement Learning
Model-Free Offline Reinforcement Learning with Enhanced Robustness
Offline RL with Smooth OOD Generalization in Convex Hull and its Neighborhood
XLand-100B: A Large-Scale Multi-Task Dataset for In-Context Reinforcement Learning
COFlowNet: Conservative Constraints on Flows Enable High-Quality Candidate Generation
Learning Task Belief Similarity with Latent Dynamics for Meta-Reinforcement Learning
Cross-Domain Offline Policy Adaptation with Optimal Transport and Dataset Constraint
Stable Hadamard Memory: Revitalizing Memory-Augmented Agents for Reinforcement Learning
The Value of Sensory Information to a Robot
Towards Generalizable Reinforcement Learning via Causality-Guided Self-Adaptive Representations
Safety Representations for Safer Policy Learning
Looking into User’s Long-term Interests through the Lens of Conservative Evidential Learning
SEMDICE: Off-policy State Entropy Maximization via Stationary Distribution Correction Estimation
Grammar Reinforcement Learning: path and cycle counting in graphs with a Context-Free Grammar and Transformer approach
PN-GAIL: Leveraging Non-optimal Information from Imperfect Demonstrations
Noise-conditioned Energy-based Annealed Rewards (NEAR): A Generative Framework for Imitation Learning from Observation
Generalized Behavior Learning from Diverse Demonstrations
Diffusing States and Matching Scores: A New Framework for Imitation Learning
Learning to Clarify: Multi-turn Conversations with Action-Based Contrastive Self-Training
Structure Language Models for Protein Conformation Generation
ImagineNav: Prompting Vision-Language Models as Embodied Navigator through Scene Imagination
Optimal Strong Regret and Violation in Constrained MDPs via Policy Optimization
Reinforcement Learning from Imperfect Corrective Actions and Proxy Rewards
Iterative Nash Policy Optimization: Aligning LLMs with General Preferences via No-Regret Learning
ActSafe: Active Exploration with Safety Constraints for Reinforcement Learning
Diffusion Policy Policy Optimization
Learning mirror maps in policy mirror descent
AdaWM: Adaptive World Model based Planning for Autonomous Driving
Dynamic Contrastive Skill Learning with State-Transition Based Skill Clustering and Dynamic Length Adjustment
Accelerating Task Generalisation with Multi-Level Skill Hierarchies
Zeroth-Order Policy Gradient for Reinforcement Learning from Human Feedback without Reward Inference
RDT-1B: a Diffusion Foundation Model for Bimanual Manipulation
$\phi$-Update: A Class of Policy Update Methods with Policy Convergence Guarantee
Learning View-invariant World Models for Visual Robotic Manipulation
Sensitivity-Aware Amortized Bayesian Inference
Streamlining Prediction in Bayesian Deep Learning
Laplace Sample Information:  Data Informativeness Through a Bayesian Lens
Bayesian Image Regression with Soft-thresholded Conditional Autoregressive Prior
Exploiting Hankel-Toeplitz Structures for Fast Computation of Kernel Precision Matrices
Identifiability for Gaussian Processes with Holomorphic Kernels
Deep Kernel Posterior Learning under Infinite Variance Prior Weights
Causal Discovery via Bayesian Optimization
Robots Pre-train Robots: Manipulation-Centric Robotic Representation from Large-Scale Robot Datasets
Variational Bayesian Pseudo-Coreset
Controllable Generation via Locally Constrained Resampling
Minimal Variance Model Aggregation: A principled, non-intrusive, and versatile integration of black box models
Kernel-based Optimally Weighted Conformal Time-Series Prediction
Distribution-Free Data Uncertainty for Neural Network Regression
A Theoretical Analysis of Self-Supervised Learning for Vision Transformers
Adam Exploits $\ell_\infty$-geometry of Loss Landscape via Coordinate-wise Adaptivity
Closed-Form Merging of Parameter-Efficient Modules for Federated Continual Learning
Optimality and Adaptivity of Deep Neural Features for Instrumental Variable Regression
Unintentional Unalignment: Likelihood Displacement in Direct Preference Optimization
PPT: Patch Order Do Matters In Time Series Pretext Task
Convergence and Implicit Bias of Gradient Descent on Continual Linear Classification
Decoupled Finetuning for Domain Generalizable Semantic Segmentation
Is Large-scale Pretraining the Secret to Good Domain Generalization?
Interference Among First-Price Pacing Equilibria: A Bias and Variance Analysis
Private Mechanism Design via Quantile Estimation
Efficient Online Pruning and Abstraction for Imperfect Information Extensive-Form Games
Can One Modality Model Synergize Training of Other Modality Models?
On the Learn-to-Optimize Capabilities of Transformers in In-Context Sparse Recovery
Learning High-Degree Parities: The Crucial Role of the Initialization
No Free Lunch: Fundamental Limits of Learning Non-Hallucinating Generative Models
Federated Granger Causality Learning For Interdependent Clients With State Space Representation
Improved Convergence Rate for Diffusion Probabilistic Models
Grokking at the Edge of Numerical Stability
Decentralized Sporadic Federated Learning: A Unified Algorithmic Framework with Convergence Guarantees
Towards Auto-Regressive Next-Token Prediction: In-context Learning Emerges from Generalization
Local Patterns Generalize Better for Novel Anomalies
Bridging the Gap Between f-divergences and Bayes Hilbert Spaces
Transformers Learn to Implement Multi-step Gradient Descent with Chain of Thought
Bounds on $L_p$ Errors in Density Ratio Estimation via $f$-Divergence Loss Functions
Computational Explorations of Total Variation Distance
Bayesian Analysis of Combinatorial Gaussian Process Bandits
DyCAST: Learning Dynamic Causal Structure from Time Series
Learning from Imperfect  Human Feedback: A Tale from Corruption-Robust Dueling
Feature-Based Online Bilateral Trade
Avoid Overclaims: Summary of Complexity Bounds for Algorithms in Minimization and Minimax Optimization
Graph Assisted Offline-Online Deep Reinforcement Learning for Dynamic Workflow Scheduling
Neural Exploratory Landscape Analysis for Meta-Black-Box-Optimization
Selective Task Group Updates for Multi-Task Optimization
Leave-One-Out Stable Conformal Prediction
Towards Self-Supervised Covariance Estimation in Deep Heteroscedastic Regression
Beyond-Expert Performance with Limited Demonstrations: Efficient Imitation Learning with Double Exploration
Statistical Tractability of Off-policy Evaluation of History-dependent Policies in POMDPs
SimpleTM: A Simple Baseline for Multivariate Time Series Forecasting
Optimal Non-Asymptotic Rates of Value Iteration for Average-Reward Markov Decision Processes
Misspecified  $Q$-Learning with Sparse Linear Function Approximation: Tight Bounds on Approximation Error
Exploring channel distinguishability in local neighborhoods of the model space in quantum neural networks
Near-optimal Active Regression of Single-Index Models
MAP: Low-compute Model Merging with Amortized Pareto Fronts via Quadratic Approximation
How Learnable Grids Recover Fine Detail in Low Dimensions: A Neural Tangent Kernel Analysis of Multigrid Parametric Encodings
Difference-of-submodular Bregman Divergence
On the expressiveness and spectral bias of KANs
Extending Mercer's expansion to indefinite and asymmetric kernels
Towards a Unified and Verified Understanding of Group-Operation Networks
Scaling Transformers for Low-Bitrate High-Quality Speech Coding
Node Similarities under Random Projections: Limits and Pathological Cases
RandLoRA: Full rank parameter-efficient fine-tuning of large models
Modeling Fine-Grained Hand-Object Dynamics for Egocentric Video Representation Learning
Intrinsic Dimension Correlation: uncovering nonlinear connections in multimodal representations
Duoduo CLIP: Efficient 3D Understanding with Multi-View Images
Looped Transformers for Length Generalization
Balanced Ranking with Relative Centrality: A multi-core periphery perspective
Exploring a Principled Framework for Deep Subspace Clustering
Recovering Manifold Structure Using Ollivier Ricci Curvature
Uncertainty Herding: One Active Learning Method for All Label Budgets
Speech Robust Bench: A Robustness Benchmark For Speech Recognition
Let SSMs be ConvNets: State-space Modeling with Optimal Tensor Contractions
Nonlinear Sequence Embedding by Monotone Variational Inequality
Differentiable Rule Induction from Raw Sequence Inputs
Fine-tuning can cripple your foundation model; preserving features may be the solution
Structuring Benchmark into Knowledge Graphs to Assist Large Language Models in Retrieving and Designing Models
Neural Context Flows for Meta-Learning of Dynamical Systems
Boosting Multiple Views for pretrained-based Continual Learning
Revisiting Prefix-tuning: Statistical Benefits of Reparameterization among Prompts
Metalic: Meta-Learning In-Context with Protein Language Models
Efficient Cross-Episode Meta-RL
MaskGCT: Zero-Shot Text-to-Speech with Masked Generative Codec Transformer
TSVD: Bridging Theory and Practice in Continual Learning with Pre-trained Models
Mitigating Parameter Interference in Model Merging via Sharpness-Aware Fine-Tuning
Tree of Attributes Prompt Learning for Vision-Language Models
Towards more rigorous evaluations of language models
A Single Goal is All You Need: Skills and Exploration Emerge from Contrastive RL without Rewards, Demonstrations, or Subgoals
On the Inherent Privacy Properties of Discrete Denoising Diffusion Models
Machine Unlearning via Simulated Oracle Matching
Machine Unlearning Fails to Remove Data Poisoning Attacks
DocMIA: Document-Level Membership Inference Attacks against DocVQA Models
Privately Counting Partially Ordered Data
Partially Observed Trajectory Inference using Optimal Transport and a Dynamics Prior
T2V2: A Unified Non-Autoregressive Model for Speech Recognition and Synthesis via Multitask Learning
DCT-CryptoNets: Scaling Private Inference in the Frequency Domain
DynFrs: An Efficient Framework for Machine Unlearning in Random Forest
Scalable Extraction of Training Data from Aligned, Production Language Models
Mixture of Experts Made Personalized: Federated Prompt Learning for Vision-Language Models
Pacmann: Efficient Private Approximate Nearest Neighbor Search
LLM Unlearning via Loss Adjustment with Only Forget Data
On Large Language Model Continual Unlearning
More RLHF, More Trust? On The Impact of Preference Alignment On Trustworthiness
The Utility and Complexity of In- and Out-of-Distribution Machine Unlearning
Tell me about yourself: LLMs are aware of their learned behaviors
ToolGen: Unified Tool Retrieval and Calling via Generation
Reducing Hallucinations in Large Vision-Language Models via Latent Space Steering
Does Safety Training of LLMs Generalize to Semantically Related Natural Prompts?
Transformer Encoder Satisfiability: Complexity and Impact on Formal Reasoning
Agree to Disagree: Demystifying Homogeneous Deep Ensembles through Distributional Equivalence
Fantastic Copyrighted Beasts and How (Not) to Generate Them
Is Your Video Language Model a Reliable Judge?
Fantastic Targets for Concept Erasure in Diffusion Models and Where To Find Them
BlueSuffix: Reinforced Blue Teaming for Vision-Language Models Against Jailbreak Attacks
How to visualize training dynamics in neural networks
Bridging the Semantic Gap Between Text and Table: A Case Study on NL2SQL
RepoGraph: Enhancing AI Software Engineering with Repository-level Code Graph
Inverse Constitutional AI: Compressing Preferences into Principles
QPM: Discrete Optimization for Globally Interpretable Image Classification
Data-centric Prediction Explanation via Kernelized Stein Discrepancy
Efficient and Accurate Explanation Estimation with Distribution Compression
Salvage: Shapley-distribution Approximation Learning Via Attribution Guided Exploration for Explainable Image Classification
The Geometry of Categorical and Hierarchical Concepts in Large Language Models
Scalable Influence and Fact Tracing for Large Language Model Pretraining
SONICS: Synthetic Or Not - Identifying Counterfeit Songs
Image Watermarks are Removable using Controllable Regeneration from Clean Noise
Bridging Jensen Gap for Max-Min Group Fairness Optimization in Recommendation
WavTokenizer: an Efficient Acoustic Discrete Codec Tokenizer for Audio Language Modeling
How Far Are We from True Unlearnability?
Is Your Multimodal Language Model Oversensitive to Safe Queries?
See It from My Perspective: How Language Affects Cultural Bias in Image Understanding
No Preference Left Behind: Group Distributional Preference Optimization
Jailbreaking Leading Safety-Aligned LLMs with Simple Adaptive Attacks
SAFREE: Training-Free and Adaptive Guard for Safe Text-to-Image And Video Generation
GSBA$^K$: $top$-$K$ Geometric Score-based Black-box Attack
Copyright-Protected Language Generation via Adaptive Model Fusion
Safety Layers in Aligned Large Language Models: The Key to LLM Security
Collapsed Language Models Promote Fairness
Towards Homogeneous Lexical Tone Decoding from Heterogeneous Intracranial Recordings
TIS-DPO: Token-level Importance Sampling for Direct Preference Optimization With Estimated Weights
Towards Scalable Exact Machine Unlearning Using Parameter-Efficient Fine-Tuning
A Benchmark for Semantic Sensitive Information in LLMs Outputs
Beyond Mere Token Analysis: A Hypergraph Metric Space Framework for Defending Against Socially Engineered LLM Attacks
A Generic Framework for Conformal Fairness
Stealthy Shield Defense: A Conditional Mutual Information-Based Approach against Black-Box Model Inversion Attacks
FairMT-Bench: Benchmarking Fairness for Multi-turn Dialogue in Conversational LLMs
KGARevion: An AI Agent for Knowledge-Intensive Biomedical QA
Efficient Reward Poisoning Attacks on Online Deep Reinforcement Learning
RAFT: Reward rAnked FineTuning for Generative Foundation Model Alignment
Disentangling 3D Animal Pose Dynamics with Scrubbed Conditional Latent Variables
Exposing and Addressing Cross-Task Inconsistency in Unified Vision-Language Models
Enhancing Vision-Language Model with Unmasked Token Alignment
LoRA Learns Less and Forgets Less
Hessian Free Efficient Single Loop Iterative Differentiation Methods for Bi-Level Optimization Problems
Diffusion Models and Gaussian Flow Matching: Two Sides of the Same Coin
A Percolation Model of Emergence: Analyzing Transformers Trained on a Formal Language
Rapid Selection and Ordering of In-Context Demonstrations via Prompt Embedding Clustering
MathCoder2: Better Math Reasoning from Continued Pretraining on Model-translated Mathematical Code
Towards Principled Evaluations of Sparse Autoencoders for Interpretability and Control
Aligned Better, Listen Better for Audio-Visual Large Language Models
Expressivity of Neural Networks with Random Weights and Learned Biases
SelectFormer in Data Markets: Privacy-Preserving and Efficient Data Selection for Transformers with Multi-Party Computation
Justice or Prejudice? Quantifying Biases in LLM-as-a-Judge
Learning from negative feedback, or positive feedback or both
Elucidating the Preconditioning in Consistency Distillation
Charting the Design Space of Neural Graph Representations for Subgraph Matching
Data Taggants: Dataset Ownership Verification Via Harmless Targeted Data Poisoning
Collab: Controlled Decoding using Mixture of Agents for LLM Alignment
Longhorn: State Space Models are Amortized Online Learners
ALBAR: Adversarial Learning approach to mitigate Biases in Action Recognition
LLMOPT: Learning to Define and Solve General Optimization Problems from Scratch
XAIguiFormer: explainable artificial intelligence guided transformer for brain disorder identification
DiffusionGuard: A Robust Defense Against Malicious Diffusion-based Image Editing
Exploiting Structure in Offline Multi-Agent RL: The Benefits of Low Interaction Rank
MatExpert: Decomposing Materials Discovery By Mimicking Human Experts
Adaptive teachers for amortized samplers
CR-CTC: Consistency regularization on CTC for improved speech recognition
Exploring Learning Complexity for Efficient Downstream Dataset Pruning
Fine-Tuning Discrete Diffusion Models via Reward Optimization with Applications to DNA and Protein Design
Bi-Factorial Preference Optimization: Balancing Safety-Helpfulness in Language Models
Towards Improving Exploration through Sibling Augmented GFlowNets
BingoGuard: LLM Content Moderation Tools with Risk Levels
Population Transformer: Learning Population-level Representations of Neural Activity
ToddlerDiffusion: Interactive Structured Image Generation with Cascaded Schrödinger Bridge
Diffusion Transformer Captures Spatial-Temporal Dependencies: A Theory for Gaussian Process Data
A Sanity Check for AI-generated Image Detection
Aligning Human Motion Generation with Human Perceptions
Exploratory Preference Optimization: Harnessing Implicit Q*-Approximation for Sample-Efficient RLHF
FIRING-Net: A filtered feature recycling network for speech enhancement
GPS: A Probabilistic Distributional Similarity with Gumbel Priors for Set-to-Set Matching
FaithEval: Can Your Language Model Stay Faithful to Context, Even If "The Moon is Made of Marshmallows"
SEAL: Safety-enhanced Aligned LLM Fine-tuning via Bilevel Data Selection
Designing Mechanical Meta-Materials by Learning Equivariant Flows
Nonlinear multiregion neural dynamics with parametric impulse response communication channels
Breaking Class Barriers: Efficient Dataset Distillation via Inter-Class Feature Compensator
Going Beyond Static: Understanding Shifts with Time-Series Attribution
Controlled LLM Decoding via Discrete Auto-regressive Biasing
Spider 2.0: Evaluating Language Models on Real-World Enterprise Text-to-SQL Workflows
Block Verification Accelerates Speculative Decoding
Scaling Laws for Adversarial Attacks on Language Model Activations and Tokens
Theory, Analysis, and Best Practices for Sigmoid Self-Attention
Problem-Parameter-Free Federated Learning
Rethinking Spiking Neural Networks from an Ensemble Learning Perspective
TopoLM: brain-like spatio-functional organization in a topographic language model
Self-Supervised Diffusion Models for Electron-Aware Molecular Representation Learning
Credit-based self organizing maps: training deep topographic networks with minimal performance degradation
VibeCheck: Discover and Quantify Qualitative Differences in Large Language Models
Generative Adapter: Contextualizing Language Models in Parameters with A Single Forward Pass
AutoDAN-Turbo: A Lifelong Agent for Strategy Self-Exploration to Jailbreak LLMs
Test-time Adaptation for Image Compression with Distribution Regularization
Dynamical Diffusion: Learning Temporal Dynamics with Diffusion Models
Fine-Grained Verifiers: Preference Modeling as Next-token Prediction in Vision-Language Alignment
Diversity Empowers Intelligence: Integrating Expertise of Software Engineering Agents
Multi-Resolution Decomposable Diffusion Model for Non-Stationary Time Series Anomaly Detection
Amulet: ReAlignment During Test Time for Personalized Preference Adaptation of LLMs
Enabling Realtime Reinforcement Learning at Scale with Staggered Asynchronous Inference
Inverse decision-making using neural amortized Bayesian actors
Uncertainty modeling for fine-tuned implicit functions
AndroidWorld: A Dynamic Benchmarking Environment for Autonomous Agents
ZETA: Leveraging $Z$-order Curves for Efficient Top-$k$ Attention
Long-Sequence Recommendation Models Need Decoupled Embeddings
Toward Guidance-Free AR Visual Generation via Condition Contrastive Alignment
Dobi-SVD: Differentiable SVD for LLM Compression and Some New Perspectives
gRNAde: Geometric Deep Learning for 3D RNA inverse design
LLM-SR: Scientific Equation Discovery via Programming with Large Language Models
Apollo-MILP: An Alternating Prediction-Correction Neural Solving Framework for Mixed-Integer Linear Programming
Zeroth-Order Fine-Tuning of LLMs with Transferable Static Sparsity
Unleashing the Potential of Vision-Language Pre-Training for 3D Zero-Shot Lesion Segmentation via Mask-Attribute Alignment
ViBiDSampler: Enhancing Video Interpolation Using Bidirectional Diffusion Sampler
InversionGNN: A Dual Path Network for Multi-Property Molecular Optimization
Visual Agents as Fast and Slow Thinkers
Physics of Language Models: Part 3.2, Knowledge Manipulation
Adversarial Attacks on Data Attribution
Knowledge Graph Finetuning Enhances Knowledge Manipulation in Large Language Models
OMG: Opacity Matters in Material Modeling with Gaussian Splatting
MaestroMotif: Skill Design from Artificial Intelligence Feedback
Facilitating Multi-turn Function Calling for LLMs via Compositional Instruction Tuning
UNIP: Rethinking Pre-trained Attention Patterns for Infrared Semantic Segmentation
Instructional Segment Embedding: Improving LLM Safety with Instruction Hierarchy
On the Benefits of Attribute-Driven Graph Domain Adaptation
Rationalizing and Augmenting Dynamic Graph Neural Networks
Capturing the Temporal Dependence of Training Data Influence
A CLIP-Powered Framework for Robust and Generalizable Data Selection
Learning Fine-Grained Representations through Textual Token Disentanglement in Composed Video Retrieval
ST-GCond: Self-supervised and Transferable Graph Dataset Condensation
Vector-ICL: In-context Learning with Continuous Vector Representations
LOKI: A Comprehensive Synthetic Data Detection Benchmark using Large Multimodal Models
EvA: Erasing Spurious Correlations with Activations
Generation and Comprehension Hand-in-Hand: Vision-guided Expression Diffusion for Boosting Referring Expression Generation and Comprehension
Ultra-Sparse Memory Network
Cross-Attention Head Position Patterns Can Align with Human Visual Concepts in Text-to-Image Generative Models
Video Action Differencing
Dynamic Negative Guidance of Diffusion Models
3DGS-Drag: Dragging Gaussians for Intuitive Point-Based 3D Editing
VideoPhy: Evaluating Physical Commonsense for Video Generation
Towards Synergistic Path-based Explanations for Knowledge Graph Completion: Exploration and Evaluation
AugKD: Ingenious Augmentations Empower Knowledge Distillation for Image Super-Resolution
Injective flows for star-like manifolds
DisPose: Disentangling Pose Guidance for Controllable Human Image Animation
Fast Feedforward 3D Gaussian Splatting Compression
Cocoon: Robust Multi-Modal Perception with Uncertainty-Aware Sensor Fusion
MGMapNet: Multi-Granularity Representation Learning for End-to-End Vectorized HD Map Construction
Learning Gain Map for Inverse Tone Mapping
Union-over-Intersections: Object Detection beyond Winner-Takes-All
Expected Sliced Transport Plans
X-NeMo: Expressive Neural Motion Reenactment via Disentangled Latent Attention
System 1.x: Learning to Balance Fast and Slow Planning with Language Models
Continuous Exposure Learning for Low-light Image Enhancement using Neural ODEs
Samba: Synchronized Set-of-Sequences Modeling for Multiple Object Tracking
Matérn Kernels for Tunable Implicit Surface Reconstruction
Diffusion Models Are Real-Time Game Engines
Scale-aware Recognition in Satellite Images under Resource Constraints
UNSURE: self-supervised learning with Unknown Noise level  and Stein's Unbiased Risk Estimate
Matryoshka Multimodal Models
Causal Representation Learning from Multimodal Biomedical Observations
Frequency-Guided Masking for Enhanced Vision Self-Supervised Learning
FasterCache: Training-Free Video Diffusion Model Acceleration with High Quality
Efficient Biological Data Acquisition through Inference Set Design
Perm: A Parametric Representation for Multi-Style 3D Hair Modeling
Incorporating Visual Correspondence into Diffusion Model for Virtual Try-On
Self-supervised Monocular Depth Estimation Robust to Reflective Surface Leveraged by Triplet Mining
Gaussian-Based Instance-Adaptive Intensity Modeling for Point-Supervised Facial Expression Spotting
Diffusion$^2$: Dynamic 3D Content Generation via Score Composition of Video and Multi-view Diffusion Models
Posterior-Mean Rectified Flow: Towards Minimum MSE Photo-Realistic Image Restoration
3DitScene: Editing Any Scene via Language-guided Disentangled Gaussian Splatting
MonST3R: A Simple Approach for Estimating Geometry in the Presence of Motion
CAT-3DGS: A Context-Adaptive Triplane Approach to Rate-Distortion-Optimized 3DGS Compression
Adaptive Length Image Tokenization via Recurrent Allocation
(ends 12:30 PM)
Break:
(ends 10:30 AM)
10:30 a.m.
Oral Session 3A
[10:30-12:00]
10:30-11:42
[10:30]
Retrieval Head Mechanistically Explains Long-Context Factuality
[10:42]
REGENT: A Retrieval-Augmented Generalist Agent That Can Act In-Context in New Environments
[10:54]
Differential Transformer
[11:06]
Context-Parametric Inversion: Why Instruction Finetuning May Not Actually Improve Context Reliance
[11:18]
Do I Know This Entity? Knowledge Awareness and Hallucinations in Language Models
[11:30]
Knowing Your Target: Target-Aware Transformer Makes Better Spatio-Temporal Video Grounding
(ends 12:00 PM)
Oral Session 3B
[10:30-12:00]
10:30-11:30
[10:30]
Learning to Discover Regulatory Elements for Gene Expression Prediction
[10:42]
Steering Protein Family Design through Profile Bayesian Flow
[10:54]
Proteina: Scaling Flow-based Protein Structure Generative Models
[11:06]
Latent Bayesian Optimization via Autoregressive Normalizing Flows
[11:18]
Composing Unbalanced Flows for Flexible Docking and Relaxation
(ends 12:00 PM)
Oral Session 3C
[10:30-12:00]
10:30-11:42
[10:30]
Restructuring Vector Quantization with the Rotation Trick
[10:42]
STAR: Synthesis of Tailored Architectures
[10:54]
SANA: Efficient High-Resolution Text-to-Image Synthesis with Linear Diffusion Transformers
[11:06]
LVSM: A Large View Synthesis Model with Minimal 3D Inductive Bias
[11:18]
LARP: Tokenizing Videos with a Learned Autoregressive Generative Prior
[11:30]
Scaling and evaluating sparse autoencoders
(ends 12:00 PM)
Oral Session 3D
[10:30-12:00]
10:30-11:42
[10:30]
MAP: Multi-Human-Value Alignment Palette
[10:42]
Limits to scalable evaluation at the frontier: LLM as judge won’t beat twice the data
[10:54]
Trust or Escalate: LLM Judges with Provable Guarantees for Human Agreement
[11:06]
AI as Humanity’s Salieri: Quantifying Linguistic Creativity of Language Models via Systematic Attribution of Machine Text against Web Text
[11:18]
Consistency Checks for Language Model Forecasters
[11:30]
Probabilistic Learning to Defer: Handling Missing Expert Annotations and Controlling Workload Distribution
(ends 12:00 PM)
Oral Session 3E
[10:30-12:00]
10:30-11:42
[10:30]
SD-LoRA: Scalable Decoupled Low-Rank Adaptation for Class Incremental Learning
[10:42]
HiRA: Parameter-Efficient Hadamard High-Rank Adaptation for Large Language Models
[10:54]
LoRA Done RITE: Robust Invariant Transformation Equilibration for LoRA Optimization
[11:06]
LaMPlace: Learning to Optimize Cross-Stage Metrics in Macro Placement
[11:18]
DSPO: Direct Score Preference Optimization for Diffusion Model Alignment
[11:30]
On the Hölder Stability of Multiset and Graph Neural Networks
(ends 12:00 PM)
Oral Session 3F
[10:30-12:00]
10:30-11:42
[10:30]
TimeMixer++: A General Time Series Pattern Machine for Universal Predictive Analysis
[10:42]
RMP-SAM: Towards Real-Time Multi-Purpose Segment Anything
[10:54]
Open-YOLO 3D: Towards Fast and Accurate Open-Vocabulary 3D Instance Segmentation
[11:06]
SAM 2: Segment Anything in Images and Videos
[11:18]
EmbodiedSAM: Online Segment Any 3D Thing in Real Time
[11:30]
MOS: Model Synergy for Test-Time Adaptation on LiDAR-Based 3D Object Detection
(ends 12:00 PM)
12:30 p.m.
Break:
Lunch Break (on your own)
(ends 2:00 PM)
Social:
AI Safety
(ends 2:00 PM)
Mentorship:
Mentorship Hour
(ends 1:15 PM)
Social:
Women in Machine Learning
(ends 2:00 PM)
Social:
AI Safety in Practice: Bridging Theory and Real-World Challenges
(ends 2:00 PM)
1 p.m.
Expo Talk Panel:
Human Attention is NOT all you need
(ends 2:00 PM)
Expo Talk Panel:
AutoGluon 1.2: Advancing AutoML with Foundation Models and LLM Agents
(ends 2:00 PM)
Social:
ML for Accelerating Scientific Discovery: Challenges and Opportunities
(ends 2:00 PM)
Expo Talk Panel:
Bridging Specialized ML Research and Systematic Investing: Transforming the Research Pipeline
(ends 2:00 PM)
Expo Talk Panel:
EUREKA: Evaluating and Understanding Large Foundation Models
(ends 2:00 PM)
1:15 p.m.
Mentorship:
Mentorship Hour
(ends 2:00 PM)
2 p.m.
Invited Talk:
Towards Building Safe and Secure AI: Lessons and Open Challenges
Dawn Song
(ends 3:00 PM)
Invited Talk:
Overflow: Towards Building Safe and Secure AI: Lessons and Open Challenges
Dawn Song
(ends 3:00 PM)
3 p.m.
Poster Session 4
[3:00-5:30]
Poster
3:00-5:30
STAMP: Scalable Task- And Model-agnostic Collaborative Perception
cryoSPHERE: Single-Particle HEterogeneous REconstruction from cryo EM
Visually Guided Decoding: Gradient-Free Hard Prompt Inversion with Language Models
Track-On: Transformer-based Online Point Tracking with Memory
DEEM: Diffusion models serve as the eyes of large language models for image perception
Articulate-Anything:  Automatic Modeling of Articulated Objects via a Vision-Language Foundation Model
6DGS: Enhanced Direction-Aware Gaussian Splatting for Volumetric Rendering
CapeX: Category-Agnostic Pose Estimation from Textual Point Explanation
Lotus: Diffusion-based Visual Foundation Model for High-quality Dense Prediction
An Image is Worth More Than 16x16 Patches: Exploring Transformers on Individual Pixels
Hydra-SGG: Hybrid Relation Assignment for One-stage Scene Graph Generation
Latent Radiance Fields with 3D-aware 2D Representations
NExT-Mol: 3D Diffusion Meets 1D Language Modeling for 3D Molecule Generation
High-Precision Dichotomous Image Segmentation via Probing Diffusion Capacity
TASAR: Transfer-based Attack on Skeletal Action Recognition
Which Tasks Should Be Compressed Together? A Causal Discovery Approach for Efficient Multi-Task Representation Compression
Mitigating Object Hallucination in MLLMs via Data-augmented Phrase-level Alignment
FreSh: Frequency Shifting for Accelerated Neural Representation Learning
OpenRCA: Can Large Language Models Locate the Root Cause of Software Failures?
Aria-MIDI: A Dataset of Piano MIDI Files for Symbolic Music Modeling
Strength Estimation and Human-Like Strength Adjustment in Games
AgentStudio: A Toolkit for Building General Virtual Agents
PostCast: Generalizable Postprocessing for Precipitation Nowcasting via Unsupervised Blurriness Modeling
A new framework for evaluating model out-of-distribution generalisation for the biochemical domain
SPORTU: A Comprehensive Sports Understanding Benchmark for Multimodal Large Language Models
AI2TALE: An Innovative Information Theory-based Approach for Learning to Localize Phishing Attacks
Regularizing Energy among Training Samples for Out-of-Distribution Generalization
Tight Clusters Make Specialized Experts
MambaPEFT: Exploring Parameter-Efficient Fine-Tuning for Mamba
Adaptive Pruning of Pretrained Transformer via Differential Inclusions
Semantic Aware Representation Learning for Lifelong Learning
Multimodal Unsupervised Domain Generalization by Retrieving Across the Modality Gap
Arithmetic Transformers Can Length-Generalize in Both Operand Length and Count
Training-Free Dataset Pruning for Instance Segmentation
Enhancing the Scalability and Applicability of Kohn-Sham Hamiltonians for Molecular Systems
Plug, Play, and Generalize: Length Extrapolation with Pointer-Augmented Neural Memory
Transformer Meets Twicing: Harnessing Unattended Residual Information
TidalDecode: Fast and Accurate LLM Decoding with Position Persistent Sparse Attention
Memory Mosaics
Differential Transformer
Gated Delta Networks: Improving Mamba2 with Delta Rule
Graph Transformers Dream of Electric Flow
FlashMask: Efficient and Rich Mask Extension of FlashAttention
Learning to Generate Diverse Pedestrian Movements from Web Videos with Noisy Labels
Diffusion-NPO: Negative Preference Optimization for Better Preference Aligned Generation of Diffusion Models
DEPfold: RNA Secondary Structure Prediction as Dependency Parsing.
Flow With What You Know
The Superposition of Diffusion Models Using the Itô Density Estimator
DreamBench++: A Human-Aligned Benchmark for Personalized Image Generation
Not-So-Optimal Transport Flows for 3D Point Cloud Generation
Pyramidal Flow Matching for Efficient Video Generative Modeling
Hummingbird: High Fidelity Image Generation via Multimodal Context Alignment
Quality Measures for Dynamic Graph Generative Models
ARLON: Boosting Diffusion Transformers with Autoregressive Models for Long Video Generation
Improving Neural Optimal Transport via Displacement Interpolation
Restructuring Vector Quantization with the Rotation Trick
Hyperbolic Genome Embeddings
The Crystal Ball Hypothesis in diffusion models: Anticipating object positions from initial noise
IV-mixed Sampler: Leveraging Image Diffusion Models for Enhanced Video Synthesis
Autoregressive Video Generation without Vector Quantization
CubeDiff: Repurposing Diffusion-Based Image Models for Panorama Generation
SANA: Efficient High-Resolution Text-to-Image Synthesis with Linear Diffusion Transformers
VSTAR: Generative Temporal Nursing for Longer Dynamic Video Synthesis
Continuous Diffusion for Mixed-Type Tabular Data
Diffusion Models as Cartoonists: The Curious Case of High Density Regions
CTSyn: A Foundation Model for Cross Tabular Data Generation
Data Unlearning in Diffusion Models
Steering Protein Family Design through Profile Bayesian Flow
Circuit Representation Learning with Masked Gate Modeling and Verilog-AIG Alignment
Information Theoretic Text-to-Image Alignment
LARP: Tokenizing Videos with a Learned Autoregressive Generative Prior
Truncated Consistency Models
Generalized Consistency Trajectory Models for Image Manipulation
One-Prompt-One-Story: Free-Lunch Consistent Text-to-Image Generation Using a Single Prompt
Bridging Context Gaps: Leveraging Coreference Resolution for Long Contextual Understanding
Hybrid Regularization Improves Diffusion-based Inverse Problem Solving
Eliminating Oversaturation and Artifacts of High Guidance Scales in Diffusion Models
Ensembling Diffusion Models via Adaptive Feature Aggregation
Estimation of single-cell and tissue perturbation effect in spatial transcriptomics via Spatial Causal Disentanglement
Dreamweaver: Learning Compositional World Models from Pixels
Ctrl-U: Robust Conditional Image Generation via Uncertainty-aware Reward Modeling
DiffSplat: Repurposing Image Diffusion Models for Scalable Gaussian Splat Generation
TweedieMix: Improving Multi-Concept Fusion for Diffusion-based Image/Video Generation
SymDiff: Equivariant Diffusion via Stochastic Symmetrisation
Positive-Unlabeled Diffusion Models for Preventing Sensitive Data Generation
Denoising as Adaptation: Noise-Space Domain Adaptation for Image Restoration
Linear combinations of latents in generative models: subspaces and beyond
Deep Incomplete Multi-view Learning via Cyclic Permutation of VAEs
Adding Conditional Control to Diffusion Models with Reinforcement Learning
MediConfusion: Can you trust your AI radiologist? Probing the reliability of multimodal medical foundation models
Dynamic Diffusion Transformer
Physics-Informed Diffusion Models
EgoSim: Egocentric Exploration in Virtual Worlds with Multi-modal Conditioning
GLoRa: A Benchmark to Evaluate the Ability to Learn Long-Range Dependencies in Graphs
Multi-Label Node Classification with Label Influence Propagation
Pushing the Limits of All-Atom Geometric Graph Neural Networks: Pre-Training, Scaling, and Zero-Shot Transfer
Bonsai: Gradient-free Graph Condensation for Node Classification
Shapley-Guided Utility Learning for Effective Graph Inference Data Valuation
Separation Power of Equivariant Neural Networks
Exact Certification of (Graph) Neural Networks Against Label Poisoning
Moner: Motion Correction in Undersampled Radial MRI with Unsupervised Neural Representation
Unifying Unsupervised Graph-Level Anomaly Detection and Out-of-Distribution Detection: A Benchmark
AutoG: Towards automatic graph construction from tabular data
Graph Neural Networks Are More Than Filters: Revisiting and Benchmarking from A Spectral Perspective
Learning Graph Quantized Tokenizers
Equivariant Denoisers Cannot Copy Graphs: Align Your Graph Diffusion Models
Homomorphism Counts as Structural Encodings for Graph Learning
Greener GRASS: Enhancing GNNs with Encoding, Rewiring, and Attention
N-ForGOT: Towards Not-forgetting and Generalization of Open Temporal Graph Learning
Graph Neural Networks Can (Often) Count Substructures
Temporal Heterogeneous Graph Generation with Privacy, Utility, and Efficiency
Integrating Protein Dynamics into Structure-Based Drug Design via Full-Atom Stochastic Flows
ACES: Automatic Cohort Extraction System for Event-Stream Datasets
Beyond Canonicalization: How Tensorial Messages Improve Equivariant Message Passing
Joint Graph Rewiring and Feature Denoising via Spectral Resonance
ScienceAgentBench: Toward Rigorous Assessment of Language Agents for Data-Driven Scientific Discovery
Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models
Generating with Confidence: Uncertainty Quantification for Black-box Large Language Models
Planning Anything with Rigor: General-Purpose Zero-Shot Planning with LLM-based Formalized Programming
Perplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models
Long Context Compression with Activation Beacon
Procedural Knowledge in Pretraining Drives Reasoning in Large Language Models
Learning Diverse Attacks on Large Language Models for Robust Red-Teaming and Safety Tuning
GANDALF: Generative AttentioN based Data Augmentation and predictive modeLing Framework for personalized cancer treatment
MoS: Unleashing Parameter Efficiency of Low-Rank Adaptation with Mixture of Shards
DeepRTL: Bridging Verilog Understanding and Generation with a Unified Representation Model
VisualAgentBench: Towards Large Multimodal Models as Visual Foundation Agents
Smaller, Weaker, Yet Better: Training LLM Reasoners via Compute-Optimal Sampling
Test of Time: A Benchmark for Evaluating LLMs on Temporal Reasoning
metabench - A Sparse Benchmark of Reasoning and Knowledge in Large Language Models
Steering Large Language Models between Code Execution and Textual Reasoning
MathGAP: Out-of-Distribution Evaluation on Problems with Arbitrarily Complex Proofs
MIA-Bench: Towards Better Instruction Following Evaluation of Multimodal LLMs
CraftRTL: High-quality Synthetic Data Generation for Verilog Code Models with Correct-by-Construction Non-Textual Representations and Targeted Code Repair
PaPaGei: Open Foundation Models for Optical Physiological Signals
LoLCATs: On Low-Rank Linearizing of Large Language Models
SPaR: Self-Play with Tree-Search Refinement to Improve Instruction-Following in Large Language Models
Efficient Inference for Large Language Model-based Generative Recommendation
GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning in Large Language Models
Kolmogorov-Arnold Transformer
Towards Robust Alignment of Language Models: Distributionally Robustifying Direct Preference Optimization
Can Textual Gradient Work in Federated Learning?
JudgeBench: A Benchmark for Evaluating LLM-Based Judges
Implicit In-context Learning
ExACT: Teaching AI Agents to Explore with Reflective-MCTS and Exploratory Learning
Large-scale and Fine-grained Vision-language Pre-training for Enhanced CT Image Understanding
Rational Decision-Making Agent with Learning Internal Utility Judgment
Advancing Mathematical Reasoning in Language Models: The Impact of Problem-Solving Data, Data Synthesis Methods, and Training Stages
STAR: Synthesis of Tailored Architectures
Differential learning kinetics govern the transition from memorization to generalization during in-context learning
Gradient-Free Generation for Hard-Constrained Systems
Simple is Effective: The Roles of Graphs and Large Language Models in Knowledge-Graph-Based Retrieval-Augmented Generation
Scaling Large Language Model-based Multi-Agent Collaboration
A Multi-Power Law for Loss Curve Prediction Across Learning Rate Schedules
Moral Alignment for LLM Agents
HelpSteer2-Preference: Complementing Ratings with Preferences
Hierarchical Uncertainty Estimation for Learning-based Registration in Neuroimaging
MAP: Multi-Human-Value Alignment Palette
Preserving Diversity in Supervised Fine-Tuning of Large Language Models
Robotouille: An Asynchronous Planning Benchmark for LLM Agents
Model Equality Testing: Which Model is this API Serving?
Spurious Forgetting in Continual Learning of Language Models
HiRA: Parameter-Efficient Hadamard High-Rank Adaptation for Large Language Models
Trust or Escalate: LLM Judges with Provable Guarantees for Human Agreement
Polyrating: A Cost-Effective and Bias-Aware Rating System for LLM Evaluation
DynaMath: A Dynamic Visual Benchmark for Evaluating Mathematical Reasoning Robustness of Vision Language Models
NeSyC: A Neuro-symbolic Continual Learner For Complex Embodied Tasks in Open Domains
Context Clues: Evaluating Long Context Models for Clinical Prediction Tasks on EHR Data
Do I Know This Entity? Knowledge Awareness and Hallucinations in Language Models
Does Spatial Cognition Emerge in Frontier Models?
Probe Pruning: Accelerating LLMs through Dynamic Pruning via Model-Probing
Small Models are LLM Knowledge Triggers for Medical Tabular Prediction
DOCS: Quantifying Weight Similarity for Deeper Insights into Large Language Models
Attributing Culture-Conditioned Generations to Pretraining Corpora
Self-Improving Robust Preference Optimization
Radar: Fast Long-Context Decoding for Any Transformer
Samba: Simple Hybrid State Space Models for Efficient Unlimited Context Language Modeling
PolyPythias: Stability and Outliers across Fifty Language Model Pre-Training Runs
Improved Sampling Of Diffusion Models In Fluid Dynamics With Tweedie's Formula
On-the-fly Preference Alignment via Principle-Guided Decoding
Offline RL in Regular Decision Processes: Sample Efficiency via Language Metrics
X-ALMA: Plug & Play Modules and Adaptive Rejection for Quality Translation at Scale
Modeling Future Conversation Turns to Teach LLMs to Ask Clarifying Questions
How Does Vision-Language Adaptation Impact the Safety of Vision Language Models?
Teaching Human Behavior Improves Content Understanding Abilities Of VLMs
Weighted-Reward Preference Optimization for Implicit Model Fusion
Mitigating Reward Over-Optimization in RLHF via Behavior-Supported Regularization
Straight to Zero: Why Linearly Decaying the Learning Rate to Zero Works Best for LLMs
Dynamic-LLaVA: Efficient Multimodal Large Language Models via Dynamic Vision-language Context Sparsification
Wavelet Diffusion Neural Operator
Language models scale reliably with over-training and on downstream tasks
CURIE: Evaluating LLMs on Multitask Scientific Long-Context Understanding and Reasoning
Efficient Dictionary Learning with Switch Sparse Autoencoders
Unveiling the Magic of Code Reasoning through Hypothesis Decomposition and Amendment
Taming Overconfidence in LLMs: Reward Calibration in RLHF
BitStack: Any-Size Compression of Large Language Models in Variable Memory Environments
Do Vision & Language Decoders use Images and Text equally? How Self-consistent are their Explanations?
NV-Embed: Improved Techniques for Training LLMs as Generalist Embedding Models
OpenMathInstruct-2: Accelerating AI for Math with Massive Open-Source Instruction Data
Quamba: A Post-Training Quantization Recipe for Selective State Space Models
Discretization-invariance? On the Discretization Mismatch Errors in Neural Operators
Towards Federated RLHF with Aggregated Client Preference for LLMs
Think-on-Graph 2.0: Deep and Faithful Large Language Model Reasoning with Knowledge-guided Retrieval Augmented Generation
Forgetting Transformer: Softmax Attention with a Forget Gate
Safety Alignment Should be Made More Than Just a Few Tokens Deep
Consistency Checks for Language Model Forecasters
Quest: Query-centric Data Synthesis Approach for Long-context Scaling of Large Language Model
LiveBench: A Challenging, Contamination-Limited LLM Benchmark
Your Absorbing Discrete Diffusion Secretly Models the Conditional Distributions of Clean Data
Emerging Safety Attack and Defense in Federated Instruction Tuning of Large Language Models
Self-Correcting Decoding with Generative Feedback for Mitigating Hallucinations in Large Vision-Language Models
Beyond Circuit Connections: A Non-Message Passing Graph Transformer Approach for Quantum Error Mitigation
NovelQA: Benchmarking Question Answering on Documents Exceeding 200K Tokens
Layer Swapping for Zero-Shot Cross-Lingual Transfer in Large Language Models
To CoT or not to CoT? Chain-of-thought helps mainly on math and symbolic reasoning
Improving Instruction-Following in Language Models through Activation Steering
Learning Evolving Tools for Large Language Models
MACPO: Weak-to-Strong Alignment via Multi-Agent Contrastive Preference Optimization
(Mis)Fitting Scaling Laws: A Survey of Scaling Law Fitting Techniques in Deep Learning
Context Steering: Controllable Personalization at Inference Time
Revisiting In-context Learning Inference Circuit in Large Language Models
Deep Kernel Relative Test for Machine-generated Text Detection
CheapNet: Cross-attention on Hierarchical representations for Efficient protein-ligand binding Affinity Prediction
RESuM: A Rare Event Surrogate Model for  Physics Detector Design
RocketEval: Efficient automated LLM evaluation via grading checklist
CSA: Data-efficient Mapping of Unimodal Features to Multimodal Features
Towards Scalable Topological Regularizers
Words in Motion: Extracting Interpretable Control Vectors for Motion Transformers
An Exploration with Entropy Constrained 3D Gaussians for 2D Video Compression
$\mathbb{X}$-Sample Contrastive Loss: Improving Contrastive Learning with Sample Similarity Graphs
Gramian Multimodal Representation Learning and Alignment
Control-oriented Clustering of Visual Latent Representation
Enhance Multi-View Classification Through Multi-Scale Alignment and Expanded Boundary
Understanding the Stability-based Generalization of Personalized Federated Learning
KinFormer: Generalizable Dynamical Symbolic Regression for Catalytic Organic Reaction Kinetics
Interpreting Global Perturbation Robustness of Image Models using Axiomatic Spectral Importance Decomposition
Tamper-Resistant Safeguards for Open-Weight LLMs
DaWin: Training-free Dynamic Weight Interpolation for Robust Adaptation
Adversarial Training for Defense Against Label Poisoning Attacks
Re-Evaluating the Impact of Unseen-Class Unlabeled Data on Semi-Supervised Learning Model
Confidence Elicitation: A New Attack Vector for Large Language Models
Targeted Attack Improves Protection against Unauthorized Diffusion Customization
Can We Ignore Labels in Out of Distribution Detection?
Autonomous Evaluation of LLMs for Truth Maintenance and Reasoning Tasks
Indirect Gradient Matching for Adversarial Robust Distillation
PINP: Physics-Informed Neural Predictor with latent estimation of fluid flows
Adaptive Energy Alignment for Accelerating Test-Time Adaptation
Towards Understanding the Robustness of Diffusion-Based Purification: A Stochastic Perspective
Boosting Ray Search Procedure of Hard-label Attacks with Transfer-based Priors
Functional Homotopy: Smoothing Discrete Optimization via Continuous Parameters for LLM Jailbreak Attacks
Adversarial Perturbations Cannot Reliably Protect Artists From Generative AI
DINOv2: Learning Robust Visual Features without Supervision
A New Perspective on Shampoo's Preconditioner
Beyond Random Augmentations: Pretraining with Hard Views
The "Law'' of the Unconscious Contrastive Learner: Probabilistic Alignment of Unpaired Modalities
Equivariant Masked Position Prediction for Efficient Molecular Representation
STRAP: Robot Sub-Trajectory Retrieval for Augmented Policy Learning
Universal Image Restoration Pre-training via Degradation Classification
What to align in multimodal contrastive learning?
SSLAM: Enhancing Self-Supervised Models with Audio Mixtures for Polyphonic Soundscapes
Breaking the Reclustering Barrier in Centroid-based Deep Clustering
A Rainbow in Deep Network Black Boxes
Let Me Grok for You: Accelerating Grokking via Embedding Transfer from a Weaker Model
REVISITING MULTI-PERMUTATION EQUIVARIANCE THROUGH THE LENS OF IRREDUCIBLE REPRESENTATIONS
Generalizability of Neural Networks Minimizing Empirical Risk Based on Expressive Power
On the Optimization and Generalization of Two-layer Transformers with Sign Gradient Descent
When narrower is better: the narrow width limit of Bayesian parallel branching neural networks
FLIP: Flow-Centric Generative Planning as General-Purpose Manipulation World Model
Learning Hierarchical Polynomials of Multiple Nonlinear Features
LiveCodeBench: Holistic and Contamination Free Evaluation of Large Language Models for Code
Training Nonlinear Transformers for Chain-of-Thought Inference:  A Theoretical Generalization Analysis
Leveraging Flatness to Improve Information-Theoretic Generalization Bounds for SGD
Decomposition Polyhedra of Piecewise Linear Functions
TimeMixer++: A General Time Series Pattern Machine for Universal Predictive Analysis
Continual Slow-and-Fast Adaptation of Latent Neural Dynamics (CoSFan): Meta-Learning What-How & When to Adapt
Neural Functions for Learning Periodic Signal
Locally Connected Echo State Networks for Time Series Forecasting
Can LLMs Understand Time Series Anomalies?
SmartPretrain: Model-Agnostic and Dataset-Agnostic Representation Learning for Motion Prediction
Scalable Mechanistic Neural Networks
Efficient Source-Free Time-Series Adaptation via Parameter Subspace Disentanglement
DeciMamba: Exploring the Length Extrapolation Potential of Mamba
Neural Wave Equation for Irregularly Sampled Sequence Data
From Layers to States: A State Space Model Perspective to Deep Neural Network Layer Dynamics
Tuning Frequency Bias of State Space Models
What Do You See in Common? Learning Hierarchical Prototypes over Tree-of-Life to Discover Evolutionary Traits
IFORMER: INTEGRATING CONVNET AND TRANSFORMER FOR MOBILE APPLICATION
Robust Weight Initialization for Tanh Neural Networks with Fixed Point Analysis
Revisiting text-to-image evaluation with Gecko: on metrics, prompts, and human rating
ReGen: Generative Robot Simulation via Inverse Design
Unsupervised Model Tree Heritage Recovery
Differentiation and Specialization of Attention Heads via the Refined Local Learning Coefficient
Forget the Data and Fine-Tuning! Just Fold the Network to Compress
NEAR: A Training-Free Pre-Estimator of Machine Learning Model Performance
Open-Set Graph Anomaly Detection via Normal Structure Regularisation
Transformer Block Coupling and its Correlation with Generalization in LLMs
Analysis of Linear Mode Connectivity via Permutation-Based Weight Matching: With Insights into Other Permutation Search Methods
Effective Interplay between Sparsity and Quantization: From Theory to Practice
Accelerating Training with Neuron Interaction and Nowcasting Networks
Motion Control of High-Dimensional Musculoskeletal Systems with Hierarchical Model-Based Planning
The Loss Landscape of Deep Linear Neural Networks: a Second-order Analysis
Mask in the Mirror: Implicit Sparsification
Efficient Interpolation between Extragradient and Proximal Methods for Weak MVIs
Competitive Fair Scheduling with Predictions
Optimizing Posterior Samples for Bayesian Optimization via Rootfinding
Latent Bayesian Optimization via Autoregressive Normalizing Flows
Learning Dynamics of LLM Finetuning
Adaptive Gradient Clipping for Robust Federated Learning
LoCoDL: Communication-Efficient Distributed Learning with Local Training and Compression
TorchTitan: One-stop PyTorch native solution for production ready LLM pretraining
ET-SEED: EFFICIENT TRAJECTORY-LEVEL SE(3) EQUIVARIANT DIFFUSION POLICY
Optimization with Access to Auxiliary Information
Methods for Convex $(L_0,L_1)$-Smooth Optimization: Clipping, Acceleration, and Adaptivity
Few for Many: Tchebycheff Set Scalarization for Many-Objective Optimization
LoRA Done RITE: Robust Invariant Transformation Equilibration for LoRA Optimization
Collaborative Discrete-Continuous Black-Box Prompt Learning for Language Models
A Coefficient Makes SVRG Effective
An Optimal Discriminator Weighted Imitation Perspective for Reinforcement Learning
Energy-Weighted Flow Matching for Offline Reinforcement Learning
Long-Short Decision Transformer: Bridging Global and Local Dependencies for Generalized Decision-Making
Latent Safety-Constrained Policy Approach for Safe Offline Reinforcement Learning
Sensor-Invariant Tactile Representation
Offline Hierarchical Reinforcement Learning via Inverse Optimization
M^3PC: Test-time Model Predictive Control using Pretrained Masked Trajectory Model
Diffusion Actor-Critic: Formulating Constrained Policy Iteration as Diffusion Noise Regression for Offline Reinforcement Learning
Fewer May Be Better: Enhancing Offline Reinforcement Learning with Reduced Dataset
Self-Improvement for Neural Combinatorial Optimization: Sample Without Replacement, but Improvement
Langevin Soft Actor-Critic: Efficient Exploration through Uncertainty-Driven Critic Learning
Efficient Online Reinforcement Learning Fine-Tuning Need Not Retain Offline Data
Episodic Novelty Through Temporal Distance
Efficient Model-Based Reinforcement Learning Through Optimistic Thompson Sampling
Efficient Discovery of Pareto Front for Multi-Objective Reinforcement Learning
3DMolFormer: A Dual-channel Framework for Structure-based Drug Discovery
Generating Freeform Endoskeletal Robots
Looking Backward: Retrospective Backward Synthesis for Goal-Conditioned GFlowNets
PWM: Policy Learning with Multi-Task World Models
Language Guided Skill Discovery
Conflict-Averse Gradient Aggregation for Constrained Multi-Objective Reinforcement Learning
Online-to-Offline RL for Agent Alignment
Semantic Temporal Abstraction via Vision-Language Model Guidance for Efficient Reinforcement Learning
TOP-ERL: Transformer-based Off-Policy Episodic Reinforcement Learning
Discrete GCBF Proximal Policy Optimization for Multi-agent Safe Optimal Control
On the Linear Speedup of Personalized Federated Reinforcement Learning with Shared Representations
Efficient Multi-agent Offline Coordination via Diffusion-based Trajectory Stitching
EC-Diffuser: Multi-Object Manipulation via Entity-Centric Behavior Generation
Multi-agent cooperation through learning-aware policy gradients
DoF: A Diffusion Factorization Framework for Offline Multi-Agent Reinforcement Learning
IntersectionZoo: Eco-driving for Benchmarking Multi-Agent Contextual Reinforcement Learning
A Policy-Gradient Approach to Solving Imperfect-Information Games with Best-Iterate Convergence
Online Reinforcement Learning in Non-Stationary Context-Driven Environments
On Bits and Bandits: Quantifying the Regret-Information Trade-off
Reinforcement learning with combinatorial actions for coupled restless bandits
Epistemic Monte Carlo Tree Search
Solving New Tasks by Adapting Internet Video Knowledge
Simple, Good, Fast: Self-Supervised World Models Free of Baggage
What's the Move? Hybrid Imitation Learning via Salient Points
Let the Code LLM Edit Itself When You Edit the Code
Diversity-Rewarded CFG Distillation
Accelerating Goal-Conditioned Reinforcement Learning Algorithms and Research
A Black Swan Hypothesis: The Role of Human Irrationality in AI Safety
Skill Expansion and Composition in Parameter Space
REGENT: A Retrieval-Augmented Generalist Agent That Can Act In-Context in New Environments
Highly Efficient Self-Adaptive Reward Shaping for Reinforcement Learning
OMNI-EPIC: Open-endedness via Models of human Notions of Interestingness with Environments Programmed in Code
Handling Delay in Real-Time Reinforcement Learning
Safety-Prioritizing Curricula for Constrained Reinforcement Learning
A deep inverse-mapping model for a flapping robotic wing
MIA-DPO: Multi-Image Augmented Direct Preference Optimization For Large Vision-Language Models
Uncertainty and Influence aware Reward Model Refinement for Reinforcement Learning from Human Feedback
MOS: Model Synergy for Test-Time Adaptation on LiDAR-Based 3D Object Detection
Bridging the Gap between Variational Inference and Stochastic Gradient MCMC in Function Space
Bayesian Experimental Design Via Contrastive Diffusions
Training-Free Diffusion Model Alignment with Sampling Demons
Extendable and Iterative Structure Learning Strategy for Bayesian Networks
E-Valuating Classifier Two-Sample Tests
Credal Wrapper of Model Averaging for Uncertainty Estimation in Classification
Connecting Federated ADMM to Bayes
TVNet: A Novel Time Series Analysis Method Based on Dynamic Convolution and 3D-Variation
Approximating Full Conformal Prediction for Neural Network Regression with Gauss-Newton Influence
Test-Time Ensemble via Linear Mode Connectivity: A Path to Better Adaptation
Benign Overfitting in Out-of-Distribution Generalization of Linear Models
On the Adversarial Risk of Test Time Adaptation: An Investigation into Realistic Test-Time Data Poisoning
Finding and Only Finding Differential Nash Equilibria by Both Pretending to be a Follower
Stochastic Semi-Gradient Descent for Learning Mean Field Games with Population-Aware Function Approximation
Regret-Optimal List Replicable Bandit Learning: Matching Upper and Lower Bounds
How Gradient descent balances features: A dynamical analysis for two-layer neural networks
Algorithmic Stability Based Generalization Bounds for Adversarial Training
Binary Losses for Density Ratio Estimation
Learning vector fields of differential equations on manifolds with geometrically constrained operator-valued kernels
Theory on Mixture-of-Experts in Continual Learning
Limits to scalable evaluation at the frontier: LLM as judge won’t beat twice the data
Asymptotic Analysis of Two-Layer Neural Networks after One Gradient Step under Gaussian Mixtures Data with Structure
Semialgebraic Neural Networks: From roots to representations
Bandit Learning in Matching Markets with Indifference
InstaTrain: Adaptive Training via Ultra-Fast Natural Annealing within Dynamical Systems
Direct Distributional Optimization for Provable Alignment of Diffusion Models
GeoLoRA: Geometric integration for parameter efficient fine-tuning
Probabilistic Conformal Prediction with Approximate Conditional Validity
Revisiting a Design Choice in Gradient Temporal Difference Learning
TS-LIF: A Temporal Segment Spiking Neuron Network for Time Series Forecasting
Near-Optimal Policy Identification in Robust Constrained Markov Decision Processes via Epigraph Form
Probing the Latent Hierarchical Structure of Data via Diffusion Models
LevAttention: Time, Space and Streaming Efficient Algorithm for Heavy Attentions
Federated Class-Incremental Learning: A Hybrid Approach Using Latent Exemplars and Data-Free Techniques to Address Local and Global Forgetting
Incremental Causal Effect for Time to Treatment Initialization
Time After Time: Deep-Q Effect Estimation for Interventions on When and What to do
OpenHands: An Open Platform for AI Software Developers as Generalist Agents
Efficient and Trustworthy Causal Discovery with Latent Variables and Complex Relations
Do Contemporary Causal Inference Models Capture Real-World Heterogeneity? Findings from a Large-Scale Benchmark
Model-agnostic meta-learners for estimating heterogeneous treatment effects over time
Accelerating Neural ODEs: A Variational Formulation-based Approach
Efficient Causal Decision Making with One-sided Feedback
A Meta-Learning Approach to Bayesian Causal Discovery
THE ROBUSTNESS OF DIFFERENTIABLE CAUSAL DISCOVERY IN MISSPECIFIED SCENARIOS
Identifiable Exchangeable Mechanisms for Causal Structure and Representation Learning
Counterfactual Realizability
Simulating Training Dynamics to Reconstruct Training Data from Deep Neural Networks
Modeling Complex System Dynamics with Flow Matching Across Time and Conditions
An Information Criterion for Controlled Disentanglement of Multimodal Data
Towards a learning theory of representation alignment
Neural networks on Symmetric Spaces of Noncompact Type
W-PCA Based Gradient-Free Proxy for Efficient Search of Lightweight Language Models
CoRNStack: High-Quality Contrastive Data for Better Code Retrieval and Reranking
ColPali: Efficient Document Retrieval with Vision Language Models
Linear Spherical Sliced Optimal Transport: A Fast Metric for Comparing Spherical Data
Boosting Methods for Interval-censored Data with Regression and Classification
Learning Partial Graph Matching via Optimal Partial Transport
Coreset Spectral Clustering
Unsupervised Multiple Kernel Learning for Graphs via Ordinality Preservation
Divergence-enhanced Knowledge-guided Context Optimization for Visual-Language Prompt Tuning
Universal Sharpness Dynamics in Neural Network Training: Fixed Point Analysis, Edge of Stability, and Route to Chaos
Test-time Adaptation for Regression by Subspace Alignment
Both Ears Wide Open: Towards Language-Driven Spatial Audio Generation
ADAPT: Attentive Self-Distillation and Dual-Decoder Prediction Fusion for Continual Panoptic Segmentation
Fluid: Scaling Autoregressive Text-to-image Generative Models with Continuous Tokens
Learning Successor Features with Distributed Hebbian Temporal Memory
Long-Context Linear System Identification
Expand and Compress: Exploring Tuning Principles for Continual Spatio-Temporal Graph Forecasting
Error-quantified Conformal Inference for Time Series
CoMRes: Semi-Supervised Time Series Forecasting Utilizing Consensus Promotion of Multi-Resolution
Mastering Task Arithmetic: $\tau$Jp as a Key Indicator for Weight Disentanglement
SD-LoRA: Scalable Decoupled Low-Rank Adaptation for Class Incremental Learning
MetaOOD: Automatic Selection of OOD Detection Models
Proteina: Scaling Flow-based Protein Structure Generative Models
In vivo cell-type and brain region classification via multimodal contrastive learning
RECAST: Reparameterized, Compact weight Adaptation for Sequential Tasks
Progressive Parameter Efficient Transfer Learning for Semantic Segmentation
Fine-Tuning Attention Modules Only: Enhancing Weight Disentanglement in Task Arithmetic
REMEDY: Recipe Merging Dynamics in Large Vision-Language Models
Multimodality Helps Few-shot 3D Point Cloud Semantic Segmentation
FedTMOS: Efficient One-Shot Federated Learning with Tsetlin Machine
CLDyB: Towards Dynamic Benchmarking for Continual Learning with Pre-trained Models
GeoILP: A Synthetic Dataset to Guide Large-Scale Rule Induction
Probabilistic Learning to Defer: Handling Missing Expert Annotations and Controlling Workload Distribution
Towards hyperparameter-free optimization with differential privacy
BrainUICL: An Unsupervised Individual Continual Learning Framework for EEG Applications
Does Training with Synthetic Data Truly Protect Privacy?
The Last Iterate Advantage: Empirical Auditing and Principled Heuristic Analysis of Differentially Private SGD
Differentially private optimization for non-decomposable objective functions
Differentially Private Federated Learning with Time-Adaptive Privacy Spending
CipherPrune:  Efficient and Scalable Private Transformer Inference
Near-Exact Privacy Amplification for Matrix Mechanisms
Wicked Oddities: Selectively Poisoning for Effective Clean-Label Backdoor Attacks
Tailoring Mixup to Data for Calibration
CHiP: Cross-modal Hierarchical Direct Preference Optimization for Multimodal LLMs
Local-Prompt: Extensible Local Prompts for Few-Shot Out-of-Distribution Detection
SIMPL: Scalable and hassle-free optimisation of neural representations from behaviour
On Targeted Manipulation and Deception when Optimizing LLMs for User Feedback
ILLUSION: Unveiling Truth with a Comprehensive Multi-Modal, Multi-Lingual Deepfake Dataset
ReDeEP: Detecting Hallucination in Retrieval-Augmented Generation via Mechanistic Interpretability
Factor Graph-based Interpretable Neural Networks
RankSHAP: Shapley Value Based Feature Attributions for Learning to Rank
Walk the Talk? Measuring the Faithfulness of Large Language Model Explanations
TabWak: A Watermark for Tabular Diffusion Models
Sparse Autoencoders Do Not Find Canonical Units of Analysis
AttriBoT: A Bag of Tricks for Efficiently Approximating Leave-One-Out Context Attribution
NeurFlow: Interpreting Neural Networks through Neuron Groups and Functional Interactions
SleepSMC: Ubiquitous Sleep Staging via Supervised Multimodal Coordination
The Computational Complexity of Circuit Discovery for Inner Interpretability
Zero-Shot Natural Language Explanations
$\text{I}^2\text{AM}$: Interpreting Image-to-Image Latent Diffusion Models via Bi-Attribution Maps
Causal Concept Graph Models: Beyond Causal Opacity in Deep Learning
Do LLMs ``know'' internally when they follow instructions?
Metric-Driven Attributions for Vision Transformers
Mechanism and Emergence of Stacked Attention Heads in Multi-Layer Transformers
BBCaL: Black-box Backdoor Detection under the Causality Lens
Multimodal Situational Safety
Programming Refusal with Conditional Activation Steering
BLEND: Behavior-guided Neural Population Dynamics Modeling via Privileged Knowledge Distillation
First-Person Fairness in Chatbots
SORRY-Bench: Systematically Evaluating Large Language Model Safety Refusal
Mind Control through Causal Inference: Predicting Clean Images from Poisoned Data
AdvPaint: Protecting Images from Inpainting Manipulation via Adversarial Attention Disruption
Revealing and Reducing Gender Biases in Vision and Language Assistants (VLAs)
Jailbreak Antidote: Runtime Safety-Utility Balance via Sparse Representation Adjustment in Large Language Models
VideoShield: Regulating Diffusion-based Video Generation Models via Watermarking
SafeWatch: An Efficient Safety-Policy Following Video Guardrail Model with Transparent Explanations
Mentored Learning: Improving Generalization and Convergence of Student Learner
A Visual Dive into Conditional Flow Matching
Beyond single neurons: population response geometry in digital twins of mouse visual cortex
Multi-modal Learning: A Look Back and the Road Ahead
Do vision models perceive objects like toddlers ?
Multi-LLM-Agents Debate - Performance, Efficiency, and Scaling Challenges
Building Blocks of Differentially Private Training
AdvWave: Stealthy Adversarial Jailbreak Attack against Large Audio-Language Models
RTDiff: Reverse Trajectory Synthesis via Diffusion for Offline Reinforcement Learning
Are Transformers Able to Reason by Connecting Separated Knowledge in Training Data?
RMP-SAM: Towards Real-Time Multi-Purpose Segment Anything
Multi-Field Adaptive Retrieval
DiffPuter: Empowering Diffusion Models for Missing Data Imputation
MindSimulator: Exploring Brain Concept Localization via Synthetic fMRI
CR2PQ: Continuous Relative Rotary Positional Query for Dense Visual Representation Learning
Unlearn and Burn: Adversarial Machine Unlearning Requests Destroy Model Accuracy
SPA: 3D Spatial-Awareness Enables Effective Embodied Representation
MTU-Bench: A Multi-granularity Tool-Use Benchmark for Large Language Models
Wayward Concepts In Multimodal Models
Small-to-Large Generalization: Training Data Influences Models Consistently Across Scale
Towards Unbiased Learning in Semi-Supervised Semantic Segmentation
PICASO: Permutation-Invariant Context Composition with State Space Models
EgoExo-Gen: Ego-centric Video Prediction by Watching Exo-centric Videos
DenseMatcher: Learning 3D Semantic Correspondence for Category-Level Manipulation from a Single Demo
InCoDe: Interpretable Compressed Descriptions For Image Generation
3D-Properties: Identifying Challenges in DPO and Charting a Path Forward
Hymba: A Hybrid-head Architecture for Small Language Models
FormalAlign: Automated Alignment Evaluation for Autoformalization
Hot-pluggable Federated Learning: Bridging General and Personalized FL via Dynamic Selection
A Robust Method to Discover Causal or Anticausal Relation
Intermediate Layer Classifiers for OOD generalization
QA-Calibration of Language Model Confidence Scores
GPUDrive: Data-driven, multi-agent driving simulation at 1 million FPS
Lumina-T2X: Scalable Flow-based Large Diffusion Transformer for Flexible Resolution Generation
The Ramanujan Library - Automated Discovery on the Hypergraph of Integer Relations
DSPO: Direct Score Preference Optimization for Diffusion Model Alignment
Retrieval Head Mechanistically Explains Long-Context Factuality
DataGen: Unified Synthetic Dataset Generation via Large Language Models
Asynchronous RLHF: Faster and More Efficient Off-Policy RL for Language Models
SLMRec: Distilling Large Language Models into Small for Sequential Recommendation
Narrowing Information Bottleneck Theory for Multimodal Image-Text Representations Interpretability
The Directionality of Optimization Trajectories in Neural Networks
Beyond Model Collapse: Scaling Up with Synthesized Data Requires Verification
3DIS: Depth-Driven Decoupled Image Synthesis for Universal Multi-Instance Generation
Anti-Exposure Bias in Diffusion Models
Multi-Draft Speculative Sampling: Canonical Decomposition and Theoretical Limits
Improving Text-to-Image Consistency via Automatic Prompt Optimization
Optimal Flow Transport and its Entropic Regularization: a GPU-friendly Matrix Iterative Algorithm for Flow Balance Satisfaction
Learning Robust Representations with Long-Term Information for Generalization in Visual Reinforcement Learning
LVSM: A Large View Synthesis Model with Minimal 3D Inductive Bias
SRSA: Skill Retrieval and Adaptation for Robotic Assembly Tasks
Grounding Video Models to Actions through Goal Conditioned Exploration
Adaptive backtracking for faster optimization
Dynamic Mixture of Experts: An Auto-Tuning Approach for Efficient Transformer Models
Uncertainty Modeling in Graph Neural Networks via Stochastic Differential Equations
Discovering Group Structures via Unitary Representation Learning
REBIND: Enhancing Ground-state Molecular Conformation Prediction via Force-Based Graph Rewiring
Flaws of ImageNet, Computer Vision's Favourite Dataset
SlowFast-VGen: Slow-Fast Learning for Action-Driven Long Video Generation
Decision Tree Induction Through LLMs via Semantically-Aware Evolution
Contextual Document Embeddings
Decoupling Angles and Strength in Low-rank Adaptation
EmbodiedSAM: Online Segment Any 3D Thing in Real Time
BOFormer: Learning to Solve Multi-Objective Bayesian Optimization via Non-Markovian RL
LaMPlace: Learning to Optimize Cross-Stage Metrics in Macro Placement
Dissecting Adversarial Robustness of Multimodal LM Agents
Pangea: A Fully Open Multilingual Multimodal LLM for 39 Languages
Brain-inspired $L_p$-Convolution benefits large kernels and aligns better with visual cortex
How to Evaluate Reward Models for RLHF
Federated Residual Low-Rank Adaption of Large Language Models
Learning Clustering-based Prototypes for Compositional Zero-Shot Learning
Why Does the Effective Context Length of LLMs Fall Short?
Exploring The Forgetting in Adversarial Training: A Novel Method for Enhancing Robustness
Vision Language Models are In-Context Value Learners
LoRA-Pro: Are Low-Rank Adapters Properly Optimized?
Real-Time Video Generation with Pyramid Attention Broadcast
AI as Humanity’s Salieri: Quantifying Linguistic Creativity of Language Models via Systematic Attribution of Machine Text against Web Text
Fundamental Limits of Prompt Tuning Transformers: Universality, Capacity and Efficiency
Influence-Guided Diffusion for Dataset Distillation
UniDrive: Towards Universal Driving Perception Across Camera Configurations
Improving Data Efficiency via Curating LLM-Driven Rating Systems
Quantifying Generalization Complexity for Large Language Models
Unearthing Skill-level Insights for Understanding Trade-offs of Foundation Models
BenTo: Benchmark Reduction with In-Context Transferability
OmniBind: Large-scale Omni Multimodal Representation via Binding Spaces
Retri3D: 3D Neural Graphics Representation Retrieval
PIORF: Physics-Informed Ollivier-Ricci Flow for Long–Range Interactions in Mesh Graph Neural Networks
Do LLM Agents  Have Regret? A Case Study in Online Learning and Games
Locality Alignment Improves Vision-Language Models
6D Object Pose Tracking in Internet Videos for Robotic Manipulation
Demystifying the Token Dynamics of Deep Selective State Space Models
4K4DGen: Panoramic 4D Generation at 4K Resolution
Monte Carlo Planning with Large Language Model for Text-Based Game Agents
Robust Transfer of Safety-Constrained Reinforcement Learning Agents
What Are Good Positional Encodings for Directed Graphs?
ChartMimic: Evaluating LMM's Cross-Modal Reasoning Capability via Chart-to-Code Generation
Scaling and evaluating sparse autoencoders
Model-based RL as a Minimalist Approach to Horizon-Free and Second-Order Bounds
Param$\Delta$ for Direct Mixing: Post-Train Large Language Model At Zero Cost
SBSC: Step-by-Step Coding for Improving Mathematical Olympiad Performance
TexTailor: Customized Text-aligned Texturing via Effective Resampling
Distilled Decoding 1: One-step Sampling of Image Auto-regressive Models with Flow Matching
Language-Assisted Feature Transformation for Anomaly Detection
IPDreamer: Appearance-Controllable 3D Object Generation with Complex Image Prompts
Graph-Guided Scene Reconstruction from Images with 3D Gaussian Splatting
LoR-VP: Low-Rank Visual Prompting for Efficient Vision Model Adaptation
High-dimension Prototype is a Better Incremental Object Detection Learner
Composing Unbalanced Flows for Flexible Docking and Relaxation
Proximal Mapping Loss: Understanding Loss Functions in Crowd Counting & Localization
Streaming Video Question-Answering with In-context Video KV-Cache Retrieval
Reconstructive Visual Instruction Tuning
Consistent Flow Distillation for Text-to-3D Generation
I2VControl-Camera: Precise Video Camera Control with Adjustable Motion Strength
Open-YOLO 3D: Towards Fast and Accurate Open-Vocabulary 3D Instance Segmentation
PIN: Prolate Spheroidal Wave Function-based Implicit Neural Representations
SAM 2: Segment Anything in Images and Videos
X-Drive: Cross-modality Consistent Multi-Sensor Data Synthesis for Driving Scenarios
SMITE: Segment Me In TimE
ChemAgent: Self-updating Memories in Large Language Models Improves Chemical Reasoning
YOLO-RD: Introducing Relevant and Compact Explicit Knowledge to YOLO by Retriever-Dictionary
PaRa: Personalizing Text-to-Image Diffusion via Parameter Rank Reduction
Sketch2Diagram: Generating Vector Diagrams from Hand-Drawn Sketches
Leveraging Driver Field-of-View for Multimodal Ego-Trajectory Prediction
Bringing NeRFs to the Latent Space: Inverse Graphics Autoencoder
Chain-of-region: Visual Language Models Need  Details for Diagram Analysis
MamBEV: Enabling State Space Models to Learn Birds-Eye-View Representations
Weighted Multi-Prompt Learning with Description-free Large Language Model Distillation
Cafe-Talk: Generating 3D Talking Face Animation with Multimodal Coarse- and Fine-grained Control
HiSplat: Hierarchical 3D Gaussian Splatting for Generalizable Sparse-View Reconstruction
E(3)-equivariant models cannot learn chirality: Field-based molecular generation
Vision-LSTM: xLSTM as Generic Vision Backbone
State Space Model Meets Transformer: A New Paradigm for 3D Object Detection
Bridging Information Asymmetry in Text-video Retrieval: A Data-centric Approach
Knowing Your Target: Target-Aware Transformer Makes Better Spatio-Temporal Video Grounding
Synergy and Diversity in CLIP: Enhancing Performance Through Adaptive Backbone Ensembling
Dense Video Object Captioning from Disjoint Supervision
NarrativeBridge: Enhancing Video Captioning with Causal-Temporal Narrative
Beyond FVD: An Enhanced Evaluation Metrics for Video Generation Distribution Quality
MAI: A Multi-turn Aggregation-Iteration Model for Composed Image Retrieval
SynCamMaster: Synchronizing Multi-Camera Video Generation from Diverse Viewpoints
(ends 5:30 PM)
Break:
(ends 3:30 PM)
3:30 p.m.
Oral Session 4A
[3:30-5:00]
3:30-4:42
[3:30]
More RLHF, More Trust? On The Impact of Preference Alignment On Trustworthiness
[3:42]
Measuring and Enhancing Trustworthiness of LLMs in RAG through Grounded Attributions and Learning to Refuse
[3:54]
Iterative Nash Policy Optimization: Aligning LLMs with General Preferences via No-Regret Learning
[4:06]
RM-Bench: Benchmarking Reward Models of Language Models with Subtlety and Style
[4:18]
REEF: Representation Encoding Fingerprints for Large Language Models
[4:30]
Rethinking Reward Modeling in Preference-based Large Language Model Alignment
(ends 5:00 PM)
Oral Session 4B
[3:30-5:00]
3:30-4:42
[3:30]
From Exploration to Mastery: Enabling LLMs to Master Tools via Self-Driven Interactions
[3:42]
Spider 2.0: Evaluating Language Models on Real-World Enterprise Text-to-SQL Workflows
[3:54]
BigCodeBench: Benchmarking Code Generation with Diverse Function Calls and Complex Instructions
[4:06]
LLM-SR: Scientific Equation Discovery via Programming with Large Language Models
[4:18]
Cybench: A Framework for Evaluating Cybersecurity Capabilities and Risks of Language Models
[4:30]
AFlow: Automating Agentic Workflow Generation
(ends 5:00 PM)
Oral Session 4C
[3:30-5:00]
3:30-4:42
[3:30]
Compositional Entailment Learning for Hyperbolic Vision-Language Models
[3:42]
Do Vision-Language Models Represent Space and How? Evaluating Spatial Frame of Reference under Ambiguities
[3:54]
Topological Blindspots: Understanding and Extending Topological Deep Learning Through the Lens of Expressivity
[4:06]
Population Transformer: Learning Population-level Representations of Neural Activity
[4:18]
TopoLM: brain-like spatio-functional organization in a topographic language model
[4:30]
The Geometry of Categorical and Hierarchical Concepts in Large Language Models
(ends 5:00 PM)
Oral Session 4D
[3:30-5:00]
3:30-4:42
[3:30]
Open-Vocabulary Customization from CLIP via Data-Free Knowledge Distillation
[3:42]
GridMix: Exploring Spatial Modulation for Neural Fields in PDE Modeling
[3:54]
Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model
[4:06]
RB-Modulation: Training-Free Stylization using Reference-Based Modulation
[4:18]
Toward Guidance-Free AR Visual Generation via Condition Contrastive Alignment
[4:30]
Ctrl-Adapter: An Efficient and Versatile Framework for Adapting Diverse Controls to Any Diffusion Model
(ends 5:00 PM)
Oral Session 4E
[3:30-5:00]
3:30-4:42
[3:30]
Synthetic continued pretraining
[3:42]
Energy-based Backdoor Defense Against Federated Graph Learning
[3:54]
Problem-Parameter-Free Federated Learning
[4:06]
Subgraph Federated Learning for Local Generalization
[4:18]
Copyright-Protected Language Generation via Adaptive Model Fusion
[4:30]
Capturing the Temporal Dependence of Training Data Influence
(ends 5:00 PM)
Oral Session 4F
[3:30-5:00]
3:30-4:42
[3:30]
Cut Your Losses in Large-Vocabulary Language Models
[3:42]
Your Mixture-of-Experts LLM Is Secretly an Embedding Model for Free
[3:54]
ChartMoE: Mixture of Diversely Aligned Expert Connector for Chart Understanding
[4:06]
MaestroMotif: Skill Design from Artificial Intelligence Feedback
[4:18]
MoE++: Accelerating Mixture-of-Experts Methods with Zero-Computation Experts
[4:30]
OLMoE: Open Mixture-of-Experts Language Models
(ends 5:00 PM)
5 p.m.
Social:
Data-Centric AI Social
(ends 6:30 PM)
Social:
Open-source Decentralized AI Community Social hosted by Flower
(ends 6:30 PM)
Social:
LatinX in AI Social
(ends 6:30 PM)
Social:
Test-Time Scaling for LLMs
(ends 6:30 PM)
5:30 p.m.
Test Of Time:
Test of Time Winner and Runner Up Presentations
(ends 6:30 PM)
SAT 26 APR
9 a.m.
Invited Talk:
Training Language Models in Academia: Challenge or Calling?
Danqi Chen
(ends 10:00 AM)
Invited Talk:
Overflow: Training Language Models in Academia: Challenge or Calling?
Danqi Chen
(ends 10:00 AM)
10 a.m.
Poster Session 5
[10:00-12:30]
Poster
10:00-12:30
Fast Uncovering of Protein Sequence Diversity from Structure
MOFFlow: Flow Matching for Structure Prediction of Metal-Organic Frameworks
Locality Sensitive Avatars From Video
Co$^{\mathbf{3}}$Gesture: Towards Coherent Concurrent Co-speech 3D Gesture Generation with Interactive Diffusion
ProtoSnap: Prototype Alignment For Cuneiform Signs
StochSync: Stochastic Diffusion Synchronization for Image Generation in Arbitrary Spaces
MP-Mat: A 3D-and-Instance-Aware Human Matting and Editing Framework with Multiplane Representation
Glad: A Streaming Scene Generator for Autonomous Driving
On the Transfer of Object-Centric Representation Learning
ReMatching Dynamic Reconstruction Flow
CertainlyUncertain: A Benchmark and Metric for Multimodal Epistemic and Aleatoric Awareness
Occlusion-aware Non-Rigid Point Cloud Registration via Unsupervised Neural Deformation Correntropy
CL-MFAP: A Contrastive Learning-Based Multimodal Foundation Model for Molecular Property Prediction and Antibiotic Screening
Progressive Token Length Scaling in Transformer Encoders for Efficient Universal Segmentation
Recognize Any Surgical Object: Unleashing the Power of Weakly-Supervised Data
CHAMP: Conformalized 3D Human Multi-Hypothesis Pose Estimators
Prompt as Knowledge Bank: Boost Vision-language model via Structural Representation for  zero-shot medical detection
TEASER: Token Enhanced Spatial Modeling for Expressions Reconstruction
Multi-Perspective Data Augmentation for Few-shot Object Detection
Generalized Video Moment Retrieval
High-quality Text-to-3D Character Generation with SparseCubes and Sparse Transformers.
IDArb: Intrinsic Decomposition for Arbitrary Number of Input Views and Illuminations
RESfM: Robust Deep Equivariant Structure from Motion
Generative Flows on Synthetic Pathway for Drug Design
ThermalGaussian: Thermal 3D Gaussian Splatting
Operator Deep Smoothing for Implied Volatility
Simulating Human-like Daily Activities with Desire-driven Autonomy
TestGenEval: A Real World Unit Test Generation and Test Completion Benchmark
Hierarchically Encapsulated Representation for Protocol Design in Self-Driving Labs
Empowering Users in Digital Privacy Management through Interactive LLM-Based Agents
Natural Language Inference Improves Compositionality in Vision-Language Models
BirdSet: A Large-Scale Dataset for Audio Classification in Avian Bioacoustics
CarbonSense: A Multimodal Dataset and Baseline for Carbon Flux Modelling
Flow: Modularized Agentic Workflow Automation
Multimodal Large Language Models for Inverse Molecular Design with Retrosynthetic Planning
CryoGEN: Generative Energy-based Models for Cryogenic Electron Tomography Reconstruction
Remove Symmetries to Control Model Expressivity and Improve Optimization
Do Deep Neural Network Solutions Form a Star Domain?
Human-Aligned Chess With a Bit of Search
Training-Free Activation Sparsity in Large Language Models
Local Loss Optimization in the Infinite Width: Stable Parameterization of Predictive Coding Networks and Target Propagation
FLOPS: Forward Learning with OPtimal Sampling
Linear Transformer Topological Masking with Graph Random Features
Attention with Markov: A Curious Case of Single-layer Transformers
Attention as a Hypernetwork
KinPFN: Bayesian Approximation of RNA Folding Kinetics using Prior-Data Fitted Networks
Adaptive Transformer Programs: Bridging the Gap Between Performance and Interpretability in Transformers
Distributional Associations vs In-Context Reasoning: A Study of Feed-forward and Attention Layers
Geometry of Lightning Self-Attention: Identifiability and Dimension
Emergence of meta-stable clustering in mean-field transformer models
PolaFormer: Polarity-aware Linear Attention for Vision Transformers
Token Statistics Transformer: Linear-Time Attention via Variational Rate Reduction
HART: Efficient Visual Generation with Hybrid Autoregressive Transformer
LayerDAG: A Layerwise Autoregressive Diffusion Model for Directed Acyclic Graph Generation
Learning multi-modal generative models with permutation-invariant encoders and tighter variational objectives
Conformal Generative Modeling with Improved Sample Efficiency through Sequential Greedy Filtering
Regulatory DNA Sequence Design with Reinforcement Learning
T-Stitch: Accelerating Sampling in Pre-Trained Diffusion Models with Trajectory Stitching
Distribution Backtracking Builds A Faster Convergence Trajectory for Diffusion Distillation
Fourier Head: Helping Large Language Models Learn Complex Probability Distributions
LaGeM: A Large Geometry Model for 3D Representation Learning and Diffusion
DRoP: Distributionally Robust Data Pruning
HALL-E: Hierarchical Neural Codec Language Model for Minute-Long Zero-Shot Text-to-Speech Synthesis
Training Language Models on Synthetic Edit Sequences Improves Code Synthesis
ACE: All-round Creator and Editor Following Instructions via Diffusion Transformer
Trivialized Momentum Facilitates Diffusion Generative Modeling on Lie Groups
MLLMs Know Where to Look: Training-free Perception of Small Visual Details with Multimodal LLMs
Size-Generalizable RNA Structure Evaluation by Exploring Hierarchical Geometries
SymmetricDiffusers: Learning Discrete Diffusion on Finite Symmetric Groups
Discrete Copula Diffusion
3DTrajMaster: Mastering 3D Trajectory for Multi-Entity Motion in Video Generation
Atlas Gaussians Diffusion for 3D Generation
Glauber Generative Model: Discrete Diffusion Models via Binary Classification
Faster Diffusion Sampling with Randomized Midpoints: Sequential and Parallel
Generalization in VAE and Diffusion Models: A Unified Information-Theoretic Analysis
Where Am I and What Will I See: An Auto-Regressive Model for Spatial Localization and View Prediction
Fast Direct: Query-Efficient  Online Black-box Guidance  for Diffusion-model Target Generation
Improved Training Technique for Latent Consistency Models
PhyloVAE: Unsupervised Learning of Phylogenetic Trees via Variational Autoencoders
Domain Guidance: A Simple Transfer Approach for a Pre-trained Diffusion Model
Halton Scheduler for Masked Generative Image Transformer
Generator Matching: Generative modeling with arbitrary Markov processes
VideoGrain: Modulating Space-Time Attention for Multi-Grained Video Editing
BinaryDM: Accurate Weight Binarization for Efficient Diffusion Models
Multilevel Generative Samplers for Investigating Critical Phenomena
Repetition Improves Language Model Embeddings
CoInD: Enabling Logical Compositions in Diffusion Models
Denoising with a Joint-Embedding Predictive Architecture
Diffusion Bridge AutoEncoders for Unsupervised Representation Learning
CLIBD: Bridging Vision and Genomics for Biodiversity Monitoring at Scale
Mining your own secrets: Diffusion Classifier Scores for Continual Personalization of Text-to-Image Diffusion Models
OpenVid-1M: A Large-Scale High-Quality Dataset for Text-to-video Generation
Diffusion State-Guided Projected Gradient for Inverse Problems
ParetoFlow: Guided Flows in Multi-Objective Optimization
CONTRA: Conformal Prediction Region via Normalizing Flow Transformation
$InterLCM$: Low-Quality Images as Intermediate States of Latent Consistency Models for Effective Blind Face Restoration
Warm Diffusion: Recipe for Blur-Noise Mixture Diffusion Models
Faster Inference of Flow-Based Generative Models via Improved Data-Noise Coupling
PianoMotion10M: Dataset and Benchmark for Hand Motion Generation in Piano Performance
Representational Similarity via Interpretable Visual Concepts
LeFusion: Controllable Pathology Synthesis via Lesion-Focused Diffusion Models
JetFormer: An autoregressive generative model of raw images and text
Flow Matching with General Discrete Paths: A Kinetic-Optimal Perspective
Multimodal Quantitative Language for Generative Recommendation
Neural Approximate Mirror Maps for Constrained Diffusion Models
Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models
A Unified Framework for Forward and Inverse Problems in Subsurface Imaging using Latent Space Translations
MVTokenFlow: High-quality 4D Content Generation using Multiview Token Flow
Re-Imagining Multimodal Instruction Tuning: A Representation View
Graph Sparsification via Mixture of Graphs
Edge Prompt Tuning for Graph Neural Networks
Towards Fast, Specialized Machine Learning Force Fields: Distilling Foundation Models via Energy Hessians
MuHBoost: Multi-Label Boosting For Practical Longitudinal Human Behavior Modeling
Learning Efficient Positional Encodings with Graph Neural Networks
DiffGAD: A Diffusion-based Unsupervised Graph Anomaly Detector
Matcha: Mitigating Graph Structure Shifts with Test-Time Adaptation
Let Your Features Tell The Differences: Understanding Graph Convolution By Feature Splitting
From GNNs to Trees: Multi-Granular Interpretability for Graph Neural Networks
Demystifying Topological Message-Passing with Relational Structures: A Case Study on Oversquashing in Simplicial Message-Passing
Graph Neural Networks Gone Hogwild
Improving Equivariant Networks with Probabilistic Symmetry Breaking
BANGS: Game-theoretic Node Selection for Graph Self-Training
Residual Connections and Normalization Can Provably Prevent Oversmoothing in GNNs
Efficiently Democratizing Medical LLMs for 50 Languages via a Mixture of Language Family Experts
GOFA: A Generative One-For-All Model for Joint Graph Language Modeling
Neural Causal Graph for Interpretable and Intervenable Classification
Scalable and Certifiable Graph Unlearning: Overcoming the Approximation Error Barrier
Bundle Neural Network for message diffusion on graphs
Learning Distributions of Complex Fluid Simulations with Diffusion Graph Networks
MaxCutPool: differentiable feature-aware Maxcut for pooling in graph neural networks
GPromptShield: Elevating Resilience in Graph Prompt Tuning Against Adversarial Attacks
Personalized Visual Instruction Tuning
Pre-training of Foundation Adapters for LLM Fine-tuning
Peeking Behind Closed Doors: Risks of LLM Evaluation by Private Data Curators
ECHOPulse: ECG Controlled Echocardio-gram Video Generation
Does Editing Provide Evidence for Localization?
Benchmarking Vision Language Model Unlearning via Fictitious Facial Identity Dataset
Feast Your Eyes:  Mixture-of-Resolution Adaptation for Multimodal Large Language Models
On a Connection Between Imitation Learning and RLHF
Seq-VCR: Preventing  Collapse in Intermediate Transformer Representations for Enhanced Reasoning
On Speeding Up Language Model Evaluation
Automatic Curriculum Expert Iteration for Reliable LLM Reasoning
MoDeGPT: Modular Decomposition for Large Language Model Compression
SciLitLLM: How to Adapt LLMs for Scientific Literature Understanding
Do LLMs have Consistent Values?
Time-to-Event Pretraining for 3D Medical Imaging
R-Sparse: Rank-Aware Activation Sparsity for Efficient LLM Inference
Generating CAD Code with Vision-Language Models for 3D Designs
Number Cookbook: Number Understanding of Language Models and How to Improve It
Generative Verifiers: Reward Modeling as Next-Token Prediction
Enhancing Document Understanding with Group Position Embedding: A Novel Approach to Incorporate Layout Information
Scaling FP8 training to trillion-token LLMs
On Linear Representations and Pretraining Data Frequency in Language Models
Controllable Safety Alignment: Inference-Time Adaptation to Diverse Safety Requirements
MMRole: A Comprehensive Framework for Developing and Evaluating Multimodal Role-Playing Agents
Teaching LLMs How to Learn with Contextual Fine-Tuning
Can Transformers Do Enumerative Geometry?
The Semantic Hub Hypothesis: Language Models Share Semantic Representations Across Languages and Modalities
Unhackable Temporal Reward for Scalable Video MLLMs
Round and Round We Go! What makes Rotary Positional Encodings useful?
Training Large Language Models for Retrieval-Augmented Question Answering through Backtracking Correction
Generalization v.s. Memorization: Tracing Language Models’ Capabilities Back to Pretraining Data
What's New in My Data? Novelty Exploration via Contrastive Generation
Improving Reasoning Performance in Large Language Models via Representation Engineering
LLMs Can Plan Only If We Tell Them
RobustKV: Defending Large Language Models against Jailbreak Attacks via KV Eviction
SPAM: Spike-Aware Adam with Momentum Reset for Stable LLM Training
Solving Differential Equations with Constrained Learning
ALLaM: Large Language Models for Arabic and English
DS-LLM: Leveraging Dynamical Systems to Enhance Both Training and Inference of Large Language Models
SPA-BENCH: A COMPREHENSIVE BENCHMARK FOR SMARTPHONE AGENT EVALUATION
Wavelet-based Positional Representation for Long Context
Gumbel Counterfactual Generation From Language Models
Measuring memorization in RLHF for code completion
Triples as the Key: Structuring Makes Decomposition and Verification Easier in LLM-based TableQA
Reasoning Elicitation in Language Models via Counterfactual Feedback
ObscuraCoder: Powering Efficient Code LM Pre-Training Via Obfuscation Grounding
OSCAR: Operating System Control via State-Aware Reasoning and Re-Planning
Spectral-Refiner: Accurate Fine-Tuning of Spatiotemporal Fourier Neural Operator for Turbulent Flows
Self-Improvement in Language Models: The Sharpening Mechanism
MA-RLHF: Reinforcement Learning from Human Feedback with Macro Actions
Relaxed Recursive Transformers: Effective Parameter Sharing with Layer-wise LoRA
Fine-tuning can Help Detect Pretraining Data from Large Language Models
ReGenesis: LLMs can Grow into Reasoning Generalists via Self-Improvement
Calibrating LLMs with Information-Theoretic Evidential Deep Learning
SaMer: A Scenario-aware Multi-dimensional Evaluator for Large Language Models
Is Factuality Enhancement a Free Lunch For LLMs? Better Factuality Can Lead to Worse Context-Faithfulness
DARE the Extreme: Revisiting Delta-Parameter Pruning For Fine-Tuned Models
Wasserstein Distances, Neuronal Entanglement, and Sparsity
MeshMask: Physics-Based Simulations with Masked Graph Neural Networks
Calibrating Expressions of Certainty
Quantum-PEFT: Ultra parameter-efficient fine-tuning
Reasoning with Latent Thoughts: On the Power of Looped Transformers
UniDetox: Universal Detoxification of Large Language Models via Dataset Distillation
LongMamba: Enhancing Mamba's Long-Context Capabilities via Training-Free Receptive Field Enlargement
Strategist: Self-improvement of LLM Decision Making via Bi-Level Tree Search
ClimaQA: An Automated Evaluation Framework for Climate Question Answering Models
Drop-Upcycling: Training Sparse Mixture of Experts with Partial Re-initialization
Bridging and Modeling Correlations in Pairwise Data for Direct Preference Optimization
FOSP: Fine-tuning Offline Safe Policy through World Models
Diff-PIC: Revolutionizing Particle-In-Cell Nuclear Fusion Simulation with Diffusion Models
PaCA: Partial Connection Adaptation for Efficient Fine-Tuning
Proactive Privacy Amnesia for Large Language Models: Safeguarding PII with Negligible Impact on Model Utility
DRESSing Up LLM: Efficient Stylized Question-Answering via Style Subspace Editing
Is Your Model Really A Good Math Reasoner? Evaluating Mathematical Reasoning with Checklist
Neuron-based Multifractal Analysis of Neuron Interaction Dynamics in Large Models
Not All LLM-Generated Data Are Equal: Rethinking Data Weighting in Text Classification
Task-Adaptive Pretrained Language Models via Clustered-Importance Sampling
Rethinking Invariance in In-context Learning
MMDT: Decoding the Trustworthiness and Safety of Multimodal Foundation Models
A Statistical Framework for Ranking LLM-based Chatbots
AstroCompress: A benchmark dataset for multi-purpose compression of astronomical data
Systematic Outliers in Large Language Models
Beyond Linear Approximations: A Novel Pruning Approach for Attention Matrix
Cheating Automatic LLM Benchmarks: Null Models Achieve High Win Rates
Addax: Utilizing Zeroth-Order Gradients to Improve Memory Efficiency and Performance of SGD for Fine-Tuning Language Models
Hierarchical Autoregressive Transformers: Combining Byte- and Word-Level Processing for Robust, Adaptable Language Models
LLaVA-MoD: Making LLaVA Tiny via MoE-Knowledge Distillation
ScImage: How good are multimodal large language models at scientific text-to-image generation?
Scaling Laws for Downstream Task Performance in Machine Translation
Faster Cascades via Speculative Decoding
LLM-based Typed Hyperresolution for Commonsense Reasoning with Knowledge Bases
Iterative Substructure Extraction for Molecular Relational Learning with Interactive Graph Information Bottleneck
No Equations Needed: Learning System Dynamics Without Relying on Closed-Form ODEs
Language Models Learn to Mislead Humans via RLHF
JudgeLM: Fine-tuned Large Language Models are Scalable Judges
MeteoRA: Multiple-tasks Embedded LoRA for Large Language Models
Causally Motivated Sycophancy Mitigation for Large Language Models
Forewarned is Forearmed:  Harnessing LLMs for Data Synthesis via Failure-induced Exploration
Generalizing Reasoning Problems to Longer Lengths
Enhancing Federated Domain Adaptation with Multi-Domain Prototype-Based Federated Fine-Tuning
SelKD: Selective Knowledge Distillation via Optimal Transport Perspective
A Differentiable Rank-Based Objective for Better Feature Learning
Improving Neural Network Accuracy by Concurrently Training with a Twin Network
Dualformer: Controllable Fast and Slow Thinking by Learning with Randomized Reasoning Traces
Interaction Asymmetry: A General Principle for Learning Composable Abstractions
CAX: Cellular Automata Accelerated in JAX
TULIP: Token-length Upgraded CLIP
CircuitFusion: Multimodal Circuit Representation Learning for Agile Chip Design
JPEG Inspired Deep Learning
Multiple Heads are Better than One: Mixture of Modality Knowledge Experts for Entity Representation Learning
Schur's Positive-Definite Network: Deep Learning in the SPD cone with structure
Resolution Attack: Exploiting Image Compression to Deceive Deep Neural Networks
Towards Unbiased Calibration using Meta-Regularization
Endowing Visual Reprogramming with Adversarial Robustness
Deep Signature: Characterization of Large-Scale Molecular Dynamics
Training Robust Ensembles Requires Rethinking Lipschitz Continuity
MixMax: Distributional Robustness in Function Space via Optimal Data Mixtures
ADBM: Adversarial Diffusion Bridge Model for Reliable Adversarial Purification
Addressing Label Shift in Distributed Learning via Entropy Regularization
Generative Classifiers Avoid Shortcut Solutions
Revisiting Feature Prediction for Learning Visual Representations from Video
DebGCD: Debiased Learning with Distribution Guidance for Generalized Category Discovery
Sylber: Syllabic Embedding Representation of Speech from Raw Audio
A Unifying Framework for Representation Learning
ASTrA: Adversarial Self-supervised Training with Adaptive-Attacks
RoboCat: A Self-Improving Generalist Agent for Robotic Manipulation
Mitigate the Gap: Improving Cross-Modal Alignment in CLIP
Beyond Interpretability: The Gains of Feature Monosemanticity on Model Robustness
Weighted Point Set Embedding for Multimodal Contrastive Learning Toward Optimal Similarity Metric
SSOLE: Rethinking Orthogonal Low-rank Embedding for Self-Supervised Learning
How Two-Layer Neural Networks Learn, One (Giant) Step at a Time
How do we interpret the outputs of a neural network trained on classification?
Prediction Risk and Estimation Risk of the Ridgeless Least Squares Estimator under General Assumptions on Regression Errors
Implicit Bias of Mirror Flow for Shallow Neural Networks in Univariate Regression
Connectome Mapping: Shape-Memory Network via Interpretation of Contextual Semantic Information
Three Mechanisms of Feature Learning in a Linear Network
Actions Speak Louder Than Words: Rate-Reward Trade-off in Markov Decision Processes
From Lazy to Rich: Exact Learning Dynamics in Deep Linear Networks
When is Task Vector Provably Effective for Model Editing? A Generalization Analysis of Nonlinear Transformers
HOPE for a Robust Parameterization of Long-memory State Space Models
CATCH: Channel-Aware Multivariate Time Series Anomaly Detection via Frequency Patching
Shedding Light on Time Series Classification using Interpretability Gated Networks
GIFT: Unlocking Full Potential of Labels in Distilled Dataset at Near-zero Cost
Accelerated training through iterative gradient propagation along the residual path
Towards Calibrated Deep Clustering Network
TabReD: Analyzing Pitfalls and Filling the Gaps in Tabular Deep Learning Benchmarks
MLPs Learn In-Context on Regression and Classification Tasks
LocoVR: Multiuser Indoor Locomotion Dataset in Virtual Reality
Noise Separation guided Candidate Label Reconstruction for Noisy Partial Label Learning
HyperPLR: Hypergraph Generation through Projection, Learning, and Reconstruction
Fast and Accurate Blind Flexible Docking
VL-ICL Bench: The Devil in the Details of Multimodal In-Context Learning
RecFlow: An Industrial Full Flow Recommendation Dataset
SOAP: Improving and Stabilizing Shampoo using Adam for Language Modeling
From Decoupling to Adaptive Transformation: a Wider Optimization Space for PTQ
Approximation algorithms for combinatorial optimization with predictions
Learning-Guided Rolling Horizon Optimization for Long-Horizon Flexible Job-Shop Scheduling
Boosting Neural Combinatorial Optimization for Large-Scale Vehicle Routing Problems
Multi-Robot Motion Planning with Diffusion Models
Unify ML4TSP: Drawing Methodological Principles for TSP and Beyond from Streamlined Design Space of Learning and Search
UniCO: On Unified Combinatorial Optimization via Problem Reduction to Matrix-Encoded General TSP
GOAL: A Generalist Combinatorial Optimization Agent Learner
Partial Gromov-Wasserstein Metric
Pareto Prompt Optimization
Topograph: An Efficient Graph-Based Framework for Strictly Topology Preserving Image Segmentation
SGD with memory: fundamental properties and stochastic acceleration
Neural Sampling from Boltzmann Densities: Fisher-Rao Curves in the Wasserstein Geometry
On the Almost Sure Convergence of the Stochastic Three Points Algorithm
Debiasing Federated Learning with Correlated Client Participation
3D-AffordanceLLM: Harnessing Large Language Models for Open-Vocabulary Affordance Detection in 3D Worlds
An Asynchronous Bundle Method for Distributed Learning Problems
Tight Time Complexities in Parallel Stochastic Optimization with Arbitrary Computation Dynamics
Taming Transformer Without Using Learning Rate Warmup
QERA: an Analytical Framework for Quantization Error Reconstruction
Many-Objective Multi-Solution Transport
Stochastic Polyak Step-sizes and Momentum: Convergence Guarantees and Practical Performance
GOPlan: Goal-conditioned Offline Reinforcement Learning by Planning with Learned Models
Preference Elicitation for Offline Reinforcement Learning
Efficient Active Imitation Learning with Random Network Distillation
Model-based Offline Reinforcement Learning with Lower Expectile Q-Learning
AdaManip: Adaptive Articulated Object Manipulation Environments and Policy Learning
Neural Stochastic Differential Equations for Uncertainty-Aware Offline RL
Scalable Decision-Making in Stochastic Environments through Learned Temporal Abstraction
Null Counterfactual Factor Interactions for Goal-Conditioned Reinforcement Learning
Residual Kernel Policy Network: Enhancing Stability and Robustness in RKHS-Based Reinforcement Learning
MAD-TD: Model-Augmented Data stabilizes High Update Ratio RL
Efficient Off-Policy Learning for High-Dimensional Action Spaces
Any-step Dynamics Model Improves Future Predictions for Online and Offline Reinforcement Learning
OGBench: Benchmarking Offline Goal-Conditioned RL
Swift Hydra:  Self-Reinforcing Generative Framework for Anomaly Detection with Multiple Mamba Models
ODE-based Smoothing Neural Network for Reinforcement Learning Tasks
Contractive Dynamical Imitation Policies for Efficient Out-of-Sample Recovery
On Rollouts in Model-Based Reinforcement Learning
QMP: Q-switch Mixture of Policies for Multi-Task Behavior Sharing
Studying the Interplay Between the Actor and Critic Representations in Reinforcement Learning
Computationally Efficient RL under Linear Bellman Completeness for Deterministic Dynamics
Subtask-Aware Visual Reward Learning from Segmented Demonstrations
POGEMA: A Benchmark Platform for Cooperative Multi-Agent Pathfinding
FlickerFusion: Intra-trajectory Domain Generalizing Multi-agent Reinforcement Learning
Advantage Alignment Algorithms
INS: Interaction-aware Synthesis to Enhance Offline Multi-agent Reinforcement Learning
A Generalist Hanabi Agent
DPLM-2: A Multimodal Diffusion Protein Language Model
Timer-XL: Long-Context Transformers for Unified Time Series Forecasting
Tractable Multi-Agent Reinforcement Learning through Behavioral Economics
Trajectory-Class-Aware Multi-Agent Reinforcement Learning
Online Reward-Weighted Fine-Tuning of Flow Matching with Wasserstein Regularization
Gap-Dependent Bounds for Q-Learning using Reference-Advantage Decomposition
OptionZero: Planning with Learned Options
Bisimulation Metric for Model Predictive Control
How to Find the Exact Pareto Front for Multi-Objective MDPs?
Efficient Exploration and Discriminative World Model Learning with an Object-Centric Abstraction
Agent S: An Open Agentic Framework that Uses Computers Like a Human
Scaling Autonomous Agents via Automatic Reward Modeling And Planning
TimeInf: Time Series Data Contribution via Influence Functions
Language Agents Meet Causality -- Bridging LLMs and Causal World Models
ORSO: Accelerating Reward Design via Online Reward Selection and Policy Optimization
Discrete Latent Plans via Semantic Skill Abstractions
LICORICE: Label-Efficient Concept-Based Interpretable Reinforcement Learning
Risk-Sensitive Variational Actor-Critic: A Model-Based Approach
Robust Simulation-Based Inference under Missing Data via Neural Processes
Bayesian Regularization of Latent Representation
Long-time asymptotics of noisy SVGD outside the population limit
From Risk to Uncertainty: Generating Predictive Uncertainty Measures via Bayesian Estimation
Scalable Bayesian Learning with posteriors
MamKO: Mamba-based Koopman operator for modeling and predictive control
Compositional simulation-based inference for time series
Deep Random Features for Scalable Interpolation of Spatiotemporal Data
Causal Graphical Models for Vision-Language Compositional Understanding
Underdamped Diffusion Bridges with Applications to Sampling
Microcanonical Langevin Ensembles: Advancing the Sampling of Bayesian Neural Networks
Optimizing Backward Policies in GFlowNets via Trajectory Likelihood Maximization
Parameter Expanded Stochastic Gradient Markov Chain Monte Carlo
End-to-end Learning of Gaussian Mixture Priors for Diffusion Sampler
Flow-based Variational Mutual Information: Fast and Flexible Approximations
Robust Conformal Prediction with a Single Binary Certificate
Root Cause Analysis of Anomalies in Multivariate Time Series through Granger Causal Discovery
Transformers are Universal In-context Learners
Entropy-based Activation Function Optimization: A Method on Searching Better Activation Functions
State Space Models are Provably Comparable to Transformers in Dynamic Token Selection
Learning Multi-Index Models with Neural Networks via Mean-Field Langevin Dynamics
Prototype antithesis for biological few-shot class-incremental learning
Generalization Guarantees for Representation Learning via Data-Dependent Gaussian Mixture Priors
LOIRE: LifelOng learning on Incremental data via pre-trained language model gRowth Efficiently
The Complexity of Two-Team Polymatrix Games with Independent Adversaries
Strategic Classification With Externalities
Latent-EnSF: A Latent Ensemble Score Filter for High-Dimensional Data Assimilation with Sparse Observation Data
Transformers Provably Learn Two-Mixture of Linear Classification via Gradient Flow
Flavors of Margin: Implicit Bias of Steepest Descent in Homogeneous Neural Networks
Rethinking Self-Distillation: Label Averaging and Enhanced Soft Label Refinement with Partial Labels
Learning Neural Networks with Distribution Shift: Efficiently Certifiable Guarantees
Statistical Advantages of Perturbing Cosine Router in Mixture of Experts
Transformers Provably Solve Parity Efficiently with Chain of Thought
Satisficing Regret Minimization in Bandits
Learning Structured Universe Graph with Outlier OOD Detection for Partial Matching
Gradient correlation is a key ingredient to accelerate SGD with momentum
Scalable Decentralized Learning with Teleportation
TimeKAN: KAN-based Frequency Decomposition Learning Architecture for Long-term Time Series Forecasting
Accelerated Over-Relaxation Heavy-Ball Method: Achieving Global Accelerated Convergence with Broad Generalization
Learning-Augmented Frequent Directions
To Clip or not to Clip: the Dynamics of SGD with Gradient Clipping in High-Dimensions
Last Iterate Convergence of Incremental Methods as a Model of Forgetting
Achieving Dimension-Free Communication in Federated Learning via Zeroth-Order Optimization
PABBO: Preferential Amortized Black-Box Optimization
Generalizable Motion Planning via Operator Learning
A Formal Framework for Understanding Length Generalization in Transformers
Topological Zigzag Spaghetti for Diffusion-based Generation and Prediction on Graphs
Causal Reasoning and Large Language Models: Opening a New Frontier for Causality
Optimal Transport for Time Series Imputation
Differentially private learners for heterogeneous treatment effects
Causal Identification for Complex Functional Longitudinal Studies
Doubly robust identification of treatment effects from multiple environments
Evaluating Semantic Variation in Text-to-Image Synthesis: A Causal Perspective
Gaussian Mixture Counterfactual Generator
Unifying Causal Representation Learning with the Invariance Principle
CausalRivers - Scaling up benchmarking of causal discovery for real-world time-series
Towards Automated Knowledge Integration From Human-Interpretable Representations
A Quantum Circuit-Based Compression Perspective for Parameter-Efficient Learning
Judge Decoding: Faster Speculative Sampling Requires Going Beyond Model Alignment
PersonalLLM: Tailoring LLMs to Individual Preferences
A General Framework for Producing Interpretable Semantic Text Embeddings
Building, Reusing, and Generalizing Abstract Representations from Concrete Sequences
Diverse Policies Recovering via Pointwise Mutual Information Weighted Imitation Learning
Learning from weak labelers as constraints
TTVD: Towards a Geometric Framework for Test-Time Adaptation Based on Voronoi Diagram
Semi-Supervised CLIP Adaptation by Enforcing Semantic and Trapezoidal Consistency
AutoUAD: Hyper-parameter Optimization for Unsupervised Anomaly Detection
Unsupervised Disentanglement of Content and Style via Variance-Invariance Constraints
Rethinking Multiple-Instance Learning From Feature Space to Probability Space
Score-based Self-supervised MRI Denoising
Mufu:  Multilingual Fused Learning for Low-Resource Translation with LLM
Federated Continual Learning Goes Online: Uncertainty-Aware Memory Management for Vision Tasks and Beyond
Second Order Bounds for Contextual Bandits with Function Approximation
Active Learning for Continual Learning: Keeping the Past Alive in the Present
On the Computation of the Fisher Information in Continual Learning
More Experts Than Galaxies: Conditionally-Overlapping Experts with Biologically-Inspired Fixed Routing
Diff-Prompt: Diffusion-driven Prompt Generator with Mask Supervision
Learning to Adapt Frozen CLIP for Few-Shot Test-Time Domain Adaptation
RA-TTA: Retrieval-Augmented Test-Time Adaptation for Vision-Language Models
Coreset Selection via Reducible Loss in Continual Learning
Test-Time Adaptation for Combating Missing Modalities in Egocentric Videos
Explore Theory of Mind: program-guided adversarial data generation for theory of mind reasoning
Complementary Label Learning with Positive Label Guessing and Negative Label Enhancement
Unlocking the Potential of Model Calibration in Federated Learning
Holistically Evaluating the Environmental Impact of Creating Language Models
GRAIN: Exact Graph Reconstruction from Gradients
Controllable Unlearning for Image-to-Image Generative Models via $\epsilon$-Constrained Optimization
Gaussian Differentially Private Human Faces Under a Face Radial Curve Representation
Learning from End User Data with Shuffled Differential Privacy over Kernel Densities
Tighter Privacy Auditing of DP-SGD in the Hidden State Threat Model
Understanding Model Calibration - A gentle introduction and visual exploration of calibration and the expected calibration error (ECE)
AI Sandbagging: Language Models can Strategically Underperform on Evaluations
Beyond Sequence: Impact of Geometric Context for RNA Property Prediction
Talking Turns: Benchmarking Audio Foundation Models on Turn-Taking Dynamics
Can LLMs Separate Instructions From Data? And What Do We Even Mean By That?
Outlier Synthesis via Hamiltonian Monte Carlo for Out-of-Distribution Detection
Perplexity Trap: PLM-Based Retrievers Overrate Low Perplexity Documents
GOttack: Universal Adversarial Attacks on Graph Neural Networks via Graph Orbits Learning
Concept Bottleneck Language Models For Protein Design
Compute-Optimal LLMs Provably Generalize Better with Scale
Mitigating the Backdoor Effect for Multi-Task Model Merging via Safety-Aware Subspace
Utility-Directed Conformal Prediction: A Decision-Aware Framework for Actionable Uncertainty Quantification
Reconsidering Faithfulness in Regular, Self-Explainable and Domain Invariant GNNs
An Engorgio Prompt Makes Large Language Model Babble on
LLaMA-Omni: Seamless Speech Interaction with Large Language Models
UV-Attack: Physical-World Adversarial Attacks on Person Detection via Dynamic-NeRF-based UV Mapping
Failures to Find Transferable Image Jailbreaks Between Vision-Language Models
Steering LLMs' Behavior with Concept Activation Vectors
Century: A Framework and Dataset for Evaluating Historical Contextualisation of Sensitive Images
Monitoring Latent World States in Language Models with Propositional Probes
See What You Are Told: Visual Attention Sink in Large Multimodal Models
LucidPPN: Unambiguous Prototypical Parts Network for User-centric Interpretable Computer Vision
Aligned LLMs Are Not Aligned Browser Agents
Discovering Influential Neuron Path in Vision Transformers
Residual Stream Analysis with Multi-Layer SAEs
Diffusion On Syntax Trees For Program Synthesis
Rethinking Visual Counterfactual Explanations Through Region Constraint
Logic-Logit: A Logic-Based Approach to Choice Modeling
MAGE: Model-Level Graph Neural Networks Explanations via Motif-based Graph Generation
Intrinsic User-Centric Interpretability through Global Mixture of Experts
Feature Responsiveness Scores: Model-Agnostic Explanations for Recourse
Cross-Modal Safety Mechanism Transfer in Large Vision-Language Models
Have the VLMs Lost Confidence? A Study of Sycophancy in VLMs
Joint Fine-tuning and Conversion of Pretrained Speech and Language Models towards Linear Complexity
Sensitivity Verification for Additive Decision Tree Ensembles
EFFICIENT JAILBREAK ATTACK SEQUENCES ON LARGE LANGUAGE MODELS VIA MULTI-ARMED BANDIT-BASED CONTEXT SWITCHING
Controlling the Fidelity and Diversity of Deep Generative Models via Pseudo Density
Relax and Merge: A Simple Yet Effective Framework for Solving Fair $k$-Means and $k$-sparse Wasserstein Barycenter Problems
Exploring Local Memorization in Diffusion Models via Bright Ending Attention
Training-free LLM-generated Text Detection by Mining Token Probability Sequences
Growth Inhibitors for Suppressing Inappropriate Image Concepts in Diffusion Models
GUI-World: A Video Benchmark and Dataset for Multimodal GUI-oriented Understanding
Language Model Alignment in Multilingual Trolley Problems
Strong Model Collapse
Soft Merging of Experts with Adaptive Routing
From Complexity to Clarity: Analytical Expressions of Deep Neural Network Weights via Clifford Algebra and Convexity
Reward Guided Latent Consistency Distillation
DelTA: An Online Document-Level Translation Agent Based on Multi-Level Memory
Can LLM Simulations Truly Reflect Humanity? A Deep Dive
Descent with Misaligned Gradients and Applications to Hidden Convexity
On the Identification of Temporal Causal Representation with Instantaneous Dependence
Compute-Constrained Data Selection
Multi-objective antibody design with constrained preference optimization
Neural Multi-Objective Combinatorial Optimization via Graph-Image Multimodal Fusion
MAGNet: Motif-Agnostic Generation of Molecules from Scaffolds
Scaling up the Banded Matrix Factorization Mechanism for Large Scale Differentially Private ML
HyperDAS: Towards Automating Mechanistic Interpretability with Hypernetworks
Single Teacher, Multiple Perspectives: Teacher Knowledge Augmentation for Enhanced Knowledge Distillation
Grid Cell-Inspired Fragmentation and Recall for Efficient Map Building
ICLR: In-Context Learning of Representations
Data Pruning by Information Maximization
Montessori-Instruct: Generate Influential Training Data Tailored for Student Learning
The Hidden Cost of Waiting for Accurate Predictions
From Sparse Dependence to Sparse Attention: Unveiling How Chain-of-Thought Enhances Transformer Sample Efficiency
Efficient Diversity-Preserving Diffusion Alignment via Gradient-Informed GFlowNets
ProteinBench: A Holistic Evaluation of Protein Foundation Models
The KoLMogorov Test: Compression by Code Generation
Training Language Models to Self-Correct via Reinforcement Learning
HexGen-2: Disaggregated Generative Inference of LLMs in Heterogeneous Environment
CREIMBO: Cross-Regional Ensemble Interactions in Multi-view Brain Observations
CFG++: Manifold-constrained Classifier Free Guidance for Diffusion Models
AgentTrek: Agent Trajectory Synthesis via Guiding Replay with Web Tutorials
ToVE: Efficient Vision-Language Learning via Knowledge Transfer from Vision Experts
Emergence of a High-Dimensional Abstraction Phase in Language Transformers
AnoLLM: Large Language Models for Tabular Anomaly Detection
DELIFT: Data Efficient Language model Instruction Fine-Tuning
Physics of Language Models: Part 3.3, Knowledge Capacity Scaling Laws
Learning Generalizable Skills from Offline Multi-Task Data for Multi-Agent Cooperation
AlphaEdit: Null-Space Constrained Knowledge Editing for Language Models
GenARM: Reward Guided Generation with Autoregressive Reward Model for Test-Time Alignment
BRAID: Input-driven Nonlinear Dynamical Modeling of Neural-Behavioral Data
LiNeS: Post-training Layer Scaling Prevents Forgetting and Enhances Model Merging
For Better or For Worse? Learning Minimum Variance Features With Label Augmentation
Non-Adversarial Inverse Reinforcement Learning via Successor Feature Matching
MAVIS: Mathematical Visual Instruction Tuning with an Automatic Data Engine
ActionReasoningBench: Reasoning about Actions with and without Ramification Constraints
A Theoretical Framework for Partially-Observed Reward States in RLHF
Beyond Content Relevance: Evaluating Instruction Following in Retrieval Models
Generalization and Distributed Learning of GFlowNets
PointOBB-v2: Towards Simpler, Faster, and Stronger Single Point Supervised Oriented Object Detection
Q-SFT: Q-Learning for Language Models via Supervised Fine-Tuning
Toward Generalizing Visual Brain Decoding to Unseen Subjects
Scaling Offline Model-Based RL via Jointly-Optimized World-Action Model Pretraining
Solving Video Inverse Problems Using Image Diffusion Models
Learning Randomized Algorithms with Transformers
AIR-BENCH 2024: A Safety Benchmark based on Regulation and Policies Specified Risk Categories
Activation Gradient based Poisoned Sample Detection Against Backdoor Attacks
Inference Scaling Laws: An Empirical Analysis of Compute-Optimal Inference for LLM Problem-Solving
Solving Token Gradient Conflict in Mixture-of-Experts for Large Vision-Language Model
Data Center Cooling System Optimization Using Offline Reinforcement Learning
Q-Adapter: Customizing Pre-trained LLMs to New Preferences with Forgetting Mitigation
Building Math Agents with Multi-Turn Iterative Preference Learning
Range, not Independence, Drives Modularity in Biologically Inspired Representations
Optimal Learning of Kernel Logistic Regression for Complex Classification Scenarios
Everything is Editable: Extend Knowledge Editing to Unstructured Data in Large Language Models
Neural ODE Transformers: Analyzing Internal Dynamics and Adaptive Fine-tuning
KBLaM: Knowledge Base augmented Language Model
Adapting Multi-modal Large Language Model to Concept Drift From Pre-training Onwards
Harnessing Diversity for Important Data Selection in Pretraining Large Language Models
Linear SCM Identification in the Presence of Confounders and Gaussian Noise
Breaking the $\log(1/\Delta_2)$ Barrier: Better Batched Best Arm Identification with Adaptive Grids
Self-play with Execution Feedback: Improving Instruction-following Capabilities of Large Language Models
Efficient Training of Neural Stochastic Differential Equations by Matching Finite Dimensional Distributions
Bio-xLSTM: Generative modeling, representation and in-context learning of biological and chemical sequences
BrainACTIV: Identifying visuo-semantic properties driving cortical selectivity using diffusion-based image manipulation
Beyond Next Token Prediction: Patch-Level Training for Large Language Models
Transformer-Squared: Self-adaptive LLMs
Provable unlearning in topic modeling and downstream tasks
Disentangled Representation Learning with the Gromov-Monge Gap
What Secrets Do Your Manifolds Hold? Understanding the Local Geometry of Generative Models
Eliminating Position Bias of Language Models: A Mechanistic Approach
No Location Left Behind: Measuring and Improving the Fairness of Implicit Representations for Earth Data
Large Language Models are Interpretable Learners
OvercookedV2: Rethinking Overcooked for Zero-Shot Coordination
Scaling Diffusion Language Models via Adaptation from Autoregressive Models
Self-Attention-Based Contextual Modulation Improves Neural System Identification
Neural Fluid Simulation on Geometric Surfaces
AssembleFlow: Rigid Flow Matching with Inertial Frames for Molecular Assembly
StringLLM: Understanding the String Processing Capability of Large Language Models
Node-Time Conditional Prompt Learning in Dynamic Graphs
CG-Bench: Clue-grounded Question Answering Benchmark for Long Video Understanding
Mind the Gap: Examining the Self-Improvement Capabilities of Large Language Models
ThinK: Thinner Key Cache by Query-Driven Pruning
Scale-Free Graph-Language Models
Privacy Auditing of Large Language Models
Analytic DAG Constraints for Differentiable DAG Learning
Improving Semantic Understanding in Speech Language Models via Brain-tuning
LLaVA-Interleave: Tackling Multi-image, Video, and 3D in Large Multimodal Models
Stable Segment Anything Model
HiLo: A Learning Framework for Generalized Category Discovery Robust to Domain Shifts
Jump Your Steps: Optimizing Sampling Schedule of Discrete Diffusion Models
Understanding and Mitigating Bottlenecks of State Space Models through the Lens of Recency and Over-smoothing
Causal Effect Estimation with Mixed Latent Confounders and Post-treatment Variables
DataEnvGym: Data Generation Agents in Teacher Environments with Student Feedback
MoLEx: Mixture of Layer Experts for Fine-tuning with Sparse Upcycling
MMed-RAG: Versatile Multimodal RAG System for Medical Vision Language Models
Density estimation with LLMs: a geometric investigation of in-context learning trajectories
Finding Shared Decodable Concepts and their Negations in the Brain
Better than Your Teacher: LLM Agents that learn from Privileged AI Feedback
Sparse Learning for State Space Models on Mobile
Progressive distillation induces an implicit curriculum
GrabS: Generative Embodied Agent for 3D Object Segmentation without Scene Supervision
Syntactic and Semantic Control of Large Language Models via Sequential Monte Carlo
Image and Video Tokenization with Binary Spherical Quantization
Understanding the Generalization of In-Context Learning in Transformers: An Empirical Study
Horizon Generalization in Reinforcement Learning
Enhancing Clustered Federated Learning: Integration of Strategies and Improved Methodologies
Exposure Bracketing Is All You Need For A High-Quality Image
One Hundred Neural Networks and Brains Watching Videos: Lessons from Alignment
RNNs are not Transformers (Yet):  The Key Bottleneck on In-Context Retrieval
Improving the Sparse Structure Learning of Spiking Neural Networks from the View of Compression Efficiency
Associative memory and dead neurons
Shared-AE: Automatic Identification of Shared Subspaces in High-dimensional Neural and Behavioral Activity
Measuring And Improving Engagement of Text-to-Image Generation Models
Depth Any Video with Scalable Synthetic Data
A Simple yet Effective $\Delta\Delta G$ Predictor is An Unsupervised Antibody Optimizer and Explainer
Personalized Representation from Personalized Generation
CyberHost: A One-stage Diffusion Framework for Audio-driven Talking Body Generation
Loopy: Taming Audio-Driven Portrait Avatar with Long-Term Motion Dependency
CO-MOT: Boosting End-to-end Transformer-based Multi-Object Tracking via Coopetition Label Assignment and Shadow Sets
TRACE: Temporal Grounding Video LLM  via Causal Event Modeling
SurFhead: Affine Rig Blending for Geometrically Accurate 2D Gaussian Surfel Head Avatars
General Scene Adaptation for Vision-and-Language Navigation
SynQ: Accurate Zero-shot Quantization by Synthesis-aware Fine-tuning
NL-Eye: Abductive NLI For Images
Evidential Learning-based Certainty Estimation for Robust Dense Feature Matching
MOOSE-Chem: Large Language Models for Rediscovering Unseen Chemistry Scientific Hypotheses
Cached Multi-Lora Composition for Multi-Concept Image Generation
IterComp: Iterative Composition-Aware Feedback Learning from Model Gallery for Text-to-Image Generation
Point Cluster: A Compact Message Unit for Communication-Efficient Collaborative Perception
SiMHand: Mining Similar Hands for Large-Scale 3D Hand Pose Pre-training
Motion-Agent: A Conversational Framework for Human Motion Generation with LLMs
TopoGaussian: Inferring Internal Topology Structures from Visual Clues
Sitcom-Crafter: A Plot-Driven Human Motion Generation System in 3D Scenes
OVTR: End-to-End Open-Vocabulary Multiple Object Tracking with Transformer
Masked Temporal Interpolation Diffusion for Procedure Planning in Instructional Videos
Learning Color Equivariant Representations
Retrieval Augmented Diffusion Model for Structure-informed Antibody Design and Optimization
Towards Marginal Fairness Sliced Wasserstein Barycenter
Video-STaR: Self-Training Enables Video Instruction Tuning with Any Supervision
Towards Realistic Data Generation for Real-World Super-Resolution
VEDIT: Latent Prediction Architecture For Procedural Video Representation Learning
LaMP: Language-Motion Pretraining for Motion Generation, Retrieval, and Captioning
Re-Aligning Language to Visual Objects with an Agentic Workflow
EffoVPR: Effective Foundation Model Utilization for Visual Place Recognition
SINGAPO: Single Image Controlled Generation of Articulated Parts in Objects
GaussianAnything: Interactive Point Cloud Flow Matching for 3D Generation
InfoGS: Efficient Structure-Aware 3D Gaussians via Lightweight Information Shaping
(ends 12:30 PM)
Exhibit Hall
(ends 5:30 PM)
Break:
(ends 10:30 AM)
10:30 a.m.
Oral Session 5A
[10:30-12:00]
10:30-11:42
[10:30]
Spread Preference Annotation: Direct Preference Judgment for Efficient LLM Alignment
[10:42]
Do LLMs Recognize Your Preferences? Evaluating Personalized Preference Following in LLMs
[10:54]
Language Representations Can be What Recommenders Need: Findings and Potentials
[11:06]
DarkBench: Benchmarking Dark Patterns in Large Language Models
[11:18]
Linear Representations of Political Perspective Emerge in Large Language Models
[11:30]
Do as We Do, Not as You Think: the Conformity of Large Language Models
(ends 12:00 PM)
Oral Session 5B
[10:30-12:00]
10:30-11:42
[10:30]
How much of my dataset did you use? Quantitative Data Usage Inference in Machine Learning
[10:42]
Proxy Denoising for Source-Free Domain Adaptation
[10:54]
Data Shapley in One Training Run
[11:06]
Data Selection via Optimal Control for Language Models
[11:18]
Combatting Dimensional Collapse in LLM Pre-Training Data via Submodular File Selection
[11:30]
DEPT: Decoupled Embeddings for Pre-training Language Models
(ends 12:00 PM)
Oral Session 5C
[10:30-12:00]
10:30-11:30
[10:30]
Sparse Feature Circuits: Discovering and Editing Interpretable Causal Graphs in Language Models
[10:42]
Unlearning-based Neural Interpretations
[10:54]
Knowledge Entropy Decay during Language Model Pretraining Hinders New Knowledge Acquisition
[11:06]
Cross-Entropy Is All You Need To Invert the Data Generating Process
[11:18]
Can a MISL Fly? Analysis and Ingredients for Mutual Information Skill Learning
(ends 12:00 PM)
Oral Session 5D
[10:30-12:00]
10:30-11:42
[10:30]
Tight Lower Bounds under Asymmetric High-Order Hölder Smoothness and Uniform Convexity
[10:42]
Second-Order Min-Max Optimization with Lazy Hessians
[10:54]
Can Neural Networks Achieve Optimal Computational-statistical Tradeoff? An Analysis on Single-Index Model
[11:06]
Standard Gaussian Process is All You Need for High-Dimensional Bayesian Optimization
[11:18]
Improved Finite-Particle Convergence Rates for Stein Variational Gradient Descent
[11:30]
Classic but Everlasting: Traditional Gradient-Based Algorithms Converges Fast Even in Time-Varying Multi-Player Games
(ends 12:00 PM)
Oral Session 5E
[10:30-12:00]
10:30-11:42
[10:30]
What should a neuron aim for? Designing local objective functions based on information theory
[10:42]
A Decade's Battle on Dataset Bias: Are We There Yet?
[10:54]
On Conformal Isometry of Grid Cells: Learning Distance-Preserving Position Embedding
[11:06]
Comparing noisy neural population dynamics using optimal transport distances
[11:18]
A Computational Framework for Modeling Emergence of Color Vision in the Human Brain
[11:30]
Learning and aligning single-neuron invariance manifolds in visual cortex
(ends 12:00 PM)
Oral Session 5F
[10:30-12:00]
10:30-11:42
[10:30]
Geometry-aware RL for Manipulation of Varying Shapes and Deformable Objects
[10:42]
Instant Policy: In-Context Imitation Learning via Graph Diffusion
[10:54]
Predictive Inverse Dynamics Models are Scalable Learners for Robotic Manipulation
[11:06]
Data Scaling Laws in Imitation Learning for Robotic Manipulation
[11:18]
Diffusion-Based Planning for Autonomous Driving with Flexible Guidance
[11:30]
Kinetix: Investigating the Training of General Agents through Open-Ended Physics-Based Control Tasks
(ends 12:00 PM)
12:30 p.m.
Break:
Lunch Break (on your own)
(ends 2:00 PM)
Social:
AI Multi-Agent Systems in Enterprise: Bridging Research and Real-World Applications
(ends 2:00 PM)
Social:
ML for Digital Twins
(ends 2:00 PM)
Mentorship:
Mentorship Hour
(ends 1:15 PM)
Social:
ML in Software Engineering
(ends 2:00 PM)
Social:
ML Safety Social
(ends 2:00 PM)
1 p.m.
Expo Talk Panel:
Kvax: Fast and easy-to-use Flash Attention implementation for JAX
(ends 2:00 PM)
Expo Talk Panel:
verl: Flexible and Efficient Infrastructures for Post-training LLMs
(ends 2:00 PM)
Expo Talk Panel:
Improving LLM Benchmarks: Making AI Work for Real-World Needs
(ends 2:00 PM)
Expo Talk Panel:
Leveraging Multimodal LLMs for Shopify’s Global Catalogue
(ends 2:00 PM)
1:15 p.m.
Town Hall:
Town Hall
(ends 2:00 PM)
Mentorship:
Mentorship Hour
(ends 2:00 PM)
2 p.m.
Invited Talk:
Open-Endedness, World Models, and the Automation of Innovation
Tim Rocktaeschel
(ends 3:00 PM)
Invited Talk:
Overflow: Open-Endedness, World Models, and the Automation of Innovation
Tim Rocktaeschel
(ends 3:00 PM)
3 p.m.
Poster Session 6
[3:00-5:30]
Poster
3:00-5:30
Curriculum-aware Training for Discriminating Molecular Property Prediction Models
Fragment and Geometry Aware Tokenization of Molecules for Structure-Based Drug Design Using Language Models
LLM-wrapper: Black-Box Semantic-Aware Adaptation of Vision-Language Models for Referring Expression Comprehension
Gap Preserving Distillation by Building Bidirectional Mappings with A Dynamic Teacher
Spectral Compressive Imaging via Unmixing-driven Subspace Diffusion Refinement
Shape as Line Segments: Accurate and Flexible Implicit Surface Representation
3D Vision-Language Gaussian Splatting
A Decade's Battle on Dataset Bias: Are We There Yet?
Exploring the Camera Bias of Person Re-identification
Multi-Task Dense Predictions via Unleashing the Power of Diffusion
MRAG-Bench: Vision-Centric Evaluation for Retrieval-Augmented Multimodal Models
MMIU: Multimodal Multi-image Understanding for Evaluating Large Vision-Language Models
Atomas: Hierarchical Adaptive Alignment on Molecule-Text for Unified Molecule Understanding and Generation
EditRoom: LLM-parameterized Graph Diffusion for Composable 3D Room Layout Editing
Learning 3D Perception from Others' Predictions
Diff-2-in-1: Bridging Generation and Dense Perception with Diffusion Models
InstantPortrait: One-Step Portrait Editing via Diffusion Multi-Objective Distillation
RecDreamer: Consistent Text-to-3D Generation via Uniform Score Distillation
Depth Pro: Sharp Monocular Metric Depth in Less Than a Second
Knowledge Distillation with Multi-granularity Mixture of Priors for Image Super-Resolution
Generalizable Human Gaussians from Single-View Image
Tuning Timestep-Distilled Diffusion Model Using Pairwise Sample Optimization
EcoFace: Audio-Visual Emotional Co-Disentanglement Speech-Driven 3D Talking Face Generation
IgGM: A Generative Model for Functional Antibody and Nanobody Design
CatVTON: Concatenation Is All You Need for Virtual Try-On with Diffusion Models
Hidden in the Noise: Two-Stage Robust Watermarking for Images
Point-based Instance Completion with Scene Constraints
Simplifying Deep Temporal Difference Learning
Ready-to-React: Online Reaction Policy for Two-Character Interaction Generation
Multi-Scale Fusion for Object Representation
Analyzing and Boosting the Power of Fine-Grained Visual Recognition for Multi-modal Large Language Models
CoMotion: Concurrent Multi-person 3D Motion
econSG: Efficient and Multi-view Consistent Open-Vocabulary 3D Semantic Gaussians
Revisit Micro-batch Clipping: Adaptive Data Pruning via Gradient Manipulation
Learning to Discover Regulatory Elements for Gene Expression Prediction
DICE: End-to-end Deformation Capture of Hand-Face Interactions from a Single Image
Unbounded: A Generative Infinite Game of Character Life Simulation
Agent-to-Sim: Learning Interactive Behavior Models from Casual Longitudinal Videos
Random Is All You Need: Random Noise Injection on Feature Statistics for Generalizable Deep Image Denoising
Intervening Anchor Token: Decoding Strategy in Alleviating Hallucinations for MLLMs
TeaserGen: Generating Teasers for Long Documentaries
Alchemy: Amplifying Theorem-Proving Capability Through Symbolic Mutation
3D-MolT5: Leveraging Discrete Structural Information for Molecule-Text Modeling
MLLM as Retriever: Interactively Learning Multimodal Retrieval for Embodied Agents
MarS: a Financial Market Simulation Engine Powered by Generative Foundation Model
MorphoDiff: Cellular Morphology Painting with Diffusion Models
Learn-by-interact: A Data-Centric Framework For Self-Adaptive Agents in Realistic Environments
LeanAgent: Lifelong Learning for Formal Theorem Proving
Pareto Low-Rank Adapters: Efficient Multi-Task Learning with Preferences
SageAttention: Accurate 8-Bit Attention for Plug-and-play Inference Acceleration
Mind the GAP: Glimpse-based Active Perception improves generalization and sample efficiency of visual reasoning
Equivariant Neural Functional Networks for Transformers
Improved Algorithms for Kernel  Matrix-Vector Multiplication Under Sparsity Assumptions
Transformer Learns Optimal Variable Selection in Group-Sparse Classification
MaskBit: Embedding-free Image Generation via Bit Tokens
Not All Prompts Are Made Equal: Prompt-based Pruning of Text-to-Image Diffusion Models
Reading Your Heart: Learning ECG Words and Sentences via Pre-training ECG Language Model
PnP-Flow: Plug-and-Play Image Restoration with Flow Matching
HD-Painter: High-Resolution and Prompt-Faithful Text-Guided Image Inpainting with Diffusion Models
Fugatto 1: Foundational Generative Audio Transformer Opus 1
ControlAR: Controllable Image Generation with Autoregressive Models
Rethinking Diffusion Posterior Sampling: From Conditional Score Estimator to Maximizing a Posterior
Semantic Image Inversion and Editing using Rectified Stochastic Differential Equations
CogVideoX: Text-to-Video Diffusion Models with An Expert Transformer
Think while You Generate: Discrete Diffusion with Planned Denoising
MS-Diffusion: Multi-subject Zero-shot Image Personalization with Layout Guidance
Easing Training Process of Rectified Flow Models Via Lengthening Inter-Path Distance
Reasoning-Enhanced Healthcare Predictions with Knowledge Graph Community Retrieval
Topological Schrödinger Bridge Matching
CameraCtrl: Enabling Camera Control for Video Diffusion Models
IRIS: LLM-Assisted Static Analysis for Detecting Security Vulnerabilities
No Training, No Problem: Rethinking Classifier-Free Guidance for Diffusion Models
On Statistical Rates of Conditional Diffusion Transformers: Approximation,  Estimation and Minimax Optimality
Diffusion Bridge Implicit Models
ClassDiffusion: More Aligned Personalization Tuning with Explicit Class Guidance
Diffusion-based Neural Network Weights Generation
Adversarial Score identity Distillation: Rapidly Surpassing the Teacher in One Step
FaceShot: Bring Any Character into Life
RelCon: Relative Contrastive Learning for a Motion Foundation Model for Wearable Data
Ambient Diffusion Posterior Sampling: Solving Inverse Problems with Diffusion Models Trained on Corrupted Data
Hallo2: Long-Duration and High-Resolution Audio-Driven Portrait Image Animation
Beyond the convexity assumption: Realistic tabular data generation under quantifier-free real linear constraints
DAWN: Dynamic Frame Avatar with Non-autoregressive Diffusion Framework for Talking head Video Generation
Field-DiT: Diffusion Transformer on Unified Video, 3D, and Game Field Generation
PFDiff: Training-Free Acceleration of Diffusion Models Combining Past and Future Scores
ZeroDiff: Solidified Visual-semantic Correlation in Zero-Shot Learning
Adjoint Matching: Fine-tuning Flow and Diffusion Generative Models with Memoryless Stochastic Optimal Control
InstantSplamp: Fast and Generalizable Stenography Framework for Generative Gaussian Splatting
MDSGen: Fast and Efficient Masked Diffusion Temporal-Aware Transformers for Open-Domain Sound Generation
Scaling Wearable Foundation Models
NVS-Solver: Video Diffusion Model as Zero-Shot Novel View Synthesizer
BrainOOD: Out-of-distribution Generalizable Brain Network Analysis
DUALFormer: Dual Graph Transformer
Graph Neural Ricci Flow: Evolving Feature from a Curvature Perspective
TGB-Seq Benchmark: Challenging Temporal GNNs with Complex Sequential Dynamics
PolyhedronNet: Representation Learning for Polyhedra with Surface-attributed Graph
On the Expressive Power of Sparse Geometric MPNNs
Beyond Random Masking: When Dropout meets Graph Convolutional Networks
Revisiting Random Walks for Learning on Graphs
Learning Graph Invariance by Harnessing Spuriosity
HR-Extreme: A High-Resolution Dataset for Extreme Weather Forecasting
Graph Neural Networks for Edge Signals: Orientation Equivariance and Invariance
DeepGate4: Efficient and Effective Representation Learning for Circuit Design at Scale
GNNs Getting ComFy: Community and Feature Similarity Guided Rewiring
Learning Long Range Dependencies on Graphs via Random Walks
Decoupled Subgraph Federated Learning
DistillHGNN: A Knowledge Distillation Approach for High-Speed Hypergraph Neural Networks
TaskGalaxy: Scaling Multi-modal Instruction Fine-tuning with Tens of Thousands Vision Task Types
Fast unsupervised ground metric learning with tree-Wasserstein distance
BOND: Aligning LLMs with Best-of-N Distillation
From Tokens to Words: On the Inner Lexicon of LLMs
MADGEN: Mass-Spec attends to De Novo Molecular generation
Metamizer: A Versatile Neural Optimizer for Fast and Accurate Physics Simulations
Recite, Reconstruct, Recollect: Memorization in LMs as a Multifaceted Phenomenon
Planning in Natural Language Improves LLM Search for Code Generation
ReMoE: Fully Differentiable Mixture-of-Experts with ReLU Routing
Mini-Monkey: Alleviating the Semantic Sawtooth Effect for Lightweight MLLMs via Complementary Image Pyramid
Inference-Aware Fine-Tuning for Best-of-N Sampling in Large Language Models
Better Instruction-Following Through Minimum Bayes Risk
Block-Attention for Efficient Prefilling
Forking Paths in Neural Text Generation
MagicPIG: LSH Sampling for Efficient LLM Generation
Mitigating Modality Prior-Induced Hallucinations in Multimodal Large Language Models via Deciphering Attention Causality
Lie Algebra Canonicalization: Equivariant Neural Operators under arbitrary Lie Groups
Generative Representational Instruction Tuning
Human-inspired Episodic Memory for Infinite Context LLMs
Large Language Models Meet Symbolic Provers for Logical Reasoning Evaluation
MagicDec: Breaking the Latency-Throughput Tradeoff for Long Context Generation with Speculative Decoding
Rethinking Reward Model Evaluation: Are We Barking up the Wrong Tree?
BEEM: Boosting Performance of Early Exit DNNs using Multi-Exit Classifiers as Experts
Shot2Story: A New Benchmark for Comprehensive Understanding of Multi-shot Videos
Accelerating Inference of Retrieval-Augmented Generation via Sparse Context Selection
Sail into the Headwind: Alignment via Robust Rewards and Dynamic Labels against Reward Hacking
Can In-context Learning Really Generalize to Out-of-distribution Tasks?
Differentiable and Learnable Wireless Simulation with Geometric Transformers
LeanQuant: Accurate and Scalable Large Language Model Quantization with Loss-error-aware Grid
Post-hoc Reward Calibration: A Case Study on Length Bias
ToolDial: Multi-turn Dialogue Generation Method for Tool-Augmented Language Models
RetroInText: A Multimodal Large Language Model Enhanced Framework for Retrosynthetic Planning via In-Context Representation Learning
Multiagent Finetuning: Self Improvement with Diverse Reasoning Chains
DistRL: An Asynchronous Distributed Reinforcement Learning Framework for On-Device Control Agent
MambaExtend: A Training-Free Approach to Improve Long Context Extension of Mamba
Weak to Strong Generalization for Large Language Models with Multi-capabilities
Efficient Policy Evaluation with Safety Constraint for Reinforcement Learning
Can Video LLMs Refuse to Answer? Alignment for Answerability in Video Large Language Models
Revealing the 3D Cosmic Web through Gravitationally Constrained Neural Fields
Mixture of Attentions For Speculative Decoding
Surprising Effectiveness of pretraining Ternary  Language Model at Scale
Combining Induction and Transduction for Abstract Reasoning
Towards a Theoretical Understanding of Synthetic Data in LLM Post-Training: A Reverse-Bottleneck Perspective
Benchmarking Multimodal Retrieval Augmented Generation with Dynamic VQA Dataset and Self-adaptive Planning Agent
HaDeMiF: Hallucination Detection and Mitigation in Large Language Models
Decoding Game: On Minimax Optimality of Heuristic Text Generation Strategies
Permute-and-Flip: An optimally stable and watermarkable decoder for LLMs
Routing Experts: Learning to Route Dynamic Experts in Existing Multi-modal Large Language Models
Optimized Multi-Token Joint Decoding With Auxiliary Model for LLM Inference
CViT: Continuous Vision Transformer for Operator Learning
Toward Understanding In-context vs. In-weight Learning
Can LLMs Really Learn to Translate a Low-Resource Language from One Grammar Book?
Adaptive Data Optimization: Dynamic Sample Selection with Scaling Laws
Draw-and-Understand: Leveraging Visual Prompts to Enable MLLMs to Comprehend What You Want
REvolve: Reward Evolution with Large Language Models using Human Feedback
Distributed Speculative Inference (DSI): Speculation Parallelism for Provably Faster Lossless Language Model Inference
Towards Interpreting Visual Information Processing in Vision-Language Models
CodePlan: Unlocking Reasoning Potential in Large Language Models by Scaling Code-form Planning
Training Free Exponential Context Extension via Cascading KV Cache
SCOPE: A Self-supervised Framework for Improving Faithfulness in Conditional Text Generation
Rethinking the role of frames for SE(3)-invariant crystal structure modeling
BadJudge: Backdoor Vulnerabilities of LLM-As-A-Judge
Knowledge Entropy Decay during Language Model Pretraining Hinders New Knowledge Acquisition
BALROG: Benchmarking Agentic LLM and VLM Reasoning On Games
Mixture-of-Agents Enhances Large Language Model Capabilities
Improving Pretraining Data Using Perplexity Correlations
Dual Process Learning: Controlling Use of In-Context vs. In-Weights Strategies with Weight Forgetting
Preference Optimization for Reasoning with Pseudo Feedback
RMB: Comprehensively benchmarking reward models in LLM alignment
Enhancing Cognition and Explainability of Multimodal Foundation Models with Self-Synthesized Data
MQuAKE-Remastered: Multi-Hop Knowledge Editing Can Only Be Advanced with Reliable Evaluations
Learning local equivariant representations for quantum operators
Preble: Efficient Distributed Prompt Scheduling for LLM Serving
OS-ATLAS: Foundation Action Model for Generalist GUI Agents
HARDMath: A Benchmark Dataset for Challenging Problems in Applied Mathematics
CAMEx: Curvature-aware Merging of Experts
WebRL: Training LLM Web Agents via Self-Evolving Online Curriculum Reinforcement Learning
Dynamic Low-Rank Sparse Adaptation for Large Language Models
Promptriever: Instruction-Trained Retrievers Can Be Prompted Like Language Models
Think Thrice Before You Act: Progressive Thought Refinement in Large Language Models
Logicbreaks: A Framework for Understanding Subversion of Rule-based Inference
PaLD: Detection of Text Partially Written by Large Language Models
FreeCG: Free the Design Space of Clebsch-Gordan Transform for Machine Learning Force Fields
Rethinking Reward Modeling in Preference-based Large Language Model Alignment
Robust LLM safeguarding via refusal feature adversarial training
Train Small, Infer Large: Memory-Efficient LoRA Training for Large Language Models
Aioli: A Unified Optimization Framework for Language Model Data Mixing
How efficient is LLM-generated code? A rigorous & high-standard benchmark
Automated Design of Agentic Systems
Scaling Long Context Training Data by Long-Distance Referrals
Adaptive Rank Allocation: Speeding Up Modern Transformers with RaNA Adapters
Diffusing to the Top: Boost Graph Neural Networks with Minimal Hyperparameter Tuning
Visual-O1: Understanding Ambiguous Instructions via Multi-modal Multi-turn Chain-of-thoughts Reasoning
PIED: Physics-Informed Experimental Design for Inverse Problems
The Labyrinth of Links: Navigating the Associative Maze of Multi-modal LLMs
DEPT: Decoupled Embeddings for Pre-training Language Models
Text4Seg: Reimagining Image Segmentation as Text Generation
In-Context Editing: Learning Knowledge from Self-Induced Distributions
Towards Effective Evaluations and Comparisons for LLM Unlearning Methods
Robust Function-Calling for On-Device Language Model via Function Masking
Deconstructing What Makes a Good Optimizer for Autoregressive Language Models
UniGS: Unified Language-Image-3D Pretraining with Gaussian Splatting
Interpreting and Editing Vision-Language Representations to Mitigate Hallucinations
CFD: Learning Generalized Molecular Representation via Concept-Enhanced  Feedback Disentanglement
AutoCGP: Closed-Loop Concept-Guided Policies from Unlabeled Demonstrations
Formation of Representations in Neural Networks
A Riemannian Framework for Learning Reduced-order Lagrangian Dynamics
Medium-Difficulty Samples Constitute Smoothed Decision Boundary for Knowledge Distillation on Pruned Datasets
How Low Can You Go? Searching for the Intrinsic Dimensionality of Complex Networks using Metric Node Embeddings
X-Fi: A Modality-Invariant Foundation Model for Multimodal Human Sensing
Isometric Regularization for Manifolds of Functional Data
$\sigma$-zero: Gradient-based Optimization of $\ell_0$-norm Adversarial Examples
Enhancing Prediction Performance through Influence Measure
Robustness Reprogramming for Representation Learning
A Transfer Attack to Image Watermarks
Learning Equivariant Non-Local Electron Density Functionals
EqNIO: Subequivariant Neural Inertial Odometry
Rethinking Audio-Visual Adversarial Vulnerability from Temporal and Modality Perspectives
Persistent Pre-training Poisoning of LLMs
Provably Reliable Conformal Prediction Sets in the Presence of Data Poisoning
Long-tailed Adversarial Training with Self-Distillation
The Pitfalls of Memorization: When Memorization Hurts Generalization
Robust Gymnasium: A Unified Modular Benchmark for Robust Reinforcement Learning
Contrastive Learning from Synthetic Audio Doppelgängers
Dataset Distillation via Knowledge Distillation: Towards Efficient Self-Supervised Pre-training of Deep Networks
Cross-Entropy Is All You Need To Invert the Data Generating Process
A primer on analytical learning dynamics of nonlinear neural networks
HyPoGen: Optimization-Biased Hypernetworks for Generalizable Policy Generation
High-dimensional Analysis of Knowledge Distillation: Weak-to-Strong Generalization and Scaling Laws
Fourier Sliced-Wasserstein Embedding for Multisets and Measures
Spherical Tree-Sliced Wasserstein Distance
Conditional Diffusion Models are Minimax-Optimal and Manifold-Adaptive for Conditional Distribution Estimation
Divergence of Neural Tangent Kernel in Classification Problems
Geometric Inductive Biases of Deep Networks: The Role of Data and Architecture
Fast and Slow Streams for Online Time Series Forecasting Without Information Leakage
FACTS: A Factored State-Space Framework for World Modelling
Time-MoE: Billion-Scale Time Series Foundation Models with Mixture of Experts
Air Quality Prediction with Physics-Guided Dual Neural ODEs in Open Systems
Learning Shape-Independent Transformation via Spherical Representations for Category-Level Object Pose Estimation
Breaking Neural Network Scaling Laws with Modularity
MMSearch: Unveiling the Potential of Large Models as Multi-modal Search Engines
SparsyFed: Sparse Adaptive Federated Learning
TabM: Advancing tabular deep learning with parameter-efficient ensembling
SpikeLLM: Scaling up Spiking Neural Network to Large Language Models via Saliency-based Spiking
Efficient Low-Bit Quantization with Adaptive Scales for Multi-Task Co-Training
LDAdam: Adaptive Optimization from Low-Dimensional Gradient Statistics
Uni$^2$Det: Unified and Universal Framework for Prompt-Guided Multi-dataset 3D Detection
Towards Foundation Models for Mixed Integer Linear Programming
Rethinking Neural Multi-Objective Combinatorial Optimization via Neat Weight Embedding
AHA: A Vision-Language-Model for Detecting and Reasoning Over Failures in Robotic Manipulation
RAG-SR: Retrieval-Augmented Generation for Neural Symbolic Regression
Learning to Select Nodes in Branch and Bound with Sufficient Tree Representation
Minimalistic Predictions for Online Class Constraint Scheduling
DRoC: Elevating Large Language Models for Complex Vehicle Routing via Decomposed Retrieval of Constraints
When GNNs meet symmetry in ILPs: an orbit-based feature augmentation approach
Edge-aware Image Smoothing with Relative Wavelet Domain Representation
A Stochastic Approach to the Subset Selection Problem via Mirror Descent
Linear Partial Gromov-Wasserstein Embedding
Cauchy-Schwarz Regularizers
Nonconvex Stochastic Optimization under Heavy-Tailed Noises: Optimal Convergence without Gradient Clipping
VLAS: Vision-Language-Action Model with Speech Instructions for Customized Robot Manipulation
On the Crucial Role of Initialization for Matrix Factorization
Convex Formulations for Training Two-Layer ReLU Neural Networks
Efficient Alternating Minimization with Applications to Weighted Low Rank Approximation
Improving Convergence Guarantees of Random Subspace Second-order Algorithm for Nonconvex Optimization
On the Performance Analysis of Momentum Method: A Frequency Domain Perspective
Variational Search Distributions
Multi-Label Test-Time Adaptation with Bound Entropy Minimization
Debiasing Mini-Batch Quadratics for Applications in Deep Learning
Robust System Identification: Finite-sample Guarantees and Connection to Regularization
Towards Faster Decentralized Stochastic Optimization with Communication Compression
PARTNR: A Benchmark for Planning and Reasoning in Embodied Multi-agent Tasks
Event-Driven Online Vertical Federated Learning
Methods with Local Steps and Random Reshuffling for Generally Smooth Non-Convex Federated Optimization
Newton Meets Marchenko-Pastur: Massively Parallel Second-Order Optimization with Hessian Sketching and Debiasing
Optimizing Neural Network Representations of Boolean Networks
Leveraging Variable Sparsity to Refine Pareto Stationarity in Multi-Objective Optimization
Parameter and Memory Efficient Pretraining via Low-rank Riemannian Optimization
DeeperForward: Enhanced Forward-Forward Training for Deeper and Better Performance
POTEC: Off-Policy Contextual Bandits for Large Action Spaces via Policy Decomposition
Fat-to-Thin Policy Optimization: Offline Reinforcement Learning with Sparse Policies
Cross-Domain Off-Policy Evaluation and Learning for Contextual Bandits
AnyTouch: Learning Unified Static-Dynamic Representation across Multiple Visuo-tactile Sensors
A General Framework for Off-Policy Learning with Partially-Observed Reward
Neuroplastic Expansion in Deep Reinforcement Learning
Geometry-aware RL for Manipulation of Varying Shapes and Deformable Objects
Don't flatten, tokenize! Unlocking the key to SoftMoE's efficacy in deep RL
Distilling Reinforcement Learning Algorithms for In-Context Model-Based Planning
Stabilizing Reinforcement Learning in Differentiable Multiphysics Simulation
Student-Informed Teacher Training
Select before Act: Spatially Decoupled Action Repetition for Continuous Control
MaxInfoRL: Boosting exploration in reinforcement learning through information gain maximization
ContraDiff: Planning Towards High Return States via Contrastive Learning
DexTrack: Towards Generalizable Neural Tracking Control for Dexterous Manipulation from Human References
Reconstruction-Guided Policy: Enhancing Decision-Making through Agent-Wise State Consistency
Learning Transformer-based World Models with Contrastive Predictive Coding
Reinforcement Learning for Control of Non-Markovian Cellular Population Dynamics
Causal Information Prioritization for Efficient Reinforcement Learning
On Generalization Across Environments In Multi-Objective Reinforcement Learning
Zero-shot Model-based Reinforcement Learning using Large Language Models
Can a MISL Fly? Analysis and Ingredients for Mutual Information Skill Learning
Kinetix: Investigating the Training of General Agents through Open-Ended Physics-Based Control Tasks
InvestESG: A multi-agent reinforcement learning benchmark for studying climate investment as a social dilemma
Lean-STaR: Learning to Interleave Thinking and Proving
BodyGen: Advancing Towards Efficient Embodiment Co-Design
Do Mice Grok? Glimpses of Hidden Progress in Sensory Cortex
CaPo: Cooperative Plan Optimization for Efficient Embodied Multi-Agent Cooperation
Toward Efficient Multi-Agent Exploration With Trajectory Entropy Maximization
Near-Optimal Online Learning for Multi-Agent Submodular Coordination: Tight Approximation and Communication Efficiency
Expected Return Symmetries
Learning to Communicate Through Implicit Communication Channels
Extreme Risk Mitigation in Reinforcement Learning using Extreme Value Theory
Doubly Optimal Policy Evaluation for Reinforcement Learning
Residual-MPPI: Online Policy Customization for Continuous Control
Overcoming Slow Decision Frequencies in Continuous Control: Model-Based Sequence Reinforcement Learning for Model-Free Control
Instant Policy: In-Context Imitation Learning via Graph Diffusion
Synthesizing Programmatic Reinforcement Learning Policies with Large Language Model Guided Search
$q$-exponential family for policy optimization
UTILITY: Utilizing Explainable Reinforcement Learning to Improve Reinforcement Learning
ADMM for Nonconvex Optimization under Minimal Continuity Assumption
Efficient Reinforcement Learning with Large Language Model Priors
Correlated Proxies: A New Definition and Improved Mitigation for Reward Hacking
BAMDP Shaping: a Unified Framework for Intrinsic Motivation and Reward Shaping
ELBOing Stein: Variational Bayes with Stein Mixture Inference
InverseBench: Benchmarking Plug-and-Play Diffusion Priors for Inverse Problems in Physical Sciences
Standard Gaussian Process is All You Need for High-Dimensional Bayesian Optimization
Distilling Structural Representations into Protein Sequence Models
VTDexManip: A Dataset and Benchmark for Visual-tactile Pretraining and Dexterous Manipulation with Reinforcement Learning
Gaussian Ensemble Belief Propagation for Efficient Inference in High-Dimensional, Black-box Systems
Provable Convergence and Limitations of Geometric Tempering for Langevin Dynamics
Improving Uncertainty Estimation through Semantically Diverse Language Generation
SoftCVI: Contrastive variational inference with self-generated soft labels
Improved Finite-Particle Convergence Rates for Stein Variational Gradient Descent
Conditional Testing based on Localized Conformal $p$-values
Conformalized Interactive Imitation Learning: Handling Expert Shift and Intermittent Feedback
Federated Domain Generalization with Data-free On-server Matching Gradient
Trained Transformer Classifiers Generalize and Exhibit Benign Overfitting In-Context
Proxy Denoising for Source-Free Domain Adaptation
Efficient Diffusion Transformer Policies with Mixture of Expert Denoisers for Multitask Learning
Minimax Optimal Two-Stage Algorithm For Moment Estimation Under Covariate Shift
Divergence-Regularized Discounted Aggregation: Equilibrium Finding in Multiplayer Partially Observable Stochastic Games
Last-Iterate Convergence Properties of Regret-Matching Algorithms in Games
Generalized Principal-Agent Problem with a Learning Agent
Classic but Everlasting: Traditional Gradient-Based Algorithms Converge Fast Even in Time-Varying Multi-Player Games
What should a neuron aim for? Designing local objective functions based on information theory
Regret Bounds for Episodic Risk-Sensitive Linear Quadratic Regulator
Generalization Bounds for Canonicalization: A Comparative Study with Group Averaging
Theory on Score-Mismatched Diffusion Models and Zero-Shot Conditional Samplers
Broadening Target Distributions for Accelerated Diffusion Models via a Novel Analysis Approach
Data Scaling Laws in Imitation Learning for Robotic Manipulation
On the Expressiveness of Rational ReLU Neural Networks With Bounded Depth
Linear Bandits with Memory
Dynamic Assortment Selection and Pricing with Censored Preference Feedback
Neural Dueling Bandits: Preference-Based Optimization with Human Feedback
Pairwise Elimination with Instance-Dependent Guarantees for Bandits with Cost Subsidy
Lipschitz Bandits in Optimal Space
dEBORA: Efficient Bilevel Optimization-based low-Rank Adaptation
Optimizing $(L_0, L_1)$-Smooth Functions by Gradient Methods
Nonasymptotic Analysis of Stochastic Gradient Descent with the Richardson–Romberg Extrapolation
Fair Submodular Cover
OccProphet: Pushing the Efficiency Frontier of Camera-Only 4D Occupancy Forecasting with an Observer-Forecaster-Refiner Framework
Tight Lower Bounds under Asymmetric High-Order Hölder Smoothness and Uniform Convexity
A Unified Theory of Quantum Neural Network Loss Landscapes
Equivariant Symmetry Breaking Sets
Boundary constrained Gaussian processes for robust physics-informed machine learning of linear partial differential equations
Improved Regret Bounds for Linear Adversarial MDPs via Linear Optimization
On Minimizing Adversarial Counterfactual Error in Adversarial Reinforcement Learning
Minimax Optimal Reinforcement Learning with Quasi-Optimism
Beyond Worst-Case Dimensionality Reduction for Sparse Vectors
Reconciling Model Multiplicity for Downstream Decision Making
Everything, Everywhere, All at Once: Is Mechanistic Interpretability Identifiable?
FreDF: Learning to Forecast in the Frequency Domain
Differentiable Causal Discovery for Latent Hierarchical Causal Models
Systems with Switching Causal Relations: A Meta-Causal Perspective
Signature Kernel Conditional Independence Tests in Causal Discovery for Stochastic Processes
Stabilized Neural Prediction of Potential Outcomes in Continuous Time
Standardizing Structural Causal Models
A Skewness-Based Criterion for Addressing Heteroscedastic Noise in Causal Discovery
Advancing Out-of-Distribution Detection via Local Neuroplasticity
Has the Deep Neural Network learned the Stochastic Process? An Evaluation Viewpoint
Attribute-based Visual Reprogramming for Vision-Language Models
Structural-Entropy-Based Sample Selection for Efficient and Effective Learning
Investigating Pattern Neurons in Urban Time Series Forecasting
MMD-Regularized Unbalanced Optimal Transport
Fast Summation of Radial Kernels via QMC Slicing
Boost Self-Supervised Dataset Distillation via Parameterization, Predefined Augmentation, and Approximation
Global Identifiability of Overcomplete Dictionary Learning via L1 and Volume Minimization
Learning Structured Representations by Embedding Class Hierarchy with Fast Optimal Transport
URLOST: Unsupervised Representation Learning without Stationarity or Topology
ReSi: A Comprehensive Benchmark for Representational Similarity Measures
Learnable Expansion of Graph Operators for Multi-Modal Feature Fusion
One for all and all for one: Efficient computation of partial Wasserstein distances on the line
Qinco2: Vector Compression and Search with Improved  Implicit Neural Codebooks
The Case for Cleaner Biosignals: High-fidelity Neural Compressor Enables Transfer from Cleaner iEEG to Noisier EEG
ConMix: Contrastive Mixup at Representation Level for Long-tailed Deep Clustering
Scale-Aware Contrastive Reverse Distillation for Unsupervised Medical Anomaly Detection
PIG: Physics-Informed Gaussians as Adaptive Parametric Mesh Representations
Budgeted Online Continual Learning by Adaptive Layer Freezing and Frequency-based Sampling
LoRA-X: Bridging Foundation Models with Training-Free Cross-Model Adaptation
Adaptive Retention & Correction: Test-Time Training for Continual Learning
Multi-objective Differentiable Neural Architecture Search
MIRACLE 3D: Memory-efficient Integrated Robust Approach for Continual Learning on 3D Point Clouds via Shape Model Construction
Why In-Context Learning Models are Good Few-Shot Learners?
DailyDilemmas: Revealing Value Preferences of LLMs with Quandaries of Daily Life
Broaden your SCOPE! Efficient Multi-turn Conversation Planning for LLMs with Semantic Space
Exploring Prosocial Irrationality for LLM Agents: A Social Cognition View
Image-level Memorization Detection via Inversion-based Inference Perturbation
Hessian-Free Online Certified Unlearning
How much of my dataset did you use? Quantitative Data Usage Inference in Machine Learning
DiSK: Differentially Private Optimizer with Simplified Kalman Filter for Noise Reduction
Data-adaptive Differentially Private Prompt Synthesis for In-Context Learning
BadRobot: Jailbreaking Embodied LLM Agents in the Physical World
Dynamic Neural Fortresses: An Adaptive Shield for Model Extraction Defense
Conformal Structured Prediction
HyperFace: Generating Synthetic Face Recognition Datasets by Exploring Face Embedding Hypersphere
Competing Large Language Models in Multi-Agent Gaming Environments
Black-Box Detection of Language Model Watermarks
Probe before You Talk: Towards Black-box Defense against Backdoor Unalignment for Large Language Models
Rethinking Invariance Regularization in Adversarial Training to Improve Robustness-Accuracy Trade-off
A Closer Look at Machine Unlearning for Large Language Models
When Prompt Engineering Meets Software Engineering: CNL-P as Natural and Robust "APIs'' for Human-AI Interaction
Mitigating Spurious Correlations in Zero-Shot Multimodal Models
Adversarial Latent Feature Augmentation for Fairness
Improved Techniques for Optimization-Based Jailbreaking on Large Language Models
Enhancing Robust Fairness via Confusional Spectral Regularization
Auto-GDA: Automatic Domain Adaptation for Efficient Grounding Verification in Retrieval-Augmented Generation
SWIFT: On-the-Fly Self-Speculative Decoding for LLM Inference Acceleration
On Calibration of LLM-based Guard Models for Reliable Content Moderation
PCNN: Probable-Class Nearest-Neighbor Explanations Improve Fine-Grained Image Classification Accuracy for AIs and Humans
How to Probe: Simple Yet Effective Techniques for Improving Post-hoc Explanations
CONDA: Adaptive Concept Bottleneck for Foundation Models Under Distribution Shifts
Bridging the Data Provenance Gap Across Text, Speech, and Video
Sparse Feature Circuits: Discovering and Editing Interpretable Causal Graphs in Language Models
Watermark Anything With Localized Messages
NNsight and NDIF: Democratizing Access to Open-Weight Foundation Model Internals
Concept Bottleneck Large Language Models
F-Fidelity: A Robust Framework for Faithfulness Evaluation of Explainable AI
Geometry-Aware Approaches for Balancing Performance and Theoretical Guarantees in Linear Bandits
SonicSim: A customizable simulation platform for speech processing in moving sound source scenarios
Looking Inward: Language Models Can Learn About Themselves by Introspection
Sparse autoencoders reveal selective remapping of visual concepts during adaptation
Boosting the visual interpretability of CLIP via adversarial fine-tuning
InstaSHAP: Interpretable Additive Models Explain Shapley Values Instantly
Generating Likely Counterfactuals Using Sum-Product Networks
PhyloLM: Inferring the Phylogeny of Large Language Models and Predicting their Performances in Benchmarks
Linear Representations of Political Perspective Emerge in Large Language Models
Counterfactual Concept Bottleneck Models
Provably Accurate Shapley Value Estimation via Leverage Score Sampling
Erasing Concept Combination from Text-to-Image Diffusion Model
Three-in-One: Fast and Accurate Transducer for Hybrid-Autoregressive ASR
Neural Interactive Proofs
Fair Clustering in the Sliding Window Model
An Effective Theory of Bias Amplification
Does Refusal Training in LLMs Generalize to the Past Tense?
DarkBench: Benchmarking Dark Patterns in Large Language Models
Balancing Bias in Two-sided Markets for Fair Stable Matchings
Do as We Do, Not as You Think: the Conformity of Large Language Models
SANER: Annotation-free Societal Attribute Neutralizer for Debiasing CLIP
PixWizard: Versatile Image-to-Image Visual Assistant with Open-Language Instructions
On the Convergence of Adaptive Gradient Methods for Nonconvex Optimization
Audio Large Language Models Can Be Descriptive Speech Quality Evaluators
Learning Regularized Graphon Mean-Field Games with Unknown Graphons
LLMs' Potential Influences on Our Democracy: Challenges and Opportunities
Analysing The Spectral Biases in Generative Models
Repurposing in AI: A Distinct Approach or an Extension of Creative Problem Solving?
SPARTUN3D: Situated Spatial Understanding of 3D World in Large Language Model
OmniRe: Omni Urban Scene Reconstruction
GenSE: Generative Speech Enhancement via Language Models using Hierarchical Modeling
HQGS: High-Quality Novel View Synthesis with Gaussian Splatting in Degraded Scenes
Beyond Graphs: Can Large Language Models Comprehend Hypergraphs?
CLIPDrag: Combining Text-based and Drag-based Instructions for Image Editing
Synthio: Augmenting Small-Scale Audio Classification Datasets with Synthetic Data
Advancing LLM Reasoning Generalists with Preference Trees
RelitLRM: Generative Relightable Radiance for Large Reconstruction Models
AdaGrad under Anisotropic Smoothness
MLLM can see? Dynamic Correction Decoding for Hallucination Mitigation
Prompting Fairness: Integrating Causality to Debias Large Language Models
On the Importance of Language-driven Representation Learning for Heterogeneous Federated Learning
SEPARATE: A Simple Low-rank Projection for Gradient Compression in Modern Large-scale Model Training Process
Breach By A Thousand Leaks: Unsafe Information Leakage in 'Safe' AI Responses
PRDP: Progressively Refined Differentiable Physics
Lightweight Neural App Control
ADIFF: Explaining audio difference using natural language
Grounding by Trying: LLMs with Reinforcement Learning-Enhanced Retrieval
Spread Preference Annotation: Direct Preference Judgment for Efficient LLM Alignment
Rare-to-Frequent: Unlocking Compositional Generation Power of Diffusion Models on Rare Concepts with LLM Guidance
A Graph Enhanced Symbolic Discovery Framework For Efficient Logic Optimization
Data Shapley in One Training Run
Maximizing the Potential of Synthetic Data: Insights from Random Matrix Theory
From Few to Many: Self-Improving Many-Shot Reasoners Through Iterative Optimization and Generation
Revisiting Large-Scale Non-convex Distributionally Robust Optimization
Computing Circuits Optimization via Model-Based Circuit Genetic Evolution
Pursuing Better Decision Boundaries for Long-Tailed Object Detection via Category Information Amount
TIGER: Time-frequency Interleaved Gain Extraction and Reconstruction for Efficient Speech Separation
Multi-session, multi-task neural decoding from distinct cell-types and brain regions
QP-SNN: Quantized and Pruned Spiking Neural Networks
SV-RAG: LoRA-Contextualizing Adaptation of  MLLMs for Long Document Understanding
One Model Transfer to All: On Robust Jailbreak Prompts Generation against LLMs
Non-myopic Generation of Language Models for Reasoning and Planning
Unlearning-based Neural Interpretations
Interpretable Unsupervised Joint Denoising and Enhancement for Real-World low-light Scenarios
Sequential Stochastic Combinatorial Optimization Using Hierarchal Reinforcement Learning
Do LLMs Recognize Your Preferences? Evaluating Personalized Preference Following in LLMs
SpaceGNN: Multi-Space Graph Neural Network for Node Anomaly Detection with Extremely Limited Labels
A Theory for Token-Level Harmonization in Retrieval-Augmented Generation
Physics-informed Temporal Difference Metric Learning for Robot Motion Planning
Discriminator-Guided Embodied Planning for LLM Agent
Certifying Language Model Robustness with Fuzzed Randomized Smoothing: An Efficient Defense Against Backdoor Attacks
Joint Reward and Policy Learning with Demonstrations and Human Feedback Improves Alignment
Anyprefer: An Agentic Framework for Preference Data Synthesis
Reassessing How to Compare and Improve the Calibration of Machine Learning Models
COAT: Compressing Optimizer states and Activations for Memory-Efficient FP8 Training
Follow My Instruction and Spill the Beans: Scalable Data Extraction from Retrieval-Augmented Generation Systems
A Common Pitfall of Margin-based Language Model Alignment: Gradient Entanglement
Can Large Language Models Understand Symbolic Graphics Programs?
The Power of LLM-Generated Synthetic Data for Stance Detection in Online Political Discussions
CirT: Global Subseasonal-to-Seasonal Forecasting with Geometry-inspired Transformer
Min-K%++: Improved Baseline for Pre-Training Data Detection from Large Language Models
Federated Few-Shot Class-Incremental Learning
DGQ: Distribution-Aware Group Quantization for Text-to-Image Diffusion Models
Self-Play Preference Optimization for Language Model Alignment
CityGaussianV2: Efficient and Geometrically Accurate Reconstruction for Large-Scale Scenes
Straightness of Rectified Flow: A Theoretical Insight into Wasserstein Convergence
FreeVS: Generative View Synthesis on Free Driving Trajectory
Large Scale Knowledge Washing
Language Representations Can be What Recommenders Need: Findings and Potentials
SeCom: On Memory Construction and Retrieval for Personalized Conversational Agents
Combatting Dimensional Collapse in LLM Pre-Training Data via Submodular File Selection
Simple ReFlow: Improved Techniques for Fast Flow Models
ADMM for Structured Fractional Minimization
Mix-CPT: A Domain Adaptation Framework via Decoupling Knowledge Learning and Format Alignment
NatureLM-audio: an Audio-Language Foundation Model for Bioacoustics
Second-Order Min-Max Optimization with Lazy Hessians
Can Neural Networks Achieve Optimal Computational-statistical Tradeoff? An Analysis on Single-Index Model
Merging LoRAs like Playing LEGO: Pushing the Modularity of LoRA to Extremes Through Rank-Wise Clustering
Learning Interleaved Image-Text Comprehension in Vision-Language Large Models
Predictive Inverse Dynamics Models are Scalable Learners for Robotic Manipulation
SPDIM: Source-Free Unsupervised Conditional and Label Shift Adaptation in EEG
Chunk-Distilled Language Modeling
An Effective Manifold-based Optimization Method for Distributionally Robust Classification
How Much is a  Noisy Image Worth? Data Scaling Laws for Ambient Diffusion.
Interleaved Scene Graphs for Interleaved Text-and-Image Generation Assessment
OCEAN: Offline Chain-of-thought Evaluation and Alignment in Large Language Models
Effective post-training embedding compression via temperature control in contrastive training
GLOMA: Global Video Text Spotting with Morphological Association
Data Distillation for extrapolative protein design through exact preference optimization
UniMatch: Universal Matching from Atom to Task for Few-Shot Drug Discovery
Linear Multistep Solver Distillation for Fast Sampling of Diffusion Models
ProtPainter: Draw or Drag Protein via Topology-guided Diffusion
NeuroLM: A Universal Multi-task Foundation Model for Bridging the Gap between Language and EEG Signals
Diffusion-Based Planning for Autonomous Driving with Flexible Guidance
MGDA Converges under Generalized Smoothness, Provably
Understanding and Enhancing Safety Mechanisms of LLMs via Safety-Specific Neuron
Language-Image Models with 3D Understanding
Improving Generalization and Robustness in SNNs Through Signed Rate Encoding and Sparse Encoding Attacks
When Graph Neural Networks Meet Dynamic Mode Decomposition
From Artificial Needles to Real Haystacks: Improving Retrieval Capabilities in LLMs by Finetuning on Synthetic Data
Deconstructing Denoising Diffusion Models for Self-Supervised Learning
PhiNets: Brain-inspired Non-contrastive Learning Based on Temporal Prediction Hypothesis
Improving Language Model Distillation through Hidden State Matching
SIM: Surface-based fMRI Analysis for Inter-Subject Multimodal Decoding from Movie-Watching Experiments
On the Optimization and Generalization of Multi-head Attention
Unveiling the Secret Recipe: A Guide For Supervised Fine-Tuning Small LLMs
A Little Goes a Long Way: Efficient Long Context Training and Inference with Partial Contexts
MCNC: Manifold-Constrained Reparameterization for Neural Compression
Can Knowledge Editing Really Correct Hallucinations?
Sharper Guarantees for Learning Neural Network Classifiers with Gradient Methods
The Optimization Landscape of SGD Across the Feature Learning Strength
How Feature Learning Can Improve Neural Scaling Laws
Towards Out-of-Modal Generalization without Instance-level Modal Correspondence
Chain-of-Focus Prompting: Leveraging Sequential Visual Cues to Prompt Large Autoregressive Vision Models
The 3D-PC: a benchmark for visual perspective taking in humans and machines
Endless Jailbreaks with Bijection Learning
SigDiffusions: Score-Based Diffusion Models for Time Series via Log-Signature Embeddings
Context-Parametric Inversion: Why Instruction Finetuning May Not Actually Improve Context Reliance
DiscoveryBench: Towards Data-Driven Discovery with Large Language Models
Grounding Multimodal Large Language Model in GUI World
Denoising Autoregressive Transformers for Scalable Text-to-Image Generation
Mixture of In-Context Prompters for Tabular PFNs
GraphBridge: Towards Arbitrary Transfer Learning in GNNs
Towards Multiple Character Image Animation Through Enhancing Implicit Decoupling
Balancing Act: Diversity and Consistency in Large Language Model Ensembles
On Conformal Isometry of Grid Cells: Learning Distance-Preserving Position Embedding
Infilling Score: A Pretraining Data Detection Algorithm for Large Language Models
3D-SPATIAL MULTIMODAL MEMORY
How many samples are needed to train a deep neural network?
Scaling Instruction-tuned LLMs to Million-token Contexts via Hierarchical Synthetic Data Generation
Fitting Networks with a Cancellation Trick
Can Reinforcement Learning Solve Asymmetric Combinatorial-Continuous Zero-Sum Games?
GenEx: Generating an Explorable World
Dynamic Modeling of Patients, Modalities and Tasks via Multi-modal Multi-task Mixture of Experts
Comparing noisy neural population dynamics using optimal transport distances
Vision CNNs trained to estimate spatial latents learned similar ventral-stream-aligned representations
A Computational Framework for Modeling Emergence of Color Vision in the Human Brain
Learning and aligning single-neuron invariance manifolds in visual cortex
Correlating instruction-tuning (in multimodal models) with vision-language processing (in the brain)
Disentangling Representations through Multi-task Learning
Transition Path Sampling with Improved Off-Policy Training of Diffusion Path Samplers
SPD Attack - Prevention of AI Powered Image Editing by Image Immunization
IDA-VLM: Towards Movie Understanding via ID-Aware Large Vision-Language Model
Solving Inverse Problems with Model Mismatch using Untrained Neural Networks within Model-based Architectures
Re-Thinking Inverse Graphics With Large Language Models
VideoGLUE: Video General Understanding Evaluation of Foundation Models
Animate-X: Universal Character Image Animation with Enhanced Motion Representation
MoDGS: Dynamic Gaussian Splatting from Casually-captured Monocular Videos with Depth Priors
CtrLoRA: An Extensible and Efficient Framework for Controllable Image Generation
ND-SDF: Learning Normal Deflection Fields for High-Fidelity Indoor Reconstruction
GDrag:Towards General-Purpose Interactive Editing with Anti-ambiguity Point Diffusion
Representative Guidance: Diffusion Model Sampling with Coherence
FreqPrior: Improving Video Diffusion Models with Frequency Filtering Gaussian Noise
Sports-Traj: A Unified Trajectory Generation Model for Multi-Agent Movement in Sports
RobuRCDet: Enhancing Robustness of Radar-Camera Fusion in Bird's Eye View for 3D Object Detection
CEB: Compositional Evaluation Benchmark for Fairness in Large Language Models
Decoupling Layout from Glyph in Online Chinese Handwriting Generation
Gaussian-Det: Learning Closed-Surface Gaussians for 3D Object Detection
Long-horizon Visual Instruction Generation with Logic and Attribute Self-reflection
DreamCatalyst: Fast and High-Quality 3D Editing via Controlling Editability and Identity Preservation
3D StreetUnveiler with Semantic-aware 2DGS - a simple baseline
LASER: A Neuro-Symbolic Framework for Learning Spatio-Temporal Scene Graphs with Weak Supervision
Boltzmann-Aligned Inverse Folding Model as a Predictor of Mutational Effects on Protein-Protein Interactions
Gaussian Head & Shoulders: High Fidelity Neural Upper Body Avatars with Anchor Gaussian Guided Texture Warping
Centrality-guided Pre-training for Graph
PostEdit: Posterior Sampling for Efficient Zero-Shot Image Editing
Storybooth: Training-Free Multi-Subject Consistency for Improved Visual Storytelling
SAMRefiner: Taming Segment Anything Model for Universal Mask Refinement
Ranking-aware adapter for text-driven image ordering with CLIP
Accessing Vision Foundation Models via ImageNet-1K
Dynamic Gaussians Mesh: Consistent Mesh Reconstruction from Dynamic Scenes
Competition Dynamics Shape Algorithmic Phases of In-Context Learning
D-FINE: Redefine Regression Task of DETRs as Fine-grained Distribution Refinement
(ends 5:30 PM)
Break:
(ends 3:30 PM)
3:30 p.m.
Oral Session 6A
[3:30-5:00]
3:30-4:42
[3:30]
Training Language Models to Self-Correct via Reinforcement Learning
[3:42]
Reasoning Elicitation in Language Models via Counterfactual Feedback
[3:54]
Self-Improvement in Language Models: The Sharpening Mechanism
[4:06]
ReGenesis: LLMs can Grow into Reasoning Generalists via Self-Improvement
[4:18]
Mind the Gap: Examining the Self-Improvement Capabilities of Large Language Models
[4:30]
Learning Dynamics of LLM Finetuning
(ends 5:00 PM)
Oral Session 6B
[3:30-5:00]
3:30-4:42
[3:30]
MoDeGPT: Modular Decomposition for Large Language Model Compression
[3:42]
AlphaEdit: Null-Space Constrained Model Editing for Language Models
[3:54]
Judge Decoding: Faster Speculative Sampling Requires Going Beyond Model Alignment
[4:06]
Cheating Automatic LLM Benchmarks: Null Models Achieve High Win Rates
[4:18]
Faster Cascades via Speculative Decoding
[4:30]
Syntactic and Semantic Control of Large Language Models via Sequential Monte Carlo
(ends 5:00 PM)
Oral Session 6C
[3:30-5:00]
3:30-4:42
[3:30]
Accelerated training through iterative gradient propagation along the residual path
[3:42]
Learning Randomized Algorithms with Transformers
[3:54]
Attention as a Hypernetwork
[4:06]
Transformers Provably Solve Parity Efficiently with Chain of Thought
[4:18]
When is Task Vector Provably Effective for Model Editing? A Generalization Analysis of Nonlinear Transformers
[4:30]
Progressive distillation induces an implicit curriculum
(ends 5:00 PM)
Oral Session 6D
[3:30-5:00]
3:30-4:42
[3:30]
OptionZero: Planning with Learned Options
[3:42]
The Complexity of Two-Team Polymatrix Games with Independent Adversaries
[3:54]
Advantage Alignment Algorithms
[4:06]
Brain Bandit: A Biologically Grounded Neural Network for Efficient Control of Exploration
[4:18]
Computationally Efficient RL under Linear Bellman Completeness for Deterministic Dynamics
[4:30]
Tractable Multi-Agent Reinforcement Learning through Behavioral Economics
(ends 5:00 PM)
Oral Session 6E
[3:30-5:00]
3:30-4:42
[3:30]
SymmetricDiffusers: Learning Discrete Diffusion Models over Finite Symmetric Groups
[3:42]
Generator Matching: Generative modeling with arbitrary Markov processes
[3:54]
Emergence of meta-stable clustering in mean-field transformer models
[4:06]
CAX: Cellular Automata Accelerated in JAX
[4:18]
Flow Matching with General Discrete Paths: A Kinetic-Optimal Perspective
[4:30]
Learning Distributions of Complex Fluid Simulations with Diffusion Graph Networks
(ends 5:00 PM)
Oral Session 6F
[3:30-5:00]
3:30-4:42
[3:30]
On the Identification of Temporal Causal Representation with Instantaneous Dependence
[3:42]
The Hidden Cost of Waiting for Accurate Predictions
[3:54]
Root Cause Analysis of Anomalies in Multivariate Time Series through Granger Causal Discovery
[4:06]
When Selection Meets Intervention: Additional Complexities in Causal Discovery
[4:18]
CyberHost: A One-stage Diffusion Framework for Audio-driven Talking Body Generation
[4:30]
Loopy: Taming Audio-Driven Portrait Avatar with Long-Term Motion Dependency
(ends 5:00 PM)
5 p.m.
Social:
LLM Agents 360°: A Holistic View on Frameworks, Systems, and Simulations.
(ends 6:30 PM)
Social:
Queer in AI Social
(ends 6:30 PM)
Social:
AI Co-scientist Discussion
(ends 6:30 PM)
SUN 27 APR
8:30 a.m.
Workshop:
Towards Agentic AI for Science: Hypothesis Generation, Comprehension, Quantification, and Validation
(ends 6:00 PM)
Workshop:
XAI4Science: From Understanding Model Behavior to Discovering New Scientific Knowledge
(ends 6:00 PM)
Workshop:
Machine Learning Multiscale Processes
(ends 6:00 PM)
Workshop:
The 2nd Workshop on Foundation Models in the Wild
(ends 9:00 AM)
8:45 a.m.
Workshop:
ICLR 2025 Workshop on Human-AI Coevolution
(ends 5:15 PM)
8:50 a.m.
Workshop:
Modular, Collaborative and Decentralized Deep Learning
(ends 6:00 PM)
Workshop:
Integrating Generative and Experimental Platforms for Biomolecular Design
(ends 5:30 PM)
8:55 a.m.
Workshop:
VerifAI: AI Verification in the Wild
(ends 5:05 PM)
Workshop:
7th Robot Learning Workshop: Towards Robots with Human-Level Abilities
(ends 6:00 PM)
Workshop:
Will Synthetic Data Finally Solve the Data Access Problem?
(ends 5:10 PM)
9 a.m.
Workshop:
ICLR 2025 Workshop on GenAI Watermarking (WMARK)
(ends 5:30 PM)
Workshop:
3rd ICLR Workshop on Machine Learning for Remote Sensing
(ends 5:20 PM)
Workshop:
Neural Network Weights as a New Data Modality
(ends 5:15 PM)
Workshop:
Workshop on Sparsity in LLMs (SLLM): Deep Dive into Mixture of Experts, Quantization, Hardware, and Inference
(ends 6:00 PM)
Workshop:
Quantify Uncertainty and Hallucination in Foundation Models: The Next Frontier in Reliable AI
(ends 6:00 PM)
Workshop:
Workshop on AI for Children: Healthcare, Psychology, Education
(ends 6:00 PM)
Workshop:
Machine Learning for Genomics Explorations (MLGenX)
(ends 6:00 PM)
Workshop:
New Frontiers in Associative Memories
(ends 6:00 PM)
Workshop:
Self-Improving Foundation Models Without Human Supervision
(ends 6:00 PM)
9:45 a.m.
Workshop:
The Future of Machine Learning Data Practices and Repositories
(ends 5:30 PM)
10 a.m.
Break:
(ends 10:30 AM)
Break:
Lunch Break (on your own)
(ends 2:00 PM)
3 p.m.
Break:
(ends 3:30 PM)
MON 28 APR
8:30 a.m.
Workshop:
2nd Workshop on Navigating and Addressing Data Problems for Foundation Models (DATA-FM)
(ends 6:00 PM)
Workshop:
I Can't Believe It's Not Better: Challenges in Applied Deep Learning
(ends 5:15 PM)
Workshop:
SCOPE: SCALABLE OPTIMIZATION FOR EFFICIENT AND ADPATIVE FOUNDATION MODELS
(ends 6:00 PM)
Workshop:
AI4MAT-ICLR-2025: AI for Accelerated Materials Design
(ends 5:00 PM)
Workshop:
Workshop on Spurious Correlation and Shortcut Learning: Foundations and Solutions
(ends 6:00 PM)
Workshop:
World Models: Understanding, Modelling and Scaling
(ends 6:00 PM)
Workshop:
Workshop on Reasoning and Planning for Large Language Models
(ends 5:40 PM)
Workshop:
The 3rd DL4C Workshop: Emergent Possibilities and Challenges in Deep Learning for Code
(ends 5:20 PM)
8:50 a.m.
Workshop:
ICLR 2025 Workshop on Tackling Climate Change with Machine Learning: Data-Centric Approaches in ML for Climate Action
(ends 5:10 PM)
Workshop:
Building Trust in LLMs and LLM Applications: From Guardrails to Explainability to Regulation
(ends 6:00 PM)
9 a.m.
Workshop:
Generative Models for Robot Learning
(ends 6:00 PM)
Workshop:
Deep Generative Model in Machine Learning: Theory, Principle and Efficacy
(ends 5:50 PM)
Workshop:
ICLR 2025 Workshop on Bidirectional Human-AI Alignment
(ends 6:00 PM)
Workshop:
Advances in Financial AI: Opportunities, Innovations, and Responsible AI
(ends 5:10 PM)
Workshop:
Second Workshop on Representational Alignment (Re$^2$-Align)
(ends 5:30 PM)
Workshop:
Learning Meaningful Representations of Life (LMRL) Workshop @ ICLR 2025
(ends 5:40 PM)
Workshop:
AI for Nucleic Acids (AI4NA)
(ends 6:00 PM)
Workshop:
Open Science for Foundation Models
(ends 6:00 PM)
Workshop:
Workshop on Embodied Intelligence with Large Language Models In Open City Environment
(ends 6:00 PM)
Workshop:
Frontiers in Probabilistic Inference: learning meets Sampling
(ends 6:00 PM)
10 a.m.
Break:
(ends 10:30 AM)
Break:
Lunch Break (on your own)
(ends 2:00 PM)
3 p.m.
Break:
(ends 3:30 PM)
Successful Page Load
ICLR uses cookies for essential functions only. We do not sell your personal
information.
Our Privacy Policy »
Accept
The ICLR Logo above may be used on presentations. Right-click and choose
download. It is a vector graphic and may be used at any scale.
Useful links
Sponsor / Exhibitor Information
Contact
2710 E Corridor Dr, Appleton WI 54913
Phone: +1-920-268-4789
ICLR Proceedings at OpenReview